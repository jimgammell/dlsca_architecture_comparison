Create sweep with ID: cltqb3ug
Sweep URL: https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50/sweeps/cltqb3ug
wandb: Agent Starting Run: 4g50mvqc with config:
wandb: 	optimizer_kwargs-lr: 0.001
wandb: 	optimizer_kwargs-weight_decay: 1e-08
wandb: 	rescale_temperature: False
wandb: 	use_sam: False
wandb: Agent Starting Run: 8fzxm868 with config:
wandb: 	optimizer_kwargs-lr: 0.001
wandb: 	optimizer_kwargs-weight_decay: 1e-08
wandb: 	rescale_temperature: False
wandb: 	use_sam: True
wandb: Agent Starting Run: rn42fa6j with config:
wandb: 	optimizer_kwargs-lr: 0.001
wandb: 	optimizer_kwargs-weight_decay: 1e-08
wandb: 	rescale_temperature: True
wandb: 	use_sam: False
wandb: Agent Starting Run: alcfgtrn with config:
wandb: 	optimizer_kwargs-lr: 0.001
wandb: 	optimizer_kwargs-weight_decay: 1e-08
wandb: 	rescale_temperature: True
wandb: 	use_sam: True
wandb: Agent Starting Run: u2kuh83i with config:
wandb: 	optimizer_kwargs-lr: 0.001
wandb: 	optimizer_kwargs-weight_decay: 1e-06
wandb: 	rescale_temperature: False
wandb: 	use_sam: False
wandb: Agent Starting Run: c8gxq720 with config:
wandb: 	optimizer_kwargs-lr: 0.001
wandb: 	optimizer_kwargs-weight_decay: 1e-06
wandb: 	rescale_temperature: False
wandb: 	use_sam: True
wandb: Agent Starting Run: 1eceu3iv with config:
wandb: 	optimizer_kwargs-lr: 0.001
wandb: 	optimizer_kwargs-weight_decay: 1e-06
wandb: 	rescale_temperature: True
wandb: 	use_sam: False
wandb: Agent Starting Run: dkxd9bq0 with config:
wandb: 	optimizer_kwargs-lr: 0.001
wandb: 	optimizer_kwargs-weight_decay: 1e-06
wandb: 	rescale_temperature: True
wandb: 	use_sam: True
wandb: Agent Starting Run: akbyqtal with config:
wandb: 	optimizer_kwargs-lr: 0.001
wandb: 	optimizer_kwargs-weight_decay: 0.0001
wandb: 	rescale_temperature: False
wandb: 	use_sam: False
wandb: Agent Starting Run: 9tyv3arp with config:
wandb: 	optimizer_kwargs-lr: 0.001
wandb: 	optimizer_kwargs-weight_decay: 0.0001
wandb: 	rescale_temperature: False
wandb: 	use_sam: True
wandb: Agent Starting Run: o9y9ngxi with config:
wandb: 	optimizer_kwargs-lr: 0.001
wandb: 	optimizer_kwargs-weight_decay: 0.0001
wandb: 	rescale_temperature: True
wandb: 	use_sam: False
wandb: Agent Starting Run: k606eeda with config:
wandb: 	optimizer_kwargs-lr: 0.001
wandb: 	optimizer_kwargs-weight_decay: 0.0001
wandb: 	rescale_temperature: True
wandb: 	use_sam: True
wandb: Currently logged in as: jgammell. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: jgammell. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: jgammell. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: jgammell. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: jgammell. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: jgammell. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: jgammell. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: jgammell. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: jgammell. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: jgammell. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: jgammell. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: jgammell. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.15.4
wandb: Run data is saved locally in /local/a/jgammell/dlsca_architecture_comparison/wandb/run-20230614_112640-rn42fa6j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50
wandb: üßπ View sweep at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50/sweeps/cltqb3ug
wandb: üöÄ View run at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50/runs/rn42fa6j
wandb: Tracking run with wandb version 0.15.4
wandb: Run data is saved locally in /local/a/jgammell/dlsca_architecture_comparison/wandb/run-20230614_112639-4g50mvqc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50
wandb: üßπ View sweep at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50/sweeps/cltqb3ug
wandb: üöÄ View run at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50/runs/4g50mvqc
wandb: Tracking run with wandb version 0.15.4
wandb: Run data is saved locally in /local/a/jgammell/dlsca_architecture_comparison/wandb/run-20230614_112640-alcfgtrn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50
wandb: üßπ View sweep at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50/sweeps/cltqb3ug
wandb: üöÄ View run at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50/runs/alcfgtrn
wandb: Tracking run with wandb version 0.15.4
wandb: Run data is saved locally in /local/a/jgammell/dlsca_architecture_comparison/wandb/run-20230614_112640-u2kuh83i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50
wandb: üßπ View sweep at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50/sweeps/cltqb3ug
wandb: üöÄ View run at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50/runs/u2kuh83i
wandb: Tracking run with wandb version 0.15.4
wandb: Run data is saved locally in /local/a/jgammell/dlsca_architecture_comparison/wandb/run-20230614_112640-8fzxm868
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-2
wandb: Tracking run with wandb version 0.15.4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50
wandb: üßπ View sweep at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50/sweeps/cltqb3ug
wandb: üöÄ View run at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50/runs/8fzxm868
wandb: Run data is saved locally in /local/a/jgammell/dlsca_architecture_comparison/wandb/run-20230614_112640-c8gxq720
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-6
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50
wandb: üßπ View sweep at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50/sweeps/cltqb3ug
wandb: üöÄ View run at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50/runs/c8gxq720
wandb: Tracking run with wandb version 0.15.4
wandb: Run data is saved locally in /local/a/jgammell/dlsca_architecture_comparison/wandb/run-20230614_112640-akbyqtal
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-9
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50
wandb: üßπ View sweep at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50/sweeps/cltqb3ug
wandb: üöÄ View run at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50/runs/akbyqtal
wandb: Tracking run with wandb version 0.15.4
wandb: Run data is saved locally in /local/a/jgammell/dlsca_architecture_comparison/wandb/run-20230614_112640-dkxd9bq0
wandb: Run `wandb offline` to turn off syncing.
wandb: Tracking run with wandb version 0.15.4
wandb: Run data is saved locally in /local/a/jgammell/dlsca_architecture_comparison/wandb/run-20230614_112640-1eceu3iv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-7
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50
wandb: üßπ View sweep at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50/sweeps/cltqb3ug
wandb: üöÄ View run at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50/runs/1eceu3iv
wandb: Syncing run feasible-sweep-8
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50
wandb: üßπ View sweep at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50/sweeps/cltqb3ug
wandb: üöÄ View run at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50/runs/dkxd9bq0
wandb: Tracking run with wandb version 0.15.4
wandb: Run data is saved locally in /local/a/jgammell/dlsca_architecture_comparison/wandb/run-20230614_112640-9tyv3arp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-10
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50
wandb: üßπ View sweep at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50/sweeps/cltqb3ug
wandb: üöÄ View run at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50/runs/9tyv3arp
wandb: Tracking run with wandb version 0.15.4
wandb: Run data is saved locally in /local/a/jgammell/dlsca_architecture_comparison/wandb/run-20230614_112640-k606eeda
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-12
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50
wandb: üßπ View sweep at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50/sweeps/cltqb3ug
wandb: üöÄ View run at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50/runs/k606eeda
wandb: Tracking run with wandb version 0.15.4
wandb: Run data is saved locally in /local/a/jgammell/dlsca_architecture_comparison/wandb/run-20230614_112640-o9y9ngxi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-11
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50
wandb: üßπ View sweep at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50/sweeps/cltqb3ug
wandb: üöÄ View run at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50/runs/o9y9ngxi
Training classifier...
ConvMixer(
  (patch_embedding): Sequential(
    (conv): Conv1d(1, 256, kernel_size=(51,), stride=(51,), padding=(28,))
  )
  (pre_mixer): Sequential(
    (act): GELU(approximate='none')
    (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mixer): Sequential(
    (layer_0): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer_1): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer_2): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer_3): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer_4): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (head): Sequential(
    (pool): AdaptiveAvgPool1d(output_size=1)
    (flatten): Flatten(start_dim=1, end_dim=-1)
    (dense): Linear(in_features=256, out_features=256, bias=True)
  )
)
Number of parameters: 454656
Training classifier...
ModelWithTemperature(
  (model): ConvMixer(
    (patch_embedding): Sequential(
      (conv): Conv1d(1, 256, kernel_size=(51,), stride=(51,), padding=(28,))
    )
    (pre_mixer): Sequential(
      (act): GELU(approximate='none')
      (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (mixer): Sequential(
      (layer_0): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layer_1): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layer_2): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layer_3): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layer_4): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (head): Sequential(
      (pool): AdaptiveAvgPool1d(output_size=1)
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (dense): Linear(in_features=256, out_features=256, bias=True)
    )
  )
)
Number of parameters: 454657
Training classifier...
ModelWithTemperature(
  (model): ConvMixer(
    (patch_embedding): Sequential(
      (conv): Conv1d(1, 256, kernel_size=(51,), stride=(51,), padding=(28,))
    )
    (pre_mixer): Sequential(
      (act): GELU(approximate='none')
      (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (mixer): Sequential(
      (layer_0): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layer_1): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layer_2): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layer_3): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layer_4): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (head): Sequential(
      (pool): AdaptiveAvgPool1d(output_size=1)
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (dense): Linear(in_features=256, out_features=256, bias=True)
    )
  )
)
Number of parameters: 454657
Training classifier...
ConvMixer(
  (patch_embedding): Sequential(
    (conv): Conv1d(1, 256, kernel_size=(51,), stride=(51,), padding=(28,))
  )
  (pre_mixer): Sequential(
    (act): GELU(approximate='none')
    (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mixer): Sequential(
    (layer_0): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer_1): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer_2): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer_3): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer_4): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (head): Sequential(
    (pool): AdaptiveAvgPool1d(output_size=1)
    (flatten): Flatten(start_dim=1, end_dim=-1)
    (dense): Linear(in_features=256, out_features=256, bias=True)
  )
)
Number of parameters: 454656
Training classifier...
ModelWithTemperature(
  (model): ConvMixer(
    (patch_embedding): Sequential(
      (conv): Conv1d(1, 256, kernel_size=(51,), stride=(51,), padding=(28,))
    )
    (pre_mixer): Sequential(
      (act): GELU(approximate='none')
      (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (mixer): Sequential(
      (layer_0): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layer_1): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layer_2): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layer_3): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layer_4): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (head): Sequential(
      (pool): AdaptiveAvgPool1d(output_size=1)
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (dense): Linear(in_features=256, out_features=256, bias=True)
    )
  )
)
Number of parameters: 454657
Training classifier...
ModelWithTemperature(
  (model): ConvMixer(
    (patch_embedding): Sequential(
      (conv): Conv1d(1, 256, kernel_size=(51,), stride=(51,), padding=(28,))
    )
    (pre_mixer): Sequential(
      (act): GELU(approximate='none')
      (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (mixer): Sequential(
      (layer_0): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layer_1): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layer_2): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layer_3): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layer_4): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (head): Sequential(
      (pool): AdaptiveAvgPool1d(output_size=1)
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (dense): Linear(in_features=256, out_features=256, bias=True)
    )
  )
)
Number of parameters: 454657
Training classifier...
ConvMixer(
  (patch_embedding): Sequential(
    (conv): Conv1d(1, 256, kernel_size=(51,), stride=(51,), padding=(28,))
  )
  (pre_mixer): Sequential(
    (act): GELU(approximate='none')
    (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mixer): Sequential(
    (layer_0): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer_1): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer_2): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer_3): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer_4): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (head): Sequential(
    (pool): AdaptiveAvgPool1d(output_size=1)
    (flatten): Flatten(start_dim=1, end_dim=-1)
    (dense): Linear(in_features=256, out_features=256, bias=True)
  )
)
Number of parameters: 454656
Training classifier...
ModelWithTemperature(
  (model): ConvMixer(
    (patch_embedding): Sequential(
      (conv): Conv1d(1, 256, kernel_size=(51,), stride=(51,), padding=(28,))
    )
    (pre_mixer): Sequential(
      (act): GELU(approximate='none')
      (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (mixer): Sequential(
      (layer_0): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layer_1): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layer_2): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layer_3): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layer_4): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (head): Sequential(
      (pool): AdaptiveAvgPool1d(output_size=1)
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (dense): Linear(in_features=256, out_features=256, bias=True)
    )
  )
)
Number of parameters: 454657
Training classifier...
ConvMixer(
  (patch_embedding): Sequential(
    (conv): Conv1d(1, 256, kernel_size=(51,), stride=(51,), padding=(28,))
  )
  (pre_mixer): Sequential(
    (act): GELU(approximate='none')
    (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mixer): Sequential(
    (layer_0): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer_1): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer_2): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer_3): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer_4): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (head): Sequential(
    (pool): AdaptiveAvgPool1d(output_size=1)
    (flatten): Flatten(start_dim=1, end_dim=-1)
    (dense): Linear(in_features=256, out_features=256, bias=True)
  )
)
Number of parameters: 454656
Training classifier...
ConvMixer(
  (patch_embedding): Sequential(
    (conv): Conv1d(1, 256, kernel_size=(51,), stride=(51,), padding=(28,))
  )
  (pre_mixer): Sequential(
    (act): GELU(approximate='none')
    (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mixer): Sequential(
    (layer_0): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer_1): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer_2): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer_3): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer_4): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (head): Sequential(
    (pool): AdaptiveAvgPool1d(output_size=1)
    (flatten): Flatten(start_dim=1, end_dim=-1)
    (dense): Linear(in_features=256, out_features=256, bias=True)
  )
)
Number of parameters: 454656
Training classifier...
ConvMixer(
  (patch_embedding): Sequential(
    (conv): Conv1d(1, 256, kernel_size=(51,), stride=(51,), padding=(28,))
  )
  (pre_mixer): Sequential(
    (act): GELU(approximate='none')
    (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mixer): Sequential(
    (layer_0): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer_1): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer_2): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer_3): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer_4): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (head): Sequential(
    (pool): AdaptiveAvgPool1d(output_size=1)
    (flatten): Flatten(start_dim=1, end_dim=-1)
    (dense): Linear(in_features=256, out_features=256, bias=True)
  )
)
Number of parameters: 454656
Training classifier...
ModelWithTemperature(
  (model): ConvMixer(
    (patch_embedding): Sequential(
      (conv): Conv1d(1, 256, kernel_size=(51,), stride=(51,), padding=(28,))
    )
    (pre_mixer): Sequential(
      (act): GELU(approximate='none')
      (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (mixer): Sequential(
      (layer_0): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layer_1): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layer_2): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layer_3): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layer_4): Sequential(
        (spatial_mixer): SpatialMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (channel_mixer): ChannelMixer(
          (model): Sequential(
            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
            (act): GELU(approximate='none')
            (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (head): Sequential(
      (pool): AdaptiveAvgPool1d(output_size=1)
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (dense): Linear(in_features=256, out_features=256, bias=True)
    )
  )
)
Number of parameters: 454657
New best model found.
Epoch 1 completed.
train loss: 5.557874541584287
train acc: 0.0038063593539703904
train rank: 127.42931772936294
train weight_norm: 94.73212335072425
train grad_norm: 0.2849607042101944
train lr: 0.0009999175912513102
val loss: 5.546994733810425
val acc: 0.00400390625
val rank: 126.41640625
test mean_rank: 70.296
test final_rank: 29.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.547, ECE: 0.001
Optimal temperature: 1.500
After temperature - NLL: 5.546, ECE: 0.001
Before temperature - NLL: 5.547, ECE: 0.001
Optimal temperature: 1.500
After temperature - NLL: 5.546, ECE: 0.001
New best model found.
Epoch 1 completed.
train loss: 5.557875232773546
train acc: 0.0038063593539703904
train rank: 127.42963667844326
train weight_norm: 94.73622704508016
train grad_norm: 0.28496999863830796
train lr: 0.0009999175912513102
val loss: 5.546995317935943
val acc: 0.00400390625
val rank: 126.4185546875
test mean_rank: 70.281
test final_rank: 29.0
test traces_to_disclosure: nan

New best model found.
Epoch 1 completed.
train loss: 5.557875256519138
train acc: 0.0038063593539703904
train rank: 127.42959812415882
train weight_norm: 94.73622699975878
train grad_norm: 0.2849700056330676
train lr: 0.0009999175912513102
val loss: 5.546995317935943
val acc: 0.00400390625
val rank: 126.41728515625
test mean_rank: 70.28
test final_rank: 29.0
test traces_to_disclosure: nan

New best model found.
Epoch 1 completed.
train loss: 5.557759435789742
train acc: 0.0037853297442799463
train rank: 127.43401083725887
train weight_norm: 94.73367512065225
train grad_norm: 0.2832899256762445
train lr: 0.0009999175912513102
val loss: 5.5468644261360165
val acc: 0.00361328125
val rank: 126.26416015625
test mean_rank: 75.335
test final_rank: 37.0
test traces_to_disclosure: nan

New best model found.
Epoch 1 completed.
train loss: 5.557759402417559
train acc: 0.0037853297442799463
train rank: 127.43395651076716
train weight_norm: 94.73367502671148
train grad_norm: 0.2832885414610085
train lr: 0.0009999175912513102
val loss: 5.54686439037323
val acc: 0.00361328125
val rank: 126.26455078125
test mean_rank: 75.328
test final_rank: 36.0
test traces_to_disclosure: nan

New best model found.
Epoch 1 completed.
train loss: 5.5578752269975915
train acc: 0.0038063593539703904
train rank: 127.42951400572005
train weight_norm: 94.74810156279224
train grad_norm: 0.28497005600830105
train lr: 0.0009999175912513102
val loss: 5.5458118438720705
val acc: 0.00361328125
val rank: 126.59287109375
test mean_rank: 156.691
test final_rank: 189.0
test traces_to_disclosure: nan

New best model found.
Epoch 1 completed.
train loss: 5.557875253310274
train acc: 0.0038063593539703904
train rank: 127.4296875
train weight_norm: 94.7481015662272
train grad_norm: 0.28497008588224815
train lr: 0.0009999175912513102
val loss: 5.545811796188355
val acc: 0.00361328125
val rank: 126.592578125
test mean_rank: 156.686
test final_rank: 189.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.547, ECE: 0.001
Optimal temperature: 1.500
After temperature - NLL: 5.546, ECE: 0.001
Before temperature - NLL: 5.547, ECE: 0.001
Optimal temperature: 1.500
After temperature - NLL: 5.546, ECE: 0.001
Before temperature - NLL: 5.547, ECE: 0.001
Optimal temperature: 1.500
After temperature - NLL: 5.546, ECE: 0.001
New best model found.
Epoch 1 completed.
train loss: 5.557758761928348
train acc: 0.0037853297442799463
train rank: 127.43412299517719
train weight_norm: 94.72957121652061
train grad_norm: 0.2832798969711163
train lr: 0.0009999175912513102
val loss: 5.546863853931427
val acc: 0.00361328125
val rank: 126.26640625
test mean_rank: 75.333
test final_rank: 37.0
test traces_to_disclosure: nan

New best model found.
Epoch 1 completed.
train loss: 5.557759438356833
train acc: 0.003790587146702557
train rank: 127.433900431808
train weight_norm: 94.74554947559528
train grad_norm: 0.28328884587271413
train lr: 0.0009999175912513102
val loss: 5.5457626461982725
val acc: 0.003125
val rank: 126.45693359375
test mean_rank: 171.862
test final_rank: 195.0
test traces_to_disclosure: nan

New best model found.
Epoch 1 completed.
train loss: 5.557758771554939
train acc: 0.003790587146702557
train rank: 127.43420185621353
train weight_norm: 94.74144592456295
train grad_norm: 0.2832795406482737
train lr: 0.0009999175912513102
val loss: 5.545762503147126
val acc: 0.003125
val rank: 126.4560546875
test mean_rank: 171.859
test final_rank: 195.0
test traces_to_disclosure: nan

Epoch 2 completed.
train loss: 5.5445911252161695
train acc: 0.004200664535666218
train rank: 123.68199024226111
train weight_norm: 94.85580913802262
train grad_norm: 0.13930052467429552
train lr: 0.000999423900885555
val loss: 5.548035311698913
val acc: 0.003515625
val rank: 126.85283203125
test mean_rank: 209.277
test final_rank: 169.0
test traces_to_disclosure: nan

New best model found.
Epoch 1 completed.
train loss: 5.557759431939106
train acc: 0.003790587146702557
train rank: 127.43411598530733
train weight_norm: 94.74555004650432
train grad_norm: 0.2832890565331254
train lr: 0.0009999175912513102
val loss: 5.545762777328491
val acc: 0.003125
val rank: 126.456640625
test mean_rank: 171.854
test final_rank: 195.0
test traces_to_disclosure: nan

Epoch 2 completed.
train loss: 5.544591478191186
train acc: 0.004200664535666218
train rank: 123.68227939939435
train weight_norm: 94.86812014509948
train grad_norm: 0.13931336997844307
train lr: 0.000999423900885555
val loss: 5.548036789894104
val acc: 0.003515625
val rank: 126.8509765625
test mean_rank: 209.268
test final_rank: 169.0
test traces_to_disclosure: nan

Epoch 2 completed.
train loss: 5.544591448027866
train acc: 0.004195407133243607
train rank: 123.6822215679677
train weight_norm: 94.86812048621071
train grad_norm: 0.13931326757203294
train lr: 0.000999423900885555
val loss: 5.548036909103393
val acc: 0.003515625
val rank: 126.84921875
test mean_rank: 209.257
test final_rank: 169.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.548, ECE: 0.001
Optimal temperature: 1.500
After temperature - NLL: 5.546, ECE: 0.001
Before temperature - NLL: 5.548, ECE: 0.001
Optimal temperature: 1.500
After temperature - NLL: 5.546, ECE: 0.001
Epoch 2 completed.
train loss: 5.5447727231607145
train acc: 0.0046107419246298785
train rank: 123.97436490578735
train weight_norm: 94.87383966390715
train grad_norm: 0.138832568691654
train lr: 0.000999423900885555
val loss: 5.546066915988922
val acc: 0.00390625
val rank: 126.70791015625
test mean_rank: 230.088
test final_rank: 240.0
test traces_to_disclosure: nan

Epoch 2 completed.
train loss: 5.544772721877169
train acc: 0.0046107419246298785
train rank: 123.97442799461642
train weight_norm: 94.87383798627474
train grad_norm: 0.13883244662753993
train lr: 0.000999423900885555
val loss: 5.546066844463349
val acc: 0.00390625
val rank: 126.7091796875
test mean_rank: 230.091
test final_rank: 240.0
test traces_to_disclosure: nan

Epoch 3 completed.
train loss: 5.542701651879948
train acc: 0.004626514131897712
train rank: 122.02543531292059
train weight_norm: 95.12677725712179
train grad_norm: 0.13291329341882477
train lr: 0.0009984373394258015
val loss: 5.5484367370605465
val acc: 0.00302734375
val rank: 126.52001953125
test mean_rank: 142.607
test final_rank: 120.0
test traces_to_disclosure: nan

Epoch 2 completed.
train loss: 5.544599142241446
train acc: 0.004489821668909825
train rank: 123.7332131140646
train weight_norm: 94.85994870438962
train grad_norm: 0.1382732136203083
train lr: 0.000999423900885555
val loss: 5.547885668277741
val acc: 0.00400390625
val rank: 126.85419921875
test mean_rank: 198.591
test final_rank: 155.0
test traces_to_disclosure: nan

Epoch 2 completed.
train loss: 5.544599377772047
train acc: 0.004495079071332436
train rank: 123.73334104419023
train weight_norm: 94.85994819833154
train grad_norm: 0.13827205493853106
train lr: 0.000999423900885555
val loss: 5.547885668277741
val acc: 0.00400390625
val rank: 126.85400390625
test mean_rank: 198.541
test final_rank: 155.0
test traces_to_disclosure: nan

Epoch 2 completed.
train loss: 5.544598818146204
train acc: 0.004489821668909825
train rank: 123.73284684836251
train weight_norm: 94.84763898980668
train grad_norm: 0.1382595986773332
train lr: 0.000999423900885555
val loss: 5.547884464263916
val acc: 0.00400390625
val rank: 126.85595703125
test mean_rank: 198.52
test final_rank: 155.0
test traces_to_disclosure: nan

Epoch 3 completed.
train loss: 5.5427019913777364
train acc: 0.004621256729475101
train rank: 122.02466773216689
train weight_norm: 95.14724966136231
train grad_norm: 0.13293014488913737
train lr: 0.0009984373394258015
val loss: 5.548435699939728
val acc: 0.00302734375
val rank: 126.5171875
test mean_rank: 142.538
test final_rank: 120.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.548, ECE: 0.000
Optimal temperature: 1.500
After temperature - NLL: 5.546, ECE: 0.000
Before temperature - NLL: 5.548, ECE: 0.000
Optimal temperature: 1.500
After temperature - NLL: 5.546, ECE: 0.000
Epoch 3 completed.
train loss: 5.542702065823376
train acc: 0.004621256729475101
train rank: 122.02492183995066
train weight_norm: 95.1472473038523
train grad_norm: 0.1329301495389832
train lr: 0.0009984373394258015
val loss: 5.548434853553772
val acc: 0.00302734375
val rank: 126.51767578125
test mean_rank: 142.528
test final_rank: 120.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.548, ECE: 0.000
Optimal temperature: 1.500
After temperature - NLL: 5.546, ECE: 0.000
Before temperature - NLL: 5.548, ECE: 0.001
Optimal temperature: 1.500
After temperature - NLL: 5.546, ECE: 0.001
Before temperature - NLL: 5.548, ECE: 0.001
Optimal temperature: 1.500
After temperature - NLL: 5.546, ECE: 0.001
Epoch 2 completed.
train loss: 5.54473917705695
train acc: 0.004442505047106326
train rank: 123.97048494279946
train weight_norm: 94.86798781536385
train grad_norm: 0.1383586258582941
train lr: 0.000999423900885555
val loss: 5.545888459682464
val acc: 0.0046875
val rank: 126.473828125
test mean_rank: 238.363
test final_rank: 247.0
test traces_to_disclosure: nan

Epoch 2 completed.
train loss: 5.544739160370859
train acc: 0.004426732839838492
train rank: 123.9705234970839
train weight_norm: 94.86798957793766
train grad_norm: 0.13835876066200856
train lr: 0.000999423900885555
val loss: 5.545888113975525
val acc: 0.0046875
val rank: 126.474609375
test mean_rank: 238.362
test final_rank: 247.0
test traces_to_disclosure: nan

Epoch 2 completed.
train loss: 5.544738770173023
train acc: 0.004431990242261104
train rank: 123.9708021394123
train weight_norm: 94.85567926214331
train grad_norm: 0.13834559545106556
train lr: 0.000999423900885555
val loss: 5.545888316631317
val acc: 0.0046875
val rank: 126.4755859375
test mean_rank: 238.357
test final_rank: 247.0
test traces_to_disclosure: nan

New best model found.
Epoch 3 completed.
train loss: 5.5427718290891175
train acc: 0.004712385038133692
train rank: 122.1728055602288
train weight_norm: 95.1466283466798
train grad_norm: 0.13319577915586872
train lr: 0.0009984373394258015
val loss: 5.545438194274903
val acc: 0.00380859375
val rank: 125.67294921875
test mean_rank: 213.841
test final_rank: 209.0
test traces_to_disclosure: nan

New best model found.
Epoch 3 completed.
train loss: 5.542771822029617
train acc: 0.004712385038133692
train rank: 122.17234290881561
train weight_norm: 95.14662650132601
train grad_norm: 0.13319566688344717
train lr: 0.0009984373394258015
val loss: 5.545438265800476
val acc: 0.00380859375
val rank: 125.67568359375
test mean_rank: 213.852
test final_rank: 209.0
test traces_to_disclosure: nan

Epoch 4 completed.
train loss: 5.541481974949586
train acc: 0.0048420676312247645
train rank: 121.126393211642
train weight_norm: 95.58893548527254
train grad_norm: 0.13124103289991526
train lr: 0.0009969588804891053
val loss: 5.548419427871704
val acc: 0.003515625
val rank: 126.03486328125
test mean_rank: 101.506
test final_rank: 141.0
test traces_to_disclosure: nan

Epoch 4 completed.
train loss: 5.541481517365611
train acc: 0.0048420676312247645
train rank: 121.12610755944368
train weight_norm: 95.61752831261813
train grad_norm: 0.13126060001884796
train lr: 0.0009969588804891053
val loss: 5.548410403728485
val acc: 0.00341796875
val rank: 126.019921875
test mean_rank: 101.504
test final_rank: 141.0
test traces_to_disclosure: nan

Epoch 3 completed.
train loss: 5.542638167077087
train acc: 0.004605484522207268
train rank: 121.96179095165995
train weight_norm: 95.13371418371784
train grad_norm: 0.1326298722563518
train lr: 0.0009984373394258015
val loss: 5.54856630563736
val acc: 0.0033203125
val rank: 126.6005859375
test mean_rank: 144.084
test final_rank: 146.0
test traces_to_disclosure: nan

Epoch 3 completed.
train loss: 5.5426382363885445
train acc: 0.004600227119784657
train rank: 121.9616384869897
train weight_norm: 95.13368331850961
train grad_norm: 0.1326263983583746
train lr: 0.0009984373394258015
val loss: 5.548564779758453
val acc: 0.00322265625
val rank: 126.6056640625
test mean_rank: 143.794
test final_rank: 146.0
test traces_to_disclosure: nan

Epoch 4 completed.
train loss: 5.54148165213789
train acc: 0.004847325033647375
train rank: 121.12651237943022
train weight_norm: 95.61752989560091
train grad_norm: 0.13126097052881583
train lr: 0.0009969588804891053
val loss: 5.5484122157096865
val acc: 0.00341796875
val rank: 126.01904296875
test mean_rank: 101.433
test final_rank: 141.0
test traces_to_disclosure: nan

Epoch 5 completed.
train loss: 5.540145034584672
train acc: 0.005152254374158815
train rank: 120.19255762113055
train weight_norm: 96.20591194812242
train grad_norm: 0.13002167130548536
train lr: 0.000994989983135938
val loss: 5.551215279102325
val acc: 0.00361328125
val rank: 127.5501953125
test mean_rank: 171.373
test final_rank: 74.0
test traces_to_disclosure: nan

Epoch 3 completed.
train loss: 5.542638327520275
train acc: 0.0046107419246298785
train rank: 121.96158416049798
train weight_norm: 95.11322652375087
train grad_norm: 0.1326112931660991
train lr: 0.0009984373394258015
val loss: 5.54856241941452
val acc: 0.00322265625
val rank: 126.6048828125
test mean_rank: 143.841
test final_rank: 146.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.549, ECE: 0.002
Optimal temperature: 1.500
After temperature - NLL: 5.547, ECE: 0.001
Epoch 4 completed.
train loss: 5.5413055766479165
train acc: 0.004989274899057873
train rank: 121.01752817967699
train weight_norm: 95.61280199764495
train grad_norm: 0.13119229222761136
train lr: 0.0009969588804891053
val loss: 5.546352612972259
val acc: 0.003515625
val rank: 126.23291015625
test mean_rank: 102.48
test final_rank: 145.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.548, ECE: 0.002
Optimal temperature: 1.500
After temperature - NLL: 5.546, ECE: 0.001
Before temperature - NLL: 5.549, ECE: 0.002
Optimal temperature: 1.500
After temperature - NLL: 5.547, ECE: 0.001
Before temperature - NLL: 5.548, ECE: 0.002
Optimal temperature: 1.500
After temperature - NLL: 5.546, ECE: 0.001
Before temperature - NLL: 5.548, ECE: 0.002
Optimal temperature: 1.500
After temperature - NLL: 5.546, ECE: 0.001
Epoch 4 completed.
train loss: 5.541305637616328
train acc: 0.004994532301480484
train rank: 121.0183711165321
train weight_norm: 95.61279918014046
train grad_norm: 0.13119195559694294
train lr: 0.0009969588804891053
val loss: 5.546353304386139
val acc: 0.003515625
val rank: 126.23662109375
test mean_rank: 102.351
test final_rank: 145.0
test traces_to_disclosure: nan

New best model found.
Epoch 3 completed.
train loss: 5.542786236887505
train acc: 0.004745681920143563
train rank: 122.18621193640647
train weight_norm: 95.13648004878318
train grad_norm: 0.132355592019468
train lr: 0.0009984373394258015
val loss: 5.545523405075073
val acc: 0.00302734375
val rank: 125.82529296875
test mean_rank: 209.637
test final_rank: 206.0
test traces_to_disclosure: nan

Epoch 5 completed.
train loss: 5.540144458914509
train acc: 0.005141739569313594
train rank: 120.19047744223869
train weight_norm: 96.2424144041597
train grad_norm: 0.13004061633263253
train lr: 0.000994989983135938
val loss: 5.551221656799316
val acc: 0.00380859375
val rank: 127.5478515625
test mean_rank: 171.844
test final_rank: 75.0
test traces_to_disclosure: nan

Epoch 5 completed.
train loss: 5.540144772741387
train acc: 0.005168026581426649
train rank: 120.18934359578284
train weight_norm: 96.2423786888501
train grad_norm: 0.13003925788850065
train lr: 0.000994989983135938
val loss: 5.55121933221817
val acc: 0.00380859375
val rank: 127.55029296875
test mean_rank: 171.68
test final_rank: 75.0
test traces_to_disclosure: nan

New best model found.
Epoch 3 completed.
train loss: 5.542786229828004
train acc: 0.004740424517720951
train rank: 122.18498345670706
train weight_norm: 95.13647398596476
train grad_norm: 0.1323551987295589
train lr: 0.0009984373394258015
val loss: 5.545521998405457
val acc: 0.00302734375
val rank: 125.821484375
test mean_rank: 209.627
test final_rank: 206.0
test traces_to_disclosure: nan

New best model found.
Epoch 3 completed.
train loss: 5.542785744006027
train acc: 0.004740424517720951
train rank: 122.18656242990129
train weight_norm: 95.11600051985089
train grad_norm: 0.13233800981423574
train lr: 0.0009984373394258015
val loss: 5.545522511005402
val acc: 0.00302734375
val rank: 125.81953125
test mean_rank: 209.592
test final_rank: 206.0
test traces_to_disclosure: nan

Epoch 6 completed.
train loss: 5.539047654512593
train acc: 0.0050891655450874835
train rank: 119.45268863559892
train weight_norm: 97.01824295569347
train grad_norm: 0.13024925203090967
train lr: 0.000992532590430281
val loss: 5.549851953983307
val acc: 0.002734375
val rank: 125.875
test mean_rank: 75.346
test final_rank: 40.0
test traces_to_disclosure: nan

Epoch 4 completed.
train loss: 5.541441386031591
train acc: 0.004931443472409152
train rank: 121.09432480933155
train weight_norm: 95.60697609024116
train grad_norm: 0.13092770129402656
train lr: 0.0009969588804891053
val loss: 5.548758971691131
val acc: 0.0041015625
val rank: 126.5775390625
test mean_rank: 78.484
test final_rank: 128.0
test traces_to_disclosure: nan

Epoch 4 completed.
train loss: 5.541441973895436
train acc: 0.004931443472409152
train rank: 121.09788056583669
train weight_norm: 95.60695560257783
train grad_norm: 0.130929673346987
train lr: 0.0009969588804891053
val loss: 5.548772037029266
val acc: 0.00400390625
val rank: 126.57919921875
test mean_rank: 78.959
test final_rank: 129.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.550, ECE: 0.001
Optimal temperature: 1.500
After temperature - NLL: 5.547, ECE: 0.001
Epoch 4 completed.
train loss: 5.5414426567416495
train acc: 0.004941958277254374
train rank: 121.09520454800358
train weight_norm: 95.57845071041301
train grad_norm: 0.13090791084595121
train lr: 0.0009969588804891053
val loss: 5.548752069473267
val acc: 0.00400390625
val rank: 126.5609375
test mean_rank: 79.037
test final_rank: 129.0
test traces_to_disclosure: nan

Epoch 5 completed.
train loss: 5.540111421094768
train acc: 0.005246887617765815
train rank: 120.09362732727679
train weight_norm: 96.24173269147529
train grad_norm: 0.1300993870405581
train lr: 0.000994989983135938
val loss: 5.546434020996093
val acc: 0.00390625
val rank: 126.05615234375
test mean_rank: 49.634
test final_rank: 4.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.550, ECE: 0.001
Optimal temperature: 1.500
After temperature - NLL: 5.547, ECE: 0.001
Epoch 6 completed.
train loss: 5.539060568905775
train acc: 0.005183798788694482
train rank: 119.45655983624945
train weight_norm: 97.06293581366216
train grad_norm: 0.13027402994963466
train lr: 0.000992532590430281
val loss: 5.5498817443847654
val acc: 0.00224609375
val rank: 125.92216796875
test mean_rank: 69.695
test final_rank: 37.0
test traces_to_disclosure: nan

Epoch 5 completed.
train loss: 5.540112318934855
train acc: 0.005246887617765815
train rank: 120.09551122981158
train weight_norm: 96.24172060358612
train grad_norm: 0.1300987443648452
train lr: 0.000994989983135938
val loss: 5.546433687210083
val acc: 0.00380859375
val rank: 126.04638671875
test mean_rank: 49.928
test final_rank: 4.0
test traces_to_disclosure: nan

Epoch 7 completed.
train loss: 5.538258876646512
train acc: 0.005341520861372813
train rank: 118.97313817855539
train weight_norm: 97.96908182690468
train grad_norm: 0.1303419352634365
train lr: 0.0009895891275220508
val loss: 5.551048886775971
val acc: 0.00302734375
val rank: 126.41650390625
test mean_rank: 87.917
test final_rank: 48.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.549, ECE: 0.001
Optimal temperature: 1.500
After temperature - NLL: 5.547, ECE: 0.001
Epoch 6 completed.
train loss: 5.5390636211770055
train acc: 0.0051627691790040375
train rank: 119.4638921601615
train weight_norm: 97.06267795176143
train grad_norm: 0.130263412663166
train lr: 0.000992532590430281
val loss: 5.549949467182159
val acc: 0.00224609375
val rank: 125.91064453125
test mean_rank: 69.269
test final_rank: 32.0
test traces_to_disclosure: nan

Epoch 4 completed.
train loss: 5.541274706736548
train acc: 0.004836810228802154
train rank: 120.96423564378647
train weight_norm: 95.59785971925355
train grad_norm: 0.13097918755603355
train lr: 0.0009969588804891053
val loss: 5.546237003803253
val acc: 0.003515625
val rank: 126.28349609375
test mean_rank: 116.714
test final_rank: 177.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.549, ECE: 0.001
Optimal temperature: 1.500
After temperature - NLL: 5.547, ECE: 0.001
Before temperature - NLL: 5.549, ECE: 0.001
Optimal temperature: 1.500
After temperature - NLL: 5.547, ECE: 0.001
Epoch 4 completed.
train loss: 5.54127408100811
train acc: 0.004826295423956932
train rank: 120.96531165881561
train weight_norm: 95.59788036571307
train grad_norm: 0.13098211659266704
train lr: 0.0009969588804891053
val loss: 5.546236431598663
val acc: 0.003515625
val rank: 126.27236328125
test mean_rank: 117.337
test final_rank: 177.0
test traces_to_disclosure: nan

Epoch 4 completed.
train loss: 5.541276304750712
train acc: 0.004831552826379542
train rank: 120.96645426760881
train weight_norm: 95.56926683766783
train grad_norm: 0.13096049838808613
train lr: 0.0009969588804891053
val loss: 5.546234571933747
val acc: 0.003515625
val rank: 126.27373046875
test mean_rank: 117.23
test final_rank: 178.0
test traces_to_disclosure: nan

Epoch 5 completed.
train loss: 5.540089761264231
train acc: 0.005231115410497981
train rank: 120.15632185116642
train weight_norm: 96.23753227586654
train grad_norm: 0.12970432263853846
train lr: 0.000994989983135938
val loss: 5.550928747653961
val acc: 0.00419921875
val rank: 127.49580078125
test mean_rank: 164.703
test final_rank: 40.0
test traces_to_disclosure: nan

Epoch 5 completed.
train loss: 5.540086507476355
train acc: 0.005246887617765815
train rank: 120.1541382766936
train weight_norm: 96.23795891535728
train grad_norm: 0.12970670842661478
train lr: 0.000994989983135938
val loss: 5.5509512543678285
val acc: 0.004296875
val rank: 127.52470703125
test mean_rank: 165.532
test final_rank: 40.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.551, ECE: 0.002
Optimal temperature: 1.500
After temperature - NLL: 5.548, ECE: 0.002
Before temperature - NLL: 5.551, ECE: 0.002
Optimal temperature: 1.500
After temperature - NLL: 5.548, ECE: 0.002
Epoch 8 completed.
train loss: 5.537320321212707
train acc: 0.0055097577388963665
train rank: 118.45354383972632
train weight_norm: 99.02904717285209
train grad_norm: 0.13071412941046484
train lr: 0.0009861624992537686
val loss: 5.554271674156189
val acc: 0.00341796875
val rank: 127.1412109375
test mean_rank: 64.597
test final_rank: 55.0
test traces_to_disclosure: nan

Epoch 7 completed.
train loss: 5.538274505096682
train acc: 0.005404609690444146
train rank: 118.9908153179677
train weight_norm: 98.02736441501145
train grad_norm: 0.13033402353222992
train lr: 0.0009895891275220508
val loss: 5.550811433792115
val acc: 0.0029296875
val rank: 126.48251953125
test mean_rank: 87.72
test final_rank: 56.0
test traces_to_disclosure: nan

Epoch 5 completed.
train loss: 5.540089304963801
train acc: 0.005210085800807537
train rank: 120.15571374495289
train weight_norm: 96.20085978745972
train grad_norm: 0.1296830956449709
train lr: 0.000994989983135938
val loss: 5.550978147983551
val acc: 0.0044921875
val rank: 127.5623046875
test mean_rank: 162.729
test final_rank: 38.0
test traces_to_disclosure: nan

Epoch 7 completed.
train loss: 5.53828317673017
train acc: 0.005362550471063257
train rank: 118.98832681415432
train weight_norm: 98.02763111833158
train grad_norm: 0.13034264122269978
train lr: 0.0009895891275220508
val loss: 5.550885236263275
val acc: 0.00263671875
val rank: 126.38466796875
test mean_rank: 87.748
test final_rank: 47.0
test traces_to_disclosure: nan

Epoch 6 completed.
train loss: 5.539215931180027
train acc: 0.0052206006056527594
train rank: 119.62141795648272
train weight_norm: 97.0702570054237
train grad_norm: 0.1301240553003777
train lr: 0.000992532590430281
val loss: 5.547406232357025
val acc: 0.0029296875
val rank: 126.76552734375
test mean_rank: 150.524
test final_rank: 93.0
test traces_to_disclosure: nan

Epoch 6 completed.
train loss: 5.539212157556218
train acc: 0.00527317462987887
train rank: 119.61555420031405
train weight_norm: 97.0703313515588
train grad_norm: 0.13012046450068493
train lr: 0.000992532590430281
val loss: 5.54739910364151
val acc: 0.0029296875
val rank: 126.73095703125
test mean_rank: 148.999
test final_rank: 90.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.550, ECE: 0.001
Optimal temperature: 1.500
After temperature - NLL: 5.547, ECE: 0.000
Epoch 5 completed.
train loss: 5.5400444200189725
train acc: 0.005252145020188425
train rank: 120.05093897207267
train weight_norm: 96.23688775883953
train grad_norm: 0.12986508475409278
train lr: 0.000994989983135938
val loss: 5.546667325496673
val acc: 0.00390625
val rank: 126.3640625
test mean_rank: 48.242
test final_rank: 2.0
test traces_to_disclosure: nan

Epoch 9 completed.
train loss: 5.536415739945094
train acc: 0.0054098670928667564
train rank: 117.9583280759309
train weight_norm: 100.2106254329747
train grad_norm: 0.13281049363018807
train lr: 0.0009822560872938316
val loss: 5.551703953742981
val acc: 0.0037109375
val rank: 126.8927734375
test mean_rank: 205.821
test final_rank: 235.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.550, ECE: 0.001
Optimal temperature: 1.500
After temperature - NLL: 5.547, ECE: 0.001
Before temperature - NLL: 5.550, ECE: 0.001
Optimal temperature: 1.500
After temperature - NLL: 5.547, ECE: 0.000
Before temperature - NLL: 5.550, ECE: 0.001
Optimal temperature: 1.500
After temperature - NLL: 5.547, ECE: 0.001
Before temperature - NLL: 5.550, ECE: 0.000
Optimal temperature: 1.500
After temperature - NLL: 5.547, ECE: 0.000
Epoch 8 completed.
train loss: 5.537254159575677
train acc: 0.005493985531628533
train rank: 118.44206342530282
train weight_norm: 99.09129104851522
train grad_norm: 0.13074798680573294
train lr: 0.0009861624992537686
val loss: 5.554242849349976
val acc: 0.003515625
val rank: 127.04423828125
test mean_rank: 46.201
test final_rank: 45.0
test traces_to_disclosure: nan

Epoch 5 completed.
train loss: 5.540046810622491
train acc: 0.005246887617765815
train rank: 120.05303317070437
train weight_norm: 96.23723846913356
train grad_norm: 0.129860699021413
train lr: 0.000994989983135938
val loss: 5.546618640422821
val acc: 0.0037109375
val rank: 126.33037109375
test mean_rank: 47.384
test final_rank: 2.0
test traces_to_disclosure: nan

Epoch 8 completed.
train loss: 5.537322196472702
train acc: 0.005520272543741588
train rank: 118.47372876009422
train weight_norm: 99.09807831084099
train grad_norm: 0.130825661536471
train lr: 0.0009861624992537686
val loss: 5.5540907144546505
val acc: 0.00341796875
val rank: 127.1056640625
test mean_rank: 50.726
test final_rank: 48.0
test traces_to_disclosure: nan

Epoch 6 completed.
train loss: 5.538960359940458
train acc: 0.005083908142664872
train rank: 119.41192624214894
train weight_norm: 97.05174769111646
train grad_norm: 0.12968857152509375
train lr: 0.000992532590430281
val loss: 5.549751138687133
val acc: 0.002734375
val rank: 125.78310546875
test mean_rank: 78.598
test final_rank: 45.0
test traces_to_disclosure: nan

Epoch 6 completed.
train loss: 5.538963346109095
train acc: 0.005189056191117093
train rank: 119.40846862382234
train weight_norm: 97.05093167435221
train grad_norm: 0.12976234502927314
train lr: 0.000992532590430281
val loss: 5.550044155120849
val acc: 0.00302734375
val rank: 126.00771484375
test mean_rank: 82.689
test final_rank: 50.0
test traces_to_disclosure: nan

Epoch 7 completed.
train loss: 5.5383282875790085
train acc: 0.00561140085240018
train rank: 119.0345323715792
train weight_norm: 98.03871427052465
train grad_norm: 0.13018004820658863
train lr: 0.0009895891275220508
val loss: 5.5466023802757265
val acc: 0.00458984375
val rank: 125.96171875
test mean_rank: 88.124
test final_rank: 82.0
test traces_to_disclosure: nan

Epoch 5 completed.
train loss: 5.5400530107890935
train acc: 0.005257402422611036
train rank: 120.06013592137731
train weight_norm: 96.20065292153366
train grad_norm: 0.12986869988228888
train lr: 0.000994989983135938
val loss: 5.546674156188965
val acc: 0.00380859375
val rank: 126.37578125
test mean_rank: 49.27
test final_rank: 2.0
test traces_to_disclosure: nan

Epoch 7 completed.
train loss: 5.538302438255916
train acc: 0.005546559555854643
train rank: 119.01238819257516
train weight_norm: 98.03804073020828
train grad_norm: 0.1301777562421074
train lr: 0.0009895891275220508
val loss: 5.546559166908264
val acc: 0.0046875
val rank: 125.8470703125
test mean_rank: 85.033
test final_rank: 73.0
test traces_to_disclosure: nan

Epoch 6 completed.
train loss: 5.538985328109557
train acc: 0.005215343203230148
train rank: 119.4313190472185
train weight_norm: 97.00791070036345
train grad_norm: 0.12964898410792527
train lr: 0.000992532590430281
val loss: 5.549767792224884
val acc: 0.0029296875
val rank: 125.909765625
test mean_rank: 75.474
test final_rank: 33.0
test traces_to_disclosure: nan

Epoch 10 completed.
train loss: 5.535342227401836
train acc: 0.005388837483176312
train rank: 117.42999242934052
train weight_norm: 101.45398047884457
train grad_norm: 0.1342864157183694
train lr: 0.0009778737467992208
val loss: 5.552857112884522
val acc: 0.00390625
val rank: 126.623828125
test mean_rank: 69.181
test final_rank: 83.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.552, ECE: 0.003
Optimal temperature: 1.500
After temperature - NLL: 5.548, ECE: 0.002
Epoch 6 completed.
train loss: 5.539121933291449
train acc: 0.005231115410497981
train rank: 119.57234185733513
train weight_norm: 97.0748653747103
train grad_norm: 0.13008532162011155
train lr: 0.000992532590430281
val loss: 5.547696602344513
val acc: 0.00263671875
val rank: 126.9142578125
test mean_rank: 151.385
test final_rank: 121.0
test traces_to_disclosure: nan

Epoch 9 completed.
train loss: 5.536411056287516
train acc: 0.005367807873485868
train rank: 117.93948028824583
train weight_norm: 100.27557747820043
train grad_norm: 0.1329541429117204
train lr: 0.0009822560872938316
val loss: 5.551867055892944
val acc: 0.00380859375
val rank: 126.8302734375
test mean_rank: 197.938
test final_rank: 223.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.552, ECE: 0.002
Optimal temperature: 1.501
After temperature - NLL: 5.548, ECE: 0.001
Epoch 9 completed.
train loss: 5.536458302314316
train acc: 0.005315233849259758
train rank: 117.97076533759535
train weight_norm: 100.2879530087424
train grad_norm: 0.13272358559547284
train lr: 0.0009822560872938316
val loss: 5.551780164241791
val acc: 0.00361328125
val rank: 126.8990234375
test mean_rank: 186.64
test final_rank: 219.0
test traces_to_disclosure: nan

Epoch 8 completed.
train loss: 5.537222285289944
train acc: 0.005257402422611036
train rank: 118.43402310453116
train weight_norm: 99.11508032710007
train grad_norm: 0.13137380768032578
train lr: 0.0009861624992537686
val loss: 5.547688579559326
val acc: 0.00380859375
val rank: 126.67998046875
test mean_rank: 175.792
test final_rank: 245.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.552, ECE: 0.001
Optimal temperature: 1.500
After temperature - NLL: 5.548, ECE: 0.001
Epoch 11 completed.
train loss: 5.5344996638445645
train acc: 0.005462441117092867
train rank: 116.99153908703452
train weight_norm: 102.77495851220183
train grad_norm: 0.1363858864785489
train lr: 0.0009730198026109122
val loss: 5.553035318851471
val acc: 0.0033203125
val rank: 125.9638671875
test mean_rank: 174.918
test final_rank: 208.0
test traces_to_disclosure: nan

Epoch 7 completed.
train loss: 5.5382548090907795
train acc: 0.005472955921938089
train rank: 118.9734641375056
train weight_norm: 98.0226807899322
train grad_norm: 0.13011706402760062
train lr: 0.0009895891275220508
val loss: 5.551099359989166
val acc: 0.00263671875
val rank: 126.65048828125
test mean_rank: 78.592
test final_rank: 30.0
test traces_to_disclosure: nan

Epoch 7 completed.
train loss: 5.538206653030211
train acc: 0.00532574865410498
train rank: 118.92404104979812
train weight_norm: 98.02361020070923
train grad_norm: 0.13014234540381187
train lr: 0.0009895891275220508
val loss: 5.551291763782501
val acc: 0.002734375
val rank: 126.64765625
test mean_rank: 67.857
test final_rank: 22.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.552, ECE: 0.002
Optimal temperature: 1.500
After temperature - NLL: 5.548, ECE: 0.002
Epoch 8 completed.
train loss: 5.537240506502052
train acc: 0.005331006056527591
train rank: 118.44926431415432
train weight_norm: 99.112903502953
train grad_norm: 0.13135971374446004
train lr: 0.0009861624992537686
val loss: 5.5476695656776425
val acc: 0.004296875
val rank: 126.66396484375
test mean_rank: 168.955
test final_rank: 244.0
test traces_to_disclosure: nan

Epoch 7 completed.
train loss: 5.538246778588276
train acc: 0.0053940948855989235
train rank: 118.9669361961642
train weight_norm: 97.96973022087548
train grad_norm: 0.1300085874182716
train lr: 0.0009895891275220508
val loss: 5.550981271266937
val acc: 0.00244140625
val rank: 126.62919921875
test mean_rank: 79.693
test final_rank: 24.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.552, ECE: 0.002
Optimal temperature: 1.500
After temperature - NLL: 5.548, ECE: 0.002
Epoch 6 completed.
train loss: 5.539130304575287
train acc: 0.00512596736204576
train rank: 119.57297449809333
train weight_norm: 97.07414253793172
train grad_norm: 0.13015046666078564
train lr: 0.000992532590430281
val loss: 5.547600960731506
val acc: 0.002734375
val rank: 126.84150390625
test mean_rank: 148.878
test final_rank: 125.0
test traces_to_disclosure: nan

Epoch 6 completed.
train loss: 5.539132539869799
train acc: 0.0051469969717362046
train rank: 119.57990375448632
train weight_norm: 97.03065786133331
train grad_norm: 0.13005789623610847
train lr: 0.000992532590430281
val loss: 5.547742283344268
val acc: 0.00244140625
val rank: 126.96279296875
test mean_rank: 147.463
test final_rank: 125.0
test traces_to_disclosure: nan

Epoch 10 completed.
train loss: 5.5353639834982875
train acc: 0.005425639300134589
train rank: 117.43942771422161
train weight_norm: 101.53776729458791
train grad_norm: 0.13431877069387158
train lr: 0.0009778737467992208
val loss: 5.552969753742218
val acc: 0.00390625
val rank: 126.7171875
test mean_rank: 57.79
test final_rank: 89.0
test traces_to_disclosure: nan

Epoch 10 completed.
train loss: 5.535264379082907
train acc: 0.0054098670928667564
train rank: 117.3685123654105
train weight_norm: 101.54668293341207
train grad_norm: 0.13473603524030542
train lr: 0.0009778737467992208
val loss: 5.5535242557525635
val acc: 0.00439453125
val rank: 126.9064453125
test mean_rank: 55.497
test final_rank: 61.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.550, ECE: 0.001
Optimal temperature: 1.500
After temperature - NLL: 5.547, ECE: 0.000
Before temperature - NLL: 5.553, ECE: 0.001
Optimal temperature: 1.501
After temperature - NLL: 5.548, ECE: 0.001
Epoch 7 completed.
train loss: 5.538325211562186
train acc: 0.0055255299461641995
train rank: 119.00794218259308
train weight_norm: 98.0458030133295
train grad_norm: 0.13009448612850885
train lr: 0.0009895891275220508
val loss: 5.546788084506988
val acc: 0.00498046875
val rank: 126.15361328125
test mean_rank: 94.107
test final_rank: 81.0
test traces_to_disclosure: nan

Epoch 12 completed.
train loss: 5.533302398260638
train acc: 0.005562331763122476
train rank: 116.36749943921042
train weight_norm: 104.10608114619919
train grad_norm: 0.13924308521671858
train lr: 0.0009676990449858007
val loss: 5.557669448852539
val acc: 0.00341796875
val rank: 127.141796875
test mean_rank: 179.33
test final_rank: 139.0
test traces_to_disclosure: nan

Epoch 9 completed.
train loss: 5.536412158853112
train acc: 0.005436154104979812
train rank: 117.968003448856
train weight_norm: 100.26194105561665
train grad_norm: 0.13232675589201476
train lr: 0.0009822560872938316
val loss: 5.5480224847793576
val acc: 0.0037109375
val rank: 126.68076171875
test mean_rank: 23.992
test final_rank: 13.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.553, ECE: 0.002
Optimal temperature: 1.500
After temperature - NLL: 5.548, ECE: 0.001
Epoch 9 completed.
train loss: 5.536489424442379
train acc: 0.005541302153432032
train rank: 118.00466331594886
train weight_norm: 100.25962970831007
train grad_norm: 0.13223284711326144
train lr: 0.0009822560872938316
val loss: 5.548025238513946
val acc: 0.00380859375
val rank: 126.6666015625
test mean_rank: 26.904
test final_rank: 14.0
test traces_to_disclosure: 344.0

Epoch 8 completed.
train loss: 5.537272522619563
train acc: 0.005504500336473755
train rank: 118.44473068079857
train weight_norm: 99.03211751044904
train grad_norm: 0.1303322910638835
train lr: 0.0009861624992537686
val loss: 5.554201769828796
val acc: 0.00390625
val rank: 127.07353515625
test mean_rank: 66.03
test final_rank: 58.0
test traces_to_disclosure: nan

Epoch 8 completed.
train loss: 5.537238293669587
train acc: 0.005388837483176312
train rank: 118.4271464221624
train weight_norm: 99.09805784650429
train grad_norm: 0.13045849504317933
train lr: 0.0009861624992537686
val loss: 5.553654944896698
val acc: 0.0041015625
val rank: 126.87255859375
test mean_rank: 69.076
test final_rank: 74.0
test traces_to_disclosure: nan

Epoch 8 completed.
train loss: 5.537256805604753
train acc: 0.005446668909825034
train rank: 118.42615978297442
train weight_norm: 99.08930540277883
train grad_norm: 0.1304565500287791
train lr: 0.0009861624992537686
val loss: 5.554136800765991
val acc: 0.003515625
val rank: 126.98583984375
test mean_rank: 67.796
test final_rank: 73.0
test traces_to_disclosure: nan

Epoch 11 completed.
train loss: 5.534388743691939
train acc: 0.005451926312247645
train rank: 116.9177374242934
train weight_norm: 102.88379249861264
train grad_norm: 0.1366856394307632
train lr: 0.0009730198026109122
val loss: 5.55326498746872
val acc: 0.002734375
val rank: 126.2548828125
test mean_rank: 174.158
test final_rank: 211.0
test traces_to_disclosure: nan

Epoch 11 completed.
train loss: 5.53449872942343
train acc: 0.005441411507402422
train rank: 116.98175155619111
train weight_norm: 102.87541681792233
train grad_norm: 0.13638490506136244
train lr: 0.0009730198026109122
val loss: 5.553110885620117
val acc: 0.0037109375
val rank: 126.08125
test mean_rank: 170.576
test final_rank: 204.0
test traces_to_disclosure: nan

Epoch 13 completed.
train loss: 5.531945464749034
train acc: 0.005735826043068641
train rank: 115.8049258355765
train weight_norm: 105.48928277958395
train grad_norm: 0.14277076045257675
train lr: 0.0009619167248692779
val loss: 5.55477294921875
val acc: 0.00458984375
val rank: 126.07919921875
test mean_rank: 59.449
test final_rank: 11.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.550, ECE: 0.001
Optimal temperature: 1.500
After temperature - NLL: 5.547, ECE: 0.000
Before temperature - NLL: 5.550, ECE: 0.001
Optimal temperature: 1.500
After temperature - NLL: 5.547, ECE: 0.000
Epoch 7 completed.
train loss: 5.538303353423867
train acc: 0.005569341633019292
train rank: 119.00659453510544
train weight_norm: 98.04006405236916
train grad_norm: 0.12998552744108066
train lr: 0.0009895891275220508
val loss: 5.546759617328644
val acc: 0.00458984375
val rank: 126.22294921875
test mean_rank: 90.432
test final_rank: 70.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.555, ECE: 0.002
Optimal temperature: 1.501
After temperature - NLL: 5.550, ECE: 0.002
Before temperature - NLL: 5.555, ECE: 0.002
Optimal temperature: 1.501
After temperature - NLL: 5.549, ECE: 0.001
Epoch 7 completed.
train loss: 5.5383164102906015
train acc: 0.005557074360699865
train rank: 119.00702388963661
train weight_norm: 97.98816053119972
train grad_norm: 0.12992202247919302
train lr: 0.0009895891275220508
val loss: 5.546731281280517
val acc: 0.00458984375
val rank: 126.11728515625
test mean_rank: 90.614
test final_rank: 96.0
test traces_to_disclosure: nan

Epoch 10 completed.
train loss: 5.53567546212978
train acc: 0.0054676985195154775
train rank: 117.4661686154105
train weight_norm: 101.49570892783905
train grad_norm: 0.13369162970695248
train lr: 0.0009778737467992208
val loss: 5.5487612128257755
val acc: 0.003515625
val rank: 126.73125
test mean_rank: 121.628
test final_rank: 82.0
test traces_to_disclosure: nan

Epoch 10 completed.
train loss: 5.535614369213982
train acc: 0.0055255299461641995
train rank: 117.43659923171825
train weight_norm: 101.48602614320448
train grad_norm: 0.1336220915620848
train lr: 0.0009778737467992208
val loss: 5.548599410057068
val acc: 0.0033203125
val rank: 126.570703125
test mean_rank: 125.906
test final_rank: 86.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.553, ECE: 0.001
Optimal temperature: 1.500
After temperature - NLL: 5.548, ECE: 0.000
Epoch 12 completed.
train loss: 5.533434509107916
train acc: 0.00563067799461642
train rank: 116.44781327108568
train weight_norm: 104.22508591273721
train grad_norm: 0.13917403706328998
train lr: 0.0009676990449858007
val loss: 5.557237923145294
val acc: 0.003515625
val rank: 126.99375
test mean_rank: 182.641
test final_rank: 128.0
test traces_to_disclosure: nan

Epoch 8 completed.
train loss: 5.537144395255786
train acc: 0.005283689434724091
train rank: 118.40749775684165
train weight_norm: 99.12138731543705
train grad_norm: 0.13107615816037663
train lr: 0.0009861624992537686
val loss: 5.547743546962738
val acc: 0.00458984375
val rank: 126.60673828125
test mean_rank: 164.89
test final_rank: 238.0
test traces_to_disclosure: nan

Epoch 12 completed.
train loss: 5.533300216233265
train acc: 0.005567589165545088
train rank: 116.38776847801704
train weight_norm: 104.22526482590307
train grad_norm: 0.13956884576632553
train lr: 0.0009676990449858007
val loss: 5.557327330112457
val acc: 0.0033203125
val rank: 126.98701171875
test mean_rank: 149.665
test final_rank: 101.0
test traces_to_disclosure: nan

Epoch 14 completed.
train loss: 5.530574923729672
train acc: 0.005793657469717362
train rank: 115.19724897655901
train weight_norm: 106.88998142053084
train grad_norm: 0.14616411564162002
train lr: 0.000955678548713192
val loss: 5.556141877174378
val acc: 0.0033203125
val rank: 126.4625
test mean_rank: 158.195
test final_rank: 68.0
test traces_to_disclosure: nan

Epoch 9 completed.
train loss: 5.536406721754318
train acc: 0.005404609690444146
train rank: 117.97906327108568
train weight_norm: 100.22027410170328
train grad_norm: 0.1322657953636411
train lr: 0.0009822560872938316
val loss: 5.551449584960937
val acc: 0.00380859375
val rank: 126.59345703125
test mean_rank: 210.994
test final_rank: 239.0
test traces_to_disclosure: nan

Epoch 9 completed.
train loss: 5.536383135321965
train acc: 0.005252145020188425
train rank: 117.94857208950202
train weight_norm: 100.29369700079769
train grad_norm: 0.13243458332880645
train lr: 0.0009822560872938316
val loss: 5.55195449590683
val acc: 0.00439453125
val rank: 126.99482421875
test mean_rank: 207.482
test final_rank: 237.0
test traces_to_disclosure: nan

Epoch 9 completed.
train loss: 5.536343545002379
train acc: 0.0053940948855989235
train rank: 117.92262505607894
train weight_norm: 100.28476727918807
train grad_norm: 0.13242134466284677
train lr: 0.0009822560872938316
val loss: 5.551855885982514
val acc: 0.00361328125
val rank: 126.876953125
test mean_rank: 197.741
test final_rank: 231.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.555, ECE: 0.002
Optimal temperature: 1.501
After temperature - NLL: 5.550, ECE: 0.001
Epoch 11 completed.
train loss: 5.534548384665159
train acc: 0.005604390982503365
train rank: 116.99208410441904
train weight_norm: 102.81918752845867
train grad_norm: 0.13637081224439604
train lr: 0.0009730198026109122
val loss: 5.548718786239624
val acc: 0.0037109375
val rank: 126.7775390625
test mean_rank: 221.441
test final_rank: 254.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.553, ECE: 0.001
Optimal temperature: 1.500
After temperature - NLL: 5.548, ECE: 0.000
Epoch 8 completed.
train loss: 5.537153416013654
train acc: 0.005352035666218035
train rank: 118.42880250392551
train weight_norm: 99.1067580212175
train grad_norm: 0.13107032699231852
train lr: 0.0009861624992537686
val loss: 5.54781858921051
val acc: 0.0048828125
val rank: 126.78515625
test mean_rank: 165.445
test final_rank: 242.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.555, ECE: 0.002
Optimal temperature: 1.501
After temperature - NLL: 5.549, ECE: 0.001
Epoch 15 completed.
train loss: 5.529099095397169
train acc: 0.006124873822341857
train rank: 114.61056667788245
train weight_norm: 108.30314128099106
train grad_norm: 0.1510109708103165
train lr: 0.0009489906728442636
val loss: 5.559419083595276
val acc: 0.0033203125
val rank: 126.69775390625
test mean_rank: 212.692
test final_rank: 118.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.553, ECE: 0.001
Optimal temperature: 1.501
After temperature - NLL: 5.548, ECE: 0.000
Epoch 13 completed.
train loss: 5.532001684042519
train acc: 0.005499242934051144
train rank: 115.83068360251232
train weight_norm: 105.60846152336119
train grad_norm: 0.14235667374168093
train lr: 0.0009619167248692779
val loss: 5.55478469133377
val acc: 0.00419921875
val rank: 126.171875
test mean_rank: 59.439
test final_rank: 16.0
test traces_to_disclosure: nan

Epoch 13 completed.
train loss: 5.531917948742093
train acc: 0.005493985531628533
train rank: 115.79878343707941
train weight_norm: 105.61192064292116
train grad_norm: 0.1427581876092383
train lr: 0.0009619167248692779
val loss: 5.555124628543854
val acc: 0.00439453125
val rank: 126.145703125
test mean_rank: 70.755
test final_rank: 18.0
test traces_to_disclosure: nan

Epoch 11 completed.
train loss: 5.534515392411285
train acc: 0.005667479811574697
train rank: 116.99942519066845
train weight_norm: 102.80440148168832
train grad_norm: 0.13619712584052573
train lr: 0.0009730198026109122
val loss: 5.5483372688293455
val acc: 0.00400390625
val rank: 126.492578125
test mean_rank: 223.105
test final_rank: 254.0
test traces_to_disclosure: nan

Epoch 8 completed.
train loss: 5.537190378273801
train acc: 0.0052784320323014805
train rank: 118.42686252243158
train weight_norm: 99.04970623561043
train grad_norm: 0.13116738260070912
train lr: 0.0009861624992537686
val loss: 5.547803544998169
val acc: 0.00478515625
val rank: 126.6876953125
test mean_rank: 168.71
test final_rank: 246.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.553, ECE: 0.001
Optimal temperature: 1.500
After temperature - NLL: 5.549, ECE: 0.001
Epoch 9 completed.
train loss: 5.536369586857299
train acc: 0.005488728129205922
train rank: 117.92997315219831
train weight_norm: 100.28890543239264
train grad_norm: 0.13224584527468322
train lr: 0.0009822560872938316
val loss: 5.548165106773377
val acc: 0.00380859375
val rank: 126.71396484375
test mean_rank: 24.911
test final_rank: 22.0
test traces_to_disclosure: 341.0

Before temperature - NLL: 5.557, ECE: 0.001
Optimal temperature: 1.502
After temperature - NLL: 5.550, ECE: 0.001
Epoch 10 completed.
train loss: 5.535380906404107
train acc: 0.00557810397039031
train rank: 117.4657953398385
train weight_norm: 101.47117123229383
train grad_norm: 0.13397425440468302
train lr: 0.0009778737467992208
val loss: 5.5527496337890625
val acc: 0.0048828125
val rank: 126.54560546875
test mean_rank: 55.711
test final_rank: 70.0
test traces_to_disclosure: nan

Epoch 10 completed.
train loss: 5.535333125138829
train acc: 0.005483470726783311
train rank: 117.436040194594
train weight_norm: 101.53504847932642
train grad_norm: 0.1339448600864701
train lr: 0.0009778737467992208
val loss: 5.552421355247498
val acc: 0.00439453125
val rank: 126.53564453125
test mean_rank: 53.133
test final_rank: 63.0
test traces_to_disclosure: nan

Epoch 12 completed.
train loss: 5.533325489244422
train acc: 0.005683252018842531
train rank: 116.38321907245403
train weight_norm: 104.17782387723425
train grad_norm: 0.1385947325353959
train lr: 0.0009676990449858007
val loss: 5.548896741867066
val acc: 0.00439453125
val rank: 126.18916015625
test mean_rank: 206.326
test final_rank: 239.0
test traces_to_disclosure: nan

Epoch 10 completed.
train loss: 5.5352306770283635
train acc: 0.005441411507402422
train rank: 117.3693956090175
train weight_norm: 101.55509616641515
train grad_norm: 0.13401778832912623
train lr: 0.0009778737467992208
val loss: 5.552640795707703
val acc: 0.0044921875
val rank: 126.5779296875
test mean_rank: 57.015
test final_rank: 57.0
test traces_to_disclosure: nan

Epoch 16 completed.
train loss: 5.527244469679862
train acc: 0.00618796265141319
train rank: 113.88709027310452
train weight_norm: 109.72602160981931
train grad_norm: 0.15812986394618705
train lr: 0.0009418596973885387
val loss: 5.557157719135285
val acc: 0.00361328125
val rank: 125.88505859375
test mean_rank: 129.747
test final_rank: 209.0
test traces_to_disclosure: nan

Epoch 14 completed.
train loss: 5.5305918671722205
train acc: 0.005656965006729475
train rank: 115.22553029665768
train weight_norm: 107.00762557598719
train grad_norm: 0.14624420469939778
train lr: 0.000955678548713192
val loss: 5.55628582239151
val acc: 0.0033203125
val rank: 126.52099609375
test mean_rank: 150.508
test final_rank: 68.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.553, ECE: 0.001
Optimal temperature: 1.501
After temperature - NLL: 5.549, ECE: 0.000
Epoch 14 completed.
train loss: 5.53073788395159
train acc: 0.005730568640646029
train rank: 115.26868130327503
train weight_norm: 107.01798766473794
train grad_norm: 0.1457125629185351
train lr: 0.000955678548713192
val loss: 5.556107771396637
val acc: 0.00400390625
val rank: 126.5390625
test mean_rank: 151.842
test final_rank: 60.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.557, ECE: 0.001
Optimal temperature: 1.501
After temperature - NLL: 5.550, ECE: 0.000
Epoch 9 completed.
train loss: 5.536355059689179
train acc: 0.00557810397039031
train rank: 117.93975367317181
train weight_norm: 100.2630912675938
train grad_norm: 0.13206068151798692
train lr: 0.0009822560872938316
val loss: 5.548188161849976
val acc: 0.004296875
val rank: 126.80380859375
test mean_rank: 24.378
test final_rank: 17.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.553, ECE: 0.001
Optimal temperature: 1.501
After temperature - NLL: 5.548, ECE: 0.001
Epoch 12 completed.
train loss: 5.5333851394550635
train acc: 0.005867261103633917
train rank: 116.39948722801704
train weight_norm: 104.16933399015963
train grad_norm: 0.13863400755841734
train lr: 0.0009676990449858007
val loss: 5.548737442493438
val acc: 0.00419921875
val rank: 126.126953125
test mean_rank: 210.162
test final_rank: 244.0
test traces_to_disclosure: nan

Epoch 9 completed.
train loss: 5.536335121093175
train acc: 0.005557074360699865
train rank: 117.92763185565276
train weight_norm: 100.20945760320724
train grad_norm: 0.1321477909038638
train lr: 0.0009822560872938316
val loss: 5.548023891448975
val acc: 0.00400390625
val rank: 126.68134765625
test mean_rank: 27.937
test final_rank: 19.0
test traces_to_disclosure: 341.0

Before temperature - NLL: 5.554, ECE: 0.002
Optimal temperature: 1.500
After temperature - NLL: 5.549, ECE: 0.001
Epoch 17 completed.
train loss: 5.524941270476556
train acc: 0.0063088829071332436
train rank: 113.06731052321669
train weight_norm: 111.14822963362526
train grad_norm: 0.16569709258354898
train lr: 0.0009342926597578587
val loss: 5.5618508696556095
val acc: 0.0037109375
val rank: 126.85673828125
test mean_rank: 247.463
test final_rank: 235.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.558, ECE: 0.002
Optimal temperature: 1.760
After temperature - NLL: 5.549, ECE: 0.001
Epoch 15 completed.
train loss: 5.529227173344444
train acc: 0.005914577725437416
train rank: 114.67564280506953
train weight_norm: 108.42561878781005
train grad_norm: 0.15049914758657132
train lr: 0.0009489906728442636
val loss: 5.559875583648681
val acc: 0.00283203125
val rank: 126.76533203125
test mean_rank: 228.07
test final_rank: 163.0
test traces_to_disclosure: nan

Epoch 10 completed.
train loss: 5.5355698231251695
train acc: 0.005593876177658143
train rank: 117.42393414928218
train weight_norm: 101.52464558131189
train grad_norm: 0.13341422611398965
train lr: 0.0009778737467992208
val loss: 5.5485623478889465
val acc: 0.00419921875
val rank: 126.69345703125
test mean_rank: 139.22
test final_rank: 97.0
test traces_to_disclosure: nan

Epoch 15 completed.
train loss: 5.529061339264121
train acc: 0.006056527590847914
train rank: 114.60388101446837
train weight_norm: 108.40472230459137
train grad_norm: 0.1508764622575322
train lr: 0.0009489906728442636
val loss: 5.559296500682831
val acc: 0.0029296875
val rank: 126.51923828125
test mean_rank: 221.32
test final_rank: 147.0
test traces_to_disclosure: nan

Epoch 13 completed.
train loss: 5.5321599432789945
train acc: 0.005614905787348586
train rank: 115.98135199360699
train weight_norm: 105.55801077193266
train grad_norm: 0.14223252380030693
train lr: 0.0009619167248692779
val loss: 5.548674714565277
val acc: 0.00380859375
val rank: 126.6572265625
test mean_rank: 189.198
test final_rank: 101.0
test traces_to_disclosure: nan

Epoch 11 completed.
train loss: 5.53448764536615
train acc: 0.005562331763122476
train rank: 116.98100850998205
train weight_norm: 102.80236200436478
train grad_norm: 0.13595432450655937
train lr: 0.0009730198026109122
val loss: 5.552218103408814
val acc: 0.00322265625
val rank: 125.6625
test mean_rank: 179.75
test final_rank: 221.0
test traces_to_disclosure: nan

Epoch 11 completed.
train loss: 5.534483636211739
train acc: 0.005378322678331091
train rank: 116.97321528712429
train weight_norm: 102.86365062055695
train grad_norm: 0.1359017424323084
train lr: 0.0009730198026109122
val loss: 5.552314364910126
val acc: 0.00341796875
val rank: 125.81240234375
test mean_rank: 159.291
test final_rank: 194.0
test traces_to_disclosure: nan

Epoch 11 completed.
train loss: 5.534443248168617
train acc: 0.005441411507402422
train rank: 116.94254885879319
train weight_norm: 102.88293273536054
train grad_norm: 0.13590419350626762
train lr: 0.0009730198026109122
val loss: 5.5522074699401855
val acc: 0.003125
val rank: 125.65439453125
test mean_rank: 172.142
test final_rank: 211.0
test traces_to_disclosure: nan

Epoch 18 completed.
train loss: 5.522616203508338
train acc: 0.006682158479138627
train rank: 112.27518646253924
train weight_norm: 112.59086547121935
train grad_norm: 0.17781370120489753
train lr: 0.0009262970277047872
val loss: 5.5646943092346195
val acc: 0.0037109375
val rank: 126.53369140625
test mean_rank: 198.761
test final_rank: 184.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.558, ECE: 0.002
Optimal temperature: 1.501
After temperature - NLL: 5.551, ECE: 0.001
Epoch 13 completed.
train loss: 5.5321984413013485
train acc: 0.006009210969044414
train rank: 115.98772046040827
train weight_norm: 105.55848378761581
train grad_norm: 0.14223165757774567
train lr: 0.0009619167248692779
val loss: 5.550059306621551
val acc: 0.0037109375
val rank: 126.7083984375
test mean_rank: 195.574
test final_rank: 122.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.554, ECE: 0.001
Optimal temperature: 1.501
After temperature - NLL: 5.549, ECE: 0.001
Epoch 16 completed.
train loss: 5.527541676568792
train acc: 0.006266823687752355
train rank: 114.03967060621353
train weight_norm: 109.85442739590655
train grad_norm: 0.15670223835412952
train lr: 0.0009418596973885387
val loss: 5.555798149108886
val acc: 0.0033203125
val rank: 125.7587890625
test mean_rank: 94.723
test final_rank: 176.0
test traces_to_disclosure: nan

Epoch 10 completed.
train loss: 5.535545055830944
train acc: 0.005493985531628533
train rank: 117.4196476138403
train weight_norm: 101.4971256764522
train grad_norm: 0.1334664639664968
train lr: 0.0009778737467992208
val loss: 5.548458778858185
val acc: 0.00439453125
val rank: 126.424609375
test mean_rank: 159.967
test final_rank: 115.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.554, ECE: 0.002
Optimal temperature: 1.501
After temperature - NLL: 5.549, ECE: 0.001
Epoch 10 completed.
train loss: 5.53558569159835
train acc: 0.005551816958277255
train rank: 117.43734227792733
train weight_norm: 101.44147035984166
train grad_norm: 0.13337980056522633
train lr: 0.0009778737467992208
val loss: 5.548538935184479
val acc: 0.00439453125
val rank: 126.5787109375
test mean_rank: 164.336
test final_rank: 123.0
test traces_to_disclosure: nan

Epoch 16 completed.
train loss: 5.527307509734204
train acc: 0.006230021870794078
train rank: 113.93386538245849
train weight_norm: 109.82978603348528
train grad_norm: 0.1573484846078172
train lr: 0.0009418596973885387
val loss: 5.556254756450653
val acc: 0.00341796875
val rank: 125.73369140625
test mean_rank: 109.254
test final_rank: 175.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.555, ECE: 0.002
Optimal temperature: 1.500
After temperature - NLL: 5.550, ECE: 0.001
Before temperature - NLL: 5.557, ECE: 0.002
Optimal temperature: 1.501
After temperature - NLL: 5.550, ECE: 0.001
Before temperature - NLL: 5.557, ECE: 0.002
Optimal temperature: 1.760
After temperature - NLL: 5.549, ECE: 0.001
Epoch 19 completed.
train loss: 5.51916580277208
train acc: 0.006829365746971737
train rank: 111.14580879878869
train weight_norm: 114.08466532059371
train grad_norm: 0.19603212368208597
train lr: 0.000917880691952835
val loss: 5.566845035552978
val acc: 0.00498046875
val rank: 126.9607421875
test mean_rank: 98.498
test final_rank: 112.0
test traces_to_disclosure: nan

Epoch 12 completed.
train loss: 5.533375990342645
train acc: 0.005614905787348586
train rank: 116.40061231213548
train weight_norm: 104.21019202555419
train grad_norm: 0.13877070513090692
train lr: 0.0009676990449858007
val loss: 5.557060599327087
val acc: 0.00283203125
val rank: 127.05
test mean_rank: 173.186
test final_rank: 123.0
test traces_to_disclosure: nan

Epoch 11 completed.
train loss: 5.534465058173979
train acc: 0.0056990242261103635
train rank: 116.96962097633467
train weight_norm: 102.84375398949996
train grad_norm: 0.13600112637384976
train lr: 0.0009730198026109122
val loss: 5.548353826999664
val acc: 0.00390625
val rank: 126.5021484375
test mean_rank: 215.177
test final_rank: 253.0
test traces_to_disclosure: nan

Epoch 12 completed.
train loss: 5.533306965757347
train acc: 0.005614905787348586
train rank: 116.3682337230821
train weight_norm: 104.22490549714871
train grad_norm: 0.13860423854298812
train lr: 0.0009676990449858007
val loss: 5.556311166286468
val acc: 0.00341796875
val rank: 126.80673828125
test mean_rank: 165.068
test final_rank: 104.0
test traces_to_disclosure: nan

Epoch 14 completed.
train loss: 5.530850838523855
train acc: 0.006184457716464783
train rank: 115.40095579576042
train weight_norm: 106.97725870570594
train grad_norm: 0.14623180858829388
train lr: 0.000955678548713192
val loss: 5.549452459812164
val acc: 0.00400390625
val rank: 126.59873046875
test mean_rank: 162.836
test final_rank: 205.0
test traces_to_disclosure: nan

Epoch 14 completed.
train loss: 5.530842069340907
train acc: 0.006182705248990579
train rank: 115.39973257346345
train weight_norm: 106.98508990792773
train grad_norm: 0.14612963845354313
train lr: 0.000955678548713192
val loss: 5.5483194351196286
val acc: 0.004296875
val rank: 126.74384765625
test mean_rank: 168.766
test final_rank: 222.0
test traces_to_disclosure: nan

Epoch 12 completed.
train loss: 5.53336463994967
train acc: 0.005614905787348586
train rank: 116.38242169975324
train weight_norm: 104.151329623613
train grad_norm: 0.13874251112466968
train lr: 0.0009676990449858007
val loss: 5.557630050182342
val acc: 0.00322265625
val rank: 127.17958984375
test mean_rank: 173.947
test final_rank: 114.0
test traces_to_disclosure: nan

Epoch 17 completed.
train loss: 5.525437030304489
train acc: 0.006014468371467026
train rank: 113.19550877635713
train weight_norm: 111.28417854310989
train grad_norm: 0.16346996953621198
train lr: 0.0009342926597578587
val loss: 5.562317335605622
val acc: 0.00380859375
val rank: 127.04462890625
test mean_rank: 244.609
test final_rank: 231.0
test traces_to_disclosure: nan

Epoch 17 completed.
train loss: 5.525030757344427
train acc: 0.006266823687752355
train rank: 113.06413505215343
train weight_norm: 111.26880297260222
train grad_norm: 0.16417237241944
train lr: 0.0009342926597578587
val loss: 5.561824429035187
val acc: 0.00419921875
val rank: 126.8248046875
test mean_rank: 243.586
test final_rank: 231.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.555, ECE: 0.001
Optimal temperature: 1.501
After temperature - NLL: 5.550, ECE: 0.000
Epoch 20 completed.
train loss: 5.514712698206125
train acc: 0.007514580529385376
train rank: 109.83337889748768
train weight_norm: 115.58360399903742
train grad_norm: 0.2204130983735332
train lr: 0.0009090519584092742
val loss: 5.570236372947693
val acc: 0.0046875
val rank: 126.78642578125
test mean_rank: 173.157
test final_rank: 172.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.561, ECE: 0.003
Optimal temperature: 1.502
After temperature - NLL: 5.552, ECE: 0.002
Epoch 11 completed.
train loss: 5.534450568228679
train acc: 0.005593876177658143
train rank: 116.93657119223869
train weight_norm: 102.82759981764957
train grad_norm: 0.13602923636549816
train lr: 0.0009730198026109122
val loss: 5.548468112945557
val acc: 0.0041015625
val rank: 126.65263671875
test mean_rank: 220.158
test final_rank: 254.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.561, ECE: 0.003
Optimal temperature: 1.760
After temperature - NLL: 5.551, ECE: 0.002
Before temperature - NLL: 5.555, ECE: 0.002
Optimal temperature: 1.501
After temperature - NLL: 5.549, ECE: 0.001
Epoch 15 completed.
train loss: 5.5291163783375055
train acc: 0.005967151749663526
train rank: 114.59058504374158
train weight_norm: 108.358685880868
train grad_norm: 0.1502092137338565
train lr: 0.0009489906728442636
val loss: 5.551444113254547
val acc: 0.003125
val rank: 127.38896484375
test mean_rank: 188.989
test final_rank: 154.0
test traces_to_disclosure: nan

Epoch 18 completed.
train loss: 5.52313384457841
train acc: 0.006587525235531628
train rank: 112.4233435677434
train weight_norm: 112.73392243602423
train grad_norm: 0.17381105800117913
train lr: 0.0009262970277047872
val loss: 5.564430737495423
val acc: 0.00419921875
val rank: 126.51328125
test mean_rank: 200.988
test final_rank: 185.0
test traces_to_disclosure: nan

Epoch 11 completed.
train loss: 5.5344370672551975
train acc: 0.005656965006729475
train rank: 116.9539206202333
train weight_norm: 102.76719706764898
train grad_norm: 0.13606557339656866
train lr: 0.0009730198026109122
val loss: 5.548119449615479
val acc: 0.00380859375
val rank: 126.28095703125
test mean_rank: 227.477
test final_rank: 254.0
test traces_to_disclosure: nan

Epoch 15 completed.
train loss: 5.529106384652139
train acc: 0.005893548115746972
train rank: 114.57481809387617
train weight_norm: 108.37118894087655
train grad_norm: 0.15000609193703124
train lr: 0.0009489906728442636
val loss: 5.5499560832977295
val acc: 0.00283203125
val rank: 127.4177734375
test mean_rank: 180.169
test final_rank: 141.0
test traces_to_disclosure: nan

Epoch 13 completed.
train loss: 5.532005672018428
train acc: 0.005804172274562584
train rank: 115.82265204407807
train weight_norm: 105.64084183660366
train grad_norm: 0.14181513299375476
train lr: 0.0009619167248692779
val loss: 5.554475808143616
val acc: 0.00478515625
val rank: 126.065625
test mean_rank: 60.184
test final_rank: 15.0
test traces_to_disclosure: nan

Epoch 13 completed.
train loss: 5.5320335037775665
train acc: 0.005604390982503365
train rank: 115.83125315444146
train weight_norm: 105.60914075516213
train grad_norm: 0.14187971731228266
train lr: 0.0009619167248692779
val loss: 5.554505300521851
val acc: 0.0041015625
val rank: 126.2265625
test mean_rank: 62.764
test final_rank: 7.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.557, ECE: 0.002
Optimal temperature: 1.501
After temperature - NLL: 5.550, ECE: 0.001
Epoch 13 completed.
train loss: 5.5319929418140275
train acc: 0.005793657469717362
train rank: 115.81009386215793
train weight_norm: 105.53564110697576
train grad_norm: 0.14167553877950717
train lr: 0.0009619167248692779
val loss: 5.55405308008194
val acc: 0.00498046875
val rank: 125.88291015625
test mean_rank: 76.19
test final_rank: 24.0
test traces_to_disclosure: nan

Epoch 21 completed.
train loss: 5.509463837778905
train acc: 0.0074304620906235986
train rank: 108.36960240017946
train weight_norm: 117.11651546456773
train grad_norm: 0.25523470943455123
train lr: 0.0008998195399682029
val loss: 5.572307193279267
val acc: 0.00400390625
val rank: 126.29404296875
test mean_rank: 133.851
test final_rank: 170.0
test traces_to_disclosure: nan

Epoch 18 completed.
train loss: 5.5227791951771215
train acc: 0.00659278263795424
train rank: 112.33422008187529
train weight_norm: 112.71935436772935
train grad_norm: 0.17476623440205502
train lr: 0.0009262970277047872
val loss: 5.564832222461701
val acc: 0.00419921875
val rank: 126.6431640625
test mean_rank: 202.345
test final_rank: 187.0
test traces_to_disclosure: nan

Epoch 12 completed.
train loss: 5.533273318253488
train acc: 0.005641192799461642
train rank: 116.36964445939884
train weight_norm: 104.21109553135368
train grad_norm: 0.13829300606515538
train lr: 0.0009676990449858007
val loss: 5.548935508728027
val acc: 0.0037109375
val rank: 126.1751953125
test mean_rank: 214.842
test final_rank: 244.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.561, ECE: 0.003
Optimal temperature: 1.761
After temperature - NLL: 5.550, ECE: 0.002
Epoch 16 completed.
train loss: 5.527322244194924
train acc: 0.0063088829071332436
train rank: 113.94955697622254
train weight_norm: 109.84015344595372
train grad_norm: 0.1576297004257594
train lr: 0.0009418596973885387
val loss: 5.5493175148963925
val acc: 0.00322265625
val rank: 126.70126953125
test mean_rank: 128.29
test final_rank: 79.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.557, ECE: 0.002
Optimal temperature: 1.501
After temperature - NLL: 5.550, ECE: 0.001
Before temperature - NLL: 5.562, ECE: 0.003
Optimal temperature: 1.767
After temperature - NLL: 5.550, ECE: 0.002
Epoch 12 completed.
train loss: 5.533230720586764
train acc: 0.005840974091520862
train rank: 116.32360363391655
train weight_norm: 104.2049150692254
train grad_norm: 0.1381348669306548
train lr: 0.0009676990449858007
val loss: 5.548983085155487
val acc: 0.00390625
val rank: 126.2087890625
test mean_rank: 212.287
test final_rank: 242.0
test traces_to_disclosure: nan

Epoch 19 completed.
train loss: 5.5199946664063155
train acc: 0.006466604979811575
train rank: 111.37980000841185
train weight_norm: 114.21191208139683
train grad_norm: 0.1897303174985917
train lr: 0.000917880691952835
val loss: 5.565708255767822
val acc: 0.00458984375
val rank: 126.83095703125
test mean_rank: 79.19
test final_rank: 101.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.557, ECE: 0.002
Optimal temperature: 1.501
After temperature - NLL: 5.550, ECE: 0.001
Epoch 16 completed.
train loss: 5.527344568902038
train acc: 0.0061932200538358005
train rank: 113.91981760318527
train weight_norm: 109.83409925856733
train grad_norm: 0.15843867869202036
train lr: 0.0009418596973885387
val loss: 5.549359405040741
val acc: 0.00361328125
val rank: 126.61494140625
test mean_rank: 107.701
test final_rank: 54.0
test traces_to_disclosure: nan

Epoch 22 completed.
train loss: 5.502246640412034
train acc: 0.00831721063257066
train rank: 106.59311560677435
train weight_norm: 118.7059972228549
train grad_norm: 0.31736737585426694
train lr: 0.0008901925479119812
val loss: 5.580585956573486
val acc: 0.00380859375
val rank: 127.40556640625
test mean_rank: 226.056
test final_rank: 212.0
test traces_to_disclosure: nan

Epoch 19 completed.
train loss: 5.519541867488487
train acc: 0.0065559808209959625
train rank: 111.25302300639301
train weight_norm: 114.2039002886547
train grad_norm: 0.19142160960741597
train lr: 0.000917880691952835
val loss: 5.565551447868347
val acc: 0.00361328125
val rank: 126.86494140625
test mean_rank: 64.889
test final_rank: 79.0
test traces_to_disclosure: nan

Epoch 14 completed.
train loss: 5.530597600770029
train acc: 0.005821696949304621
train rank: 115.21774934107222
train weight_norm: 107.05544492560858
train grad_norm: 0.14488795875105398
train lr: 0.000955678548713192
val loss: 5.556273281574249
val acc: 0.003515625
val rank: 126.5751953125
test mean_rank: 154.102
test final_rank: 53.0
test traces_to_disclosure: nan

Epoch 14 completed.
train loss: 5.530675115367124
train acc: 0.005748093315388067
train rank: 115.22827816565726
train weight_norm: 107.01073479556237
train grad_norm: 0.14504726245170455
train lr: 0.000955678548713192
val loss: 5.556374967098236
val acc: 0.003515625
val rank: 126.67744140625
test mean_rank: 166.651
test final_rank: 65.0
test traces_to_disclosure: nan

Epoch 12 completed.
train loss: 5.533243185097244
train acc: 0.005809429676985195
train rank: 116.34959097409153
train weight_norm: 104.12409145098339
train grad_norm: 0.13833597225108563
train lr: 0.0009676990449858007
val loss: 5.549002230167389
val acc: 0.00380859375
val rank: 126.04951171875
test mean_rank: 213.037
test final_rank: 248.0
test traces_to_disclosure: nan

Epoch 14 completed.
train loss: 5.530698670352613
train acc: 0.005721806303275012
train rank: 115.26548305013459
train weight_norm: 106.93263614222879
train grad_norm: 0.1447680438073423
train lr: 0.000955678548713192
val loss: 5.556610858440399
val acc: 0.003515625
val rank: 126.72509765625
test mean_rank: 158.75
test final_rank: 75.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.562, ECE: 0.002
Optimal temperature: 1.761
After temperature - NLL: 5.551, ECE: 0.001
Before temperature - NLL: 5.558, ECE: 0.002
Optimal temperature: 1.501
After temperature - NLL: 5.551, ECE: 0.002
Epoch 17 completed.
train loss: 5.525193854263942
train acc: 0.006203734858681023
train rank: 113.14075468259308
train weight_norm: 111.28500734181804
train grad_norm: 0.1639558082220316
train lr: 0.0009342926597578587
val loss: 5.549761009216309
val acc: 0.0037109375
val rank: 127.027734375
test mean_rank: 159.568
test final_rank: 140.0
test traces_to_disclosure: nan

Epoch 13 completed.
train loss: 5.53204609920969
train acc: 0.005825201884253028
train rank: 115.9024191061014
train weight_norm: 105.58818792254807
train grad_norm: 0.14158482849727572
train lr: 0.0009619167248692779
val loss: 5.5502736330032345
val acc: 0.00341796875
val rank: 126.9349609375
test mean_rank: 189.828
test final_rank: 99.0
test traces_to_disclosure: nan

Epoch 20 completed.
train loss: 5.515223428667153
train acc: 0.007309541834903545
train rank: 109.96762666834906
train weight_norm: 115.7221619522378
train grad_norm: 0.2131488422729534
train lr: 0.0009090519584092742
val loss: 5.569425785541535
val acc: 0.003515625
val rank: 126.916015625
test mean_rank: 146.925
test final_rank: 101.0
test traces_to_disclosure: nan

Epoch 23 completed.
train loss: 5.491948191282085
train acc: 0.009128603073126964
train rank: 104.25927756280842
train weight_norm: 120.34297616226341
train grad_norm: 0.40151205341879925
train lr: 0.0008801804829194873
val loss: 5.588703465461731
val acc: 0.00361328125
val rank: 127.2203125
test mean_rank: 210.941
test final_rank: 227.0
test traces_to_disclosure: nan

Epoch 20 completed.
train loss: 5.515811110248797
train acc: 0.007186869111709287
train rank: 110.13494875785106
train weight_norm: 115.70887289779859
train grad_norm: 0.21191467812206752
train lr: 0.0009090519584092742
val loss: 5.571008956432342
val acc: 0.0037109375
val rank: 127.36396484375
test mean_rank: 127.691
test final_rank: 72.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.562, ECE: 0.002
Optimal temperature: 1.767
After temperature - NLL: 5.550, ECE: 0.001
Before temperature - NLL: 5.558, ECE: 0.002
Optimal temperature: 1.502
After temperature - NLL: 5.551, ECE: 0.001
Epoch 17 completed.
train loss: 5.525285196496853
train acc: 0.0061196164199192465
train rank: 113.15059303499326
train weight_norm: 111.26775189725971
train grad_norm: 0.16489174017955655
train lr: 0.0009342926597578587
val loss: 5.54964051246643
val acc: 0.0044921875
val rank: 126.93779296875
test mean_rank: 188.744
test final_rank: 182.0
test traces_to_disclosure: nan

Epoch 13 completed.
train loss: 5.531982817207018
train acc: 0.005767370457604307
train rank: 115.89567561126064
train weight_norm: 105.58483831401753
train grad_norm: 0.14158267577799377
train lr: 0.0009619167248692779
val loss: 5.550047242641449
val acc: 0.00380859375
val rank: 126.611328125
test mean_rank: 173.085
test final_rank: 91.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.559, ECE: 0.002
Optimal temperature: 1.501
After temperature - NLL: 5.551, ECE: 0.001
Epoch 15 completed.
train loss: 5.528991697293431
train acc: 0.00593560733512786
train rank: 114.57586782189321
train weight_norm: 108.46368710645501
train grad_norm: 0.14916648312604797
train lr: 0.0009489906728442636
val loss: 5.559947347640991
val acc: 0.00302734375
val rank: 126.80986328125
test mean_rank: 206.844
test final_rank: 115.0
test traces_to_disclosure: nan

Epoch 15 completed.
train loss: 5.529075581485137
train acc: 0.006046012786002692
train rank: 114.59475065892778
train weight_norm: 108.43066054785297
train grad_norm: 0.14923179208570636
train lr: 0.0009489906728442636
val loss: 5.559016335010528
val acc: 0.00341796875
val rank: 126.5814453125
test mean_rank: 213.009
test final_rank: 124.0
test traces_to_disclosure: nan

Epoch 13 completed.
train loss: 5.53204287494336
train acc: 0.00588303331090175
train rank: 115.91425877635713
train weight_norm: 105.50219801712065
train grad_norm: 0.14172997458630462
train lr: 0.0009619167248692779
val loss: 5.550619089603424
val acc: 0.00361328125
val rank: 127.1876953125
test mean_rank: 183.851
test final_rank: 116.0
test traces_to_disclosure: nan

Epoch 15 completed.
train loss: 5.529122684396613
train acc: 0.006124873822341857
train rank: 114.60953973194259
train weight_norm: 108.33056721496891
train grad_norm: 0.14890866507790618
train lr: 0.0009489906728442636
val loss: 5.559460735321045
val acc: 0.002734375
val rank: 126.59736328125
test mean_rank: 223.63
test final_rank: 145.0
test traces_to_disclosure: nan

Epoch 24 completed.
train loss: 5.478141716640057
train acc: 0.009989064602960968
train rank: 101.40576456650963
train weight_norm: 122.03479016128819
train grad_norm: 0.524901584490087
train lr: 0.0008697932256900982
val loss: 5.599816143512726
val acc: 0.003515625
val rank: 126.8623046875
test mean_rank: 182.885
test final_rank: 156.0
test traces_to_disclosure: nan

Epoch 21 completed.
train loss: 5.510905919132772
train acc: 0.007451491700314043
train rank: 108.73602231942577
train weight_norm: 117.21848931950493
train grad_norm: 0.24266977375888588
train lr: 0.0008998195399682029
val loss: 5.573057305812836
val acc: 0.00439453125
val rank: 126.86796875
test mean_rank: 147.353
test final_rank: 179.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.565, ECE: 0.002
Optimal temperature: 1.761
After temperature - NLL: 5.551, ECE: 0.001
Epoch 21 completed.
train loss: 5.510270176472927
train acc: 0.007490045984746522
train rank: 108.58788449136385
train weight_norm: 117.25962433992014
train grad_norm: 0.24418462936090965
train lr: 0.0008998195399682029
val loss: 5.572496342658996
val acc: 0.0037109375
val rank: 126.652734375
test mean_rank: 108.009
test final_rank: 149.0
test traces_to_disclosure: nan

Epoch 18 completed.
train loss: 5.522700867453944
train acc: 0.006471862382234185
train rank: 112.28650564995512
train weight_norm: 112.75278975101611
train grad_norm: 0.17637511059445612
train lr: 0.0009262970277047872
val loss: 5.550351023674011
val acc: 0.00341796875
val rank: 126.74453125
test mean_rank: 11.764
test final_rank: 3.0
test traces_to_disclosure: 477.0

Before temperature - NLL: 5.557, ECE: 0.002
Optimal temperature: 1.501
After temperature - NLL: 5.550, ECE: 0.001
Before temperature - NLL: 5.564, ECE: 0.003
Optimal temperature: 1.767
After temperature - NLL: 5.551, ECE: 0.002
Epoch 14 completed.
train loss: 5.530856737057261
train acc: 0.005925092530282638
train rank: 115.40914507626736
train weight_norm: 107.00653832752396
train grad_norm: 0.14531032395988694
train lr: 0.000955678548713192
val loss: 5.549515068531036
val acc: 0.00380859375
val rank: 126.62255859375
test mean_rank: 156.091
test final_rank: 221.0
test traces_to_disclosure: nan

Epoch 18 completed.
train loss: 5.52272259210353
train acc: 0.006319397711978466
train rank: 112.30391816677881
train weight_norm: 112.73466058885165
train grad_norm: 0.1772698241192732
train lr: 0.0009262970277047872
val loss: 5.55002613067627
val acc: 0.00517578125
val rank: 126.53017578125
test mean_rank: 8.234
test final_rank: 2.0
test traces_to_disclosure: 433.0

Before temperature - NLL: 5.557, ECE: 0.002
Optimal temperature: 1.502
After temperature - NLL: 5.551, ECE: 0.001
Epoch 25 completed.
train loss: 5.459070058722515
train acc: 0.011541750785105427
train rank: 98.09645055237773
train weight_norm: 123.78595733301331
train grad_norm: 0.6997631767273158
train lr: 0.0008590410271926295
val loss: 5.613776397705078
val acc: 0.0044921875
val rank: 127.13349609375
test mean_rank: 42.579
test final_rank: 90.0
test traces_to_disclosure: nan

Epoch 22 completed.
train loss: 5.5044117211332875
train acc: 0.007949192462987887
train rank: 107.11331980428444
train weight_norm: 118.80618404220391
train grad_norm: 0.29652266596650084
train lr: 0.0008901925479119812
val loss: 5.57934992313385
val acc: 0.00361328125
val rank: 127.19296875
test mean_rank: 216.419
test final_rank: 212.0
test traces_to_disclosure: nan

Epoch 14 completed.
train loss: 5.530842218232187
train acc: 0.006151160834454912
train rank: 115.38192750392551
train weight_norm: 107.01246513168063
train grad_norm: 0.14537307640592065
train lr: 0.000955678548713192
val loss: 5.549652528762818
val acc: 0.00390625
val rank: 126.70908203125
test mean_rank: 143.832
test final_rank: 208.0
test traces_to_disclosure: nan

Epoch 16 completed.
train loss: 5.527459805618225
train acc: 0.006361456931359354
train rank: 113.99545234690444
train weight_norm: 109.76302253845304
train grad_norm: 0.1550446422289514
train lr: 0.0009418596973885387
val loss: 5.556081557273865
val acc: 0.0033203125
val rank: 125.79267578125
test mean_rank: 126.845
test final_rank: 210.0
test traces_to_disclosure: nan

Epoch 16 completed.
train loss: 5.527388731852515
train acc: 0.006051270188425303
train rank: 113.95310922779274
train weight_norm: 109.86996473799918
train grad_norm: 0.1554705345108812
train lr: 0.0009418596973885387
val loss: 5.5562056541442875
val acc: 0.0033203125
val rank: 125.800390625
test mean_rank: 128.28
test final_rank: 208.0
test traces_to_disclosure: nan

Epoch 16 completed.
train loss: 5.527342406127848
train acc: 0.006109101615074024
train rank: 113.93253701211306
train weight_norm: 109.91019040703087
train grad_norm: 0.15545004929867812
train lr: 0.0009418596973885387
val loss: 5.55677958726883
val acc: 0.003125
val rank: 126.13203125
test mean_rank: 136.591
test final_rank: 210.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.558, ECE: 0.002
Optimal temperature: 1.501
After temperature - NLL: 5.551, ECE: 0.001
Before temperature - NLL: 5.569, ECE: 0.004
Optimal temperature: 2.073
After temperature - NLL: 5.551, ECE: 0.002
Epoch 22 completed.
train loss: 5.503431845802317
train acc: 0.007886103633916555
train rank: 106.8593679901301
train weight_norm: 118.82449440503513
train grad_norm: 0.2967673502842346
train lr: 0.0008901925479119812
val loss: 5.5810943961143495
val acc: 0.00341796875
val rank: 127.2587890625
test mean_rank: 218.591
test final_rank: 198.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.569, ECE: 0.003
Optimal temperature: 2.078
After temperature - NLL: 5.551, ECE: 0.002
Epoch 14 completed.
train loss: 5.530762629425542
train acc: 0.006105596680125618
train rank: 115.34899163021534
train weight_norm: 106.91431125907026
train grad_norm: 0.1453798609342681
train lr: 0.000955678548713192
val loss: 5.5499331712722775
val acc: 0.0041015625
val rank: 126.99482421875
test mean_rank: 161.054
test final_rank: 225.0
test traces_to_disclosure: nan

Epoch 19 completed.
train loss: 5.5195087693421065
train acc: 0.006640099259757739
train rank: 111.2258615130103
train weight_norm: 114.2247838024831
train grad_norm: 0.19109920348776965
train lr: 0.000917880691952835
val loss: 5.550400257110596
val acc: 0.00390625
val rank: 127.71171875
test mean_rank: 116.979
test final_rank: 213.0
test traces_to_disclosure: nan

Epoch 19 completed.
train loss: 5.519410330386052
train acc: 0.00685039535666218
train rank: 111.19460450314044
train weight_norm: 114.20418209669805
train grad_norm: 0.1949534533242521
train lr: 0.000917880691952835
val loss: 5.550291025638581
val acc: 0.00537109375
val rank: 127.5265625
test mean_rank: 121.976
test final_rank: 213.0
test traces_to_disclosure: nan

Epoch 26 completed.
train loss: 5.432632476452382
train acc: 0.012617765814266487
train rank: 93.84589502018842
train weight_norm: 125.55711411736854
train grad_norm: 0.9259278583757646
train lr: 0.0008479344985488699
val loss: 5.637729060649872
val acc: 0.003125
val rank: 127.43828125
test mean_rank: 72.971
test final_rank: 122.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.561, ECE: 0.003
Optimal temperature: 1.769
After temperature - NLL: 5.551, ECE: 0.002
Epoch 23 completed.
train loss: 5.495117770871436
train acc: 0.008545031404217139
train rank: 104.92954730260207
train weight_norm: 120.42485796284741
train grad_norm: 0.3653943998457432
train lr: 0.0008801804829194873
val loss: 5.585716629028321
val acc: 0.00576171875
val rank: 127.29697265625
test mean_rank: 210.585
test final_rank: 239.0
test traces_to_disclosure: nan

Epoch 15 completed.
train loss: 5.529086484562501
train acc: 0.006114359017496635
train rank: 114.5884522908255
train weight_norm: 108.38678678080642
train grad_norm: 0.1487662448731685
train lr: 0.0009489906728442636
val loss: 5.549834048748016
val acc: 0.002734375
val rank: 127.3740234375
test mean_rank: 171.815
test final_rank: 145.0
test traces_to_disclosure: nan

Epoch 23 completed.
train loss: 5.494010911173968
train acc: 0.008729040489008525
train rank: 104.71172961529832
train weight_norm: 120.44557329616748
train grad_norm: 0.36785663824951403
train lr: 0.0008801804829194873
val loss: 5.5844218850135805
val acc: 0.00390625
val rank: 126.7857421875
test mean_rank: 137.014
test final_rank: 198.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.571, ECE: 0.003
Optimal temperature: 2.073
After temperature - NLL: 5.551, ECE: 0.001
Before temperature - NLL: 5.561, ECE: 0.003
Optimal temperature: 1.770
After temperature - NLL: 5.551, ECE: 0.002
Epoch 17 completed.
train loss: 5.525239082557196
train acc: 0.006319397711978466
train rank: 113.12763395861373
train weight_norm: 111.31423400307162
train grad_norm: 0.1613052297197306
train lr: 0.0009342926597578587
val loss: 5.560971224308014
val acc: 0.00361328125
val rank: 126.6634765625
test mean_rank: 245.516
test final_rank: 221.0
test traces_to_disclosure: nan

Epoch 17 completed.
train loss: 5.525297350389319
train acc: 0.006471862382234185
train rank: 113.17987676648721
train weight_norm: 111.36485897780973
train grad_norm: 0.16161473031530516
train lr: 0.0009342926597578587
val loss: 5.56266325712204
val acc: 0.00458984375
val rank: 127.4923828125
test mean_rank: 248.709
test final_rank: 233.0
test traces_to_disclosure: nan

Epoch 17 completed.
train loss: 5.525290840888248
train acc: 0.006277338492597578
train rank: 113.15843532694032
train weight_norm: 111.19857810216091
train grad_norm: 0.16078148149098218
train lr: 0.0009342926597578587
val loss: 5.562139093875885
val acc: 0.00458984375
val rank: 127.11181640625
test mean_rank: 246.697
test final_rank: 219.0
test traces_to_disclosure: nan

Epoch 27 completed.
train loss: 5.396920114314412
train acc: 0.015262239232839838
train rank: 89.00511019515478
train weight_norm: 127.3590788099671
train grad_norm: 1.2199826331015506
train lr: 0.0008364846005616848
val loss: 5.666927623748779
val acc: 0.0037109375
val rank: 127.6365234375
test mean_rank: 120.453
test final_rank: 128.0
test traces_to_disclosure: nan

Epoch 20 completed.
train loss: 5.5153048478097
train acc: 0.007043166778824584
train rank: 109.8895857867878
train weight_norm: 115.72335503350527
train grad_norm: 0.2148155622984689
train lr: 0.0009090519584092742
val loss: 5.550735580921173
val acc: 0.00390625
val rank: 127.50810546875
test mean_rank: 182.393
test final_rank: 209.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.570, ECE: 0.004
Optimal temperature: 2.078
After temperature - NLL: 5.551, ECE: 0.002
Epoch 15 completed.
train loss: 5.529062588153906
train acc: 0.005798914872139973
train rank: 114.57423627467476
train weight_norm: 108.40587607350649
train grad_norm: 0.1487281120409514
train lr: 0.0009489906728442636
val loss: 5.550070261955261
val acc: 0.00322265625
val rank: 127.5654296875
test mean_rank: 174.111
test final_rank: 129.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.562, ECE: 0.003
Optimal temperature: 1.772
After temperature - NLL: 5.551, ECE: 0.002
Epoch 20 completed.
train loss: 5.514844705086216
train acc: 0.007122027815163749
train rank: 109.76100199080304
train weight_norm: 115.71814475354775
train grad_norm: 0.2204319063926288
train lr: 0.0009090519584092742
val loss: 5.550346493721008
val acc: 0.00341796875
val rank: 127.16494140625
test mean_rank: 165.701
test final_rank: 165.0
test traces_to_disclosure: nan

Epoch 24 completed.
train loss: 5.482960530277216
train acc: 0.009578987213997308
train rank: 102.31700384140869
train weight_norm: 122.09127638169711
train grad_norm: 0.4758017159180016
train lr: 0.0008697932256900982
val loss: 5.5933668375015255
val acc: 0.00361328125
val rank: 126.82275390625
test mean_rank: 176.39
test final_rank: 162.0
test traces_to_disclosure: nan

Epoch 15 completed.
train loss: 5.5289648493719294
train acc: 0.006009210969044414
train rank: 114.54320533310901
train weight_norm: 108.30087242930034
train grad_norm: 0.14889918503808933
train lr: 0.0009489906728442636
val loss: 5.550457012653351
val acc: 0.003515625
val rank: 128.02080078125
test mean_rank: 164.51
test final_rank: 115.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.561, ECE: 0.002
Optimal temperature: 1.769
After temperature - NLL: 5.550, ECE: 0.001
Epoch 24 completed.
train loss: 5.480994458795396
train acc: 0.009584244616419919
train rank: 101.94195827725437
train weight_norm: 122.11091466242759
train grad_norm: 0.4777536822628716
train lr: 0.0008697932256900982
val loss: 5.597531378269196
val acc: 0.0037109375
val rank: 127.00419921875
test mean_rank: 187.885
test final_rank: 132.0
test traces_to_disclosure: nan

Epoch 16 completed.
train loss: 5.527445332359016
train acc: 0.0061196164199192465
train rank: 113.97157673003588
train weight_norm: 109.85229349369577
train grad_norm: 0.1554829879732212
train lr: 0.0009418596973885387
val loss: 5.5494617342948915
val acc: 0.00419921875
val rank: 126.87666015625
test mean_rank: 119.965
test final_rank: 80.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.572, ECE: 0.002
Optimal temperature: 2.073
After temperature - NLL: 5.551, ECE: 0.000
Epoch 28 completed.
train loss: 5.350837532957342
train acc: 0.018194117317182595
train rank: 83.75857131841633
train weight_norm: 129.19891151211394
train grad_norm: 1.5956034665518022
train lr: 0.0008247026328980229
val loss: 5.704038786888122
val acc: 0.00380859375
val rank: 127.18212890625
test mean_rank: 99.913
test final_rank: 110.0
test traces_to_disclosure: nan

Epoch 21 completed.
train loss: 5.510509188050055
train acc: 0.007339333781965007
train rank: 108.65572951716017
train weight_norm: 117.24214699182893
train grad_norm: 0.24962393470960728
train lr: 0.0008998195399682029
val loss: 5.55020158290863
val acc: 0.0052734375
val rank: 126.569921875
test mean_rank: 148.457
test final_rank: 152.0
test traces_to_disclosure: nan

Epoch 18 completed.
train loss: 5.522956208297093
train acc: 0.006713702893674294
train rank: 112.37946002972186
train weight_norm: 112.78085315550632
train grad_norm: 0.1704565870320011
train lr: 0.0009262970277047872
val loss: 5.564423668384552
val acc: 0.00458984375
val rank: 126.918359375
test mean_rank: 179.613
test final_rank: 170.0
test traces_to_disclosure: nan

Epoch 18 completed.
train loss: 5.522871150944788
train acc: 0.006750504710632571
train rank: 112.37278663358008
train weight_norm: 112.82931723523389
train grad_norm: 0.1706180496807966
train lr: 0.0009262970277047872
val loss: 5.564759814739228
val acc: 0.0046875
val rank: 126.80537109375
test mean_rank: 191.061
test final_rank: 180.0
test traces_to_disclosure: nan

Epoch 18 completed.
train loss: 5.523128980582688
train acc: 0.006813593539703903
train rank: 112.45916750785106
train weight_norm: 112.64506319637009
train grad_norm: 0.16919179638067505
train lr: 0.0009262970277047872
val loss: 5.56484100818634
val acc: 0.0033203125
val rank: 126.77802734375
test mean_rank: 188.548
test final_rank: 176.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.573, ECE: 0.004
Optimal temperature: 2.079
After temperature - NLL: 5.551, ECE: 0.001
Before temperature - NLL: 5.561, ECE: 0.002
Optimal temperature: 1.770
After temperature - NLL: 5.550, ECE: 0.001
Epoch 25 completed.
train loss: 5.463340156010952
train acc: 0.010805714445939885
train rank: 98.72276490298339
train weight_norm: 123.83957755861182
train grad_norm: 0.6292069191133779
train lr: 0.0008590410271926295
val loss: 5.609407114982605
val acc: 0.00361328125
val rank: 126.53271484375
test mean_rank: 12.706
test final_rank: 30.0
test traces_to_disclosure: 36.0

Epoch 25 completed.
train loss: 5.465557599613195
train acc: 0.010520062247644684
train rank: 99.08217144739793
train weight_norm: 123.80025774015343
train grad_norm: 0.6267045022472901
train lr: 0.0008590410271926295
val loss: 5.607242333889007
val acc: 0.00400390625
val rank: 127.03427734375
test mean_rank: 26.092
test final_rank: 43.0
test traces_to_disclosure: nan

Epoch 21 completed.
train loss: 5.509773723530416
train acc: 0.0074304620906235986
train rank: 108.40289577725437
train weight_norm: 117.286433359443
train grad_norm: 0.2587272636913936
train lr: 0.0008998195399682029
val loss: 5.550776529312134
val acc: 0.00380859375
val rank: 127.01455078125
test mean_rank: 131.301
test final_rank: 101.0
test traces_to_disclosure: nan

Epoch 16 completed.
train loss: 5.5274482318883305
train acc: 0.006198477456258412
train rank: 113.99966878364738
train weight_norm: 109.88289775829936
train grad_norm: 0.15559031172059126
train lr: 0.0009418596973885387
val loss: 5.549345469474792
val acc: 0.0044921875
val rank: 126.83818359375
test mean_rank: 112.481
test final_rank: 85.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.561, ECE: 0.002
Optimal temperature: 1.772
After temperature - NLL: 5.550, ECE: 0.001
Epoch 29 completed.
train loss: 5.295668470426331
train acc: 0.02246838548676536
train rank: 78.40051943135936
train weight_norm: 131.03977877347566
train grad_norm: 1.9858023555606024
train lr: 0.0008126002229375134
val loss: 5.743638503551483
val acc: 0.0033203125
val rank: 126.9576171875
test mean_rank: 246.178
test final_rank: 253.0
test traces_to_disclosure: nan

Epoch 16 completed.
train loss: 5.527377417398815
train acc: 0.006256308882907133
train rank: 113.94178828790936
train weight_norm: 109.75808743276443
train grad_norm: 0.15592870122418565
train lr: 0.0009418596973885387
val loss: 5.54931526184082
val acc: 0.004296875
val rank: 126.79072265625
test mean_rank: 114.593
test final_rank: 64.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.581, ECE: 0.004
Optimal temperature: 2.073
After temperature - NLL: 5.553, ECE: 0.002
Before temperature - NLL: 5.562, ECE: 0.003
Optimal temperature: 1.770
After temperature - NLL: 5.551, ECE: 0.002
Epoch 22 completed.
train loss: 5.5035290461369515
train acc: 0.008248864401076717
train rank: 106.8628886972858
train weight_norm: 118.79226810073989
train grad_norm: 0.30371254159007904
train lr: 0.0008901925479119812
val loss: 5.552186286449432
val acc: 0.00361328125
val rank: 126.94111328125
test mean_rank: 22.841
test final_rank: 36.0
test traces_to_disclosure: 32.0

Epoch 17 completed.
train loss: 5.525382871101554
train acc: 0.006214249663526245
train rank: 113.2175811041947
train weight_norm: 111.26439898383009
train grad_norm: 0.16077700077246254
train lr: 0.0009342926597578587
val loss: 5.549642336368561
val acc: 0.00302734375
val rank: 126.79833984375
test mean_rank: 179.314
test final_rank: 182.0
test traces_to_disclosure: nan

Epoch 26 completed.
train loss: 5.438997810332965
train acc: 0.012304074136384027
train rank: 94.83526104755497
train weight_norm: 125.60988534180326
train grad_norm: 0.8338833565261495
train lr: 0.0008479344985488699
val loss: 5.627863121032715
val acc: 0.00390625
val rank: 126.8291015625
test mean_rank: 174.156
test final_rank: 206.0
test traces_to_disclosure: nan

Epoch 26 completed.
train loss: 5.441034905522219
train acc: 0.012142847128757291
train rank: 95.0424798115747
train weight_norm: 125.58095278323094
train grad_norm: 0.8328750206431403
train lr: 0.0008479344985488699
val loss: 5.628246212005616
val acc: 0.00419921875
val rank: 127.2001953125
test mean_rank: 136.217
test final_rank: 210.0
test traces_to_disclosure: nan

Epoch 19 completed.
train loss: 5.520066275410505
train acc: 0.006713702893674294
train rank: 111.44133439883358
train weight_norm: 114.0902037625827
train grad_norm: 0.18163455516312896
train lr: 0.000917880691952835
val loss: 5.5656800150871275
val acc: 0.0041015625
val rank: 126.93828125
test mean_rank: 90.245
test final_rank: 111.0
test traces_to_disclosure: nan

Epoch 19 completed.
train loss: 5.519834681442897
train acc: 0.006713702893674294
train rank: 111.35351299629879
train weight_norm: 114.25064636976815
train grad_norm: 0.18327216667921684
train lr: 0.000917880691952835
val loss: 5.565816640853882
val acc: 0.00439453125
val rank: 126.8576171875
test mean_rank: 88.624
test final_rank: 86.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.583, ECE: 0.006
Optimal temperature: 2.080
After temperature - NLL: 5.554, ECE: 0.003
Epoch 19 completed.
train loss: 5.519906492605505
train acc: 0.006582267833109018
train rank: 111.38488917395694
train weight_norm: 114.29252289160053
train grad_norm: 0.18353120347013366
train lr: 0.000917880691952835
val loss: 5.566575455665588
val acc: 0.004296875
val rank: 127.16640625
test mean_rank: 86.308
test final_rank: 116.0
test traces_to_disclosure: nan

Epoch 30 completed.
train loss: 5.230324223416972
train acc: 0.027136958838043963
train rank: 72.83682424854196
train weight_norm: 132.89035705242668
train grad_norm: 2.461238126208512
train lr: 0.000800189314297648
val loss: 5.801524841785431
val acc: 0.00380859375
val rank: 127.558984375
test mean_rank: 92.569
test final_rank: 52.0
test traces_to_disclosure: nan

Epoch 22 completed.
train loss: 5.502125331883796
train acc: 0.008290923620457604
train rank: 106.50597591408702
train weight_norm: 118.88075620447421
train grad_norm: 0.3207398538844356
train lr: 0.0008901925479119812
val loss: 5.552943849563599
val acc: 0.00302734375
val rank: 126.93369140625
test mean_rank: 9.764
test final_rank: 3.0
test traces_to_disclosure: 554.0

Before temperature - NLL: 5.586, ECE: 0.004
Optimal temperature: 2.073
After temperature - NLL: 5.554, ECE: 0.001
Before temperature - NLL: 5.562, ECE: 0.002
Optimal temperature: 1.770
After temperature - NLL: 5.550, ECE: 0.001
Epoch 23 completed.
train loss: 5.4944432959421805
train acc: 0.00855554620906236
train rank: 104.74360174125168
train weight_norm: 120.40654654469257
train grad_norm: 0.3824615024942281
train lr: 0.0008801804829194873
val loss: 5.553360939025879
val acc: 0.00478515625
val rank: 126.7791015625
test mean_rank: 43.871
test final_rank: 15.0
test traces_to_disclosure: nan

Epoch 17 completed.
train loss: 5.5253400456055015
train acc: 0.006103844212651414
train rank: 113.1804550807537
train weight_norm: 111.31306828423998
train grad_norm: 0.16124347599644823
train lr: 0.0009342926597578587
val loss: 5.549374413490296
val acc: 0.00400390625
val rank: 126.61875
test mean_rank: 192.497
test final_rank: 210.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.562, ECE: 0.002
Optimal temperature: 1.773
After temperature - NLL: 5.551, ECE: 0.001
Epoch 27 completed.
train loss: 5.408274449057084
train acc: 0.014010977456258412
train rank: 90.45752895076266
train weight_norm: 127.38207608850774
train grad_norm: 1.100177220329706
train lr: 0.0008364846005616848
val loss: 5.652722358703613
val acc: 0.003515625
val rank: 127.34208984375
test mean_rank: 70.31
test final_rank: 141.0
test traces_to_disclosure: nan

Epoch 17 completed.
train loss: 5.525263796584282
train acc: 0.0061353886271870795
train rank: 113.14735447510094
train weight_norm: 111.19304790382802
train grad_norm: 0.16147808062772354
train lr: 0.0009342926597578587
val loss: 5.549677729606628
val acc: 0.00400390625
val rank: 126.79453125
test mean_rank: 190.914
test final_rank: 195.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.587, ECE: 0.005
Optimal temperature: 2.080
After temperature - NLL: 5.554, ECE: 0.002
Epoch 27 completed.
train loss: 5.405884602188583
train acc: 0.014825874831763123
train rank: 90.17825222913862
train weight_norm: 127.39880534295283
train grad_norm: 1.0923092131185912
train lr: 0.0008364846005616848
val loss: 5.655549323558807
val acc: 0.0037109375
val rank: 127.0953125
test mean_rank: 93.049
test final_rank: 117.0
test traces_to_disclosure: nan

Epoch 31 completed.
train loss: 5.159216095268485
train acc: 0.033112872925078515
train rank: 67.74430272824135
train weight_norm: 134.7198014384749
train grad_norm: 2.962799404496077
train lr: 0.0007874821550468655
val loss: 5.855391085147858
val acc: 0.00390625
val rank: 128.04580078125
test mean_rank: 175.912
test final_rank: 67.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.563, ECE: 0.003
Optimal temperature: 1.770
After temperature - NLL: 5.551, ECE: 0.002
Epoch 23 completed.
train loss: 5.492056892184518
train acc: 0.008466170367877973
train rank: 104.19025838380438
train weight_norm: 120.56288769352324
train grad_norm: 0.4158160804884003
train lr: 0.0008801804829194873
val loss: 5.55393477678299
val acc: 0.00380859375
val rank: 126.91162109375
test mean_rank: 46.515
test final_rank: 25.0
test traces_to_disclosure: nan

Epoch 18 completed.
train loss: 5.523037669796642
train acc: 0.006377229138627187
train rank: 112.41863468764018
train weight_norm: 112.72027554694961
train grad_norm: 0.1706446482525308
train lr: 0.0009262970277047872
val loss: 5.549340486526489
val acc: 0.0033203125
val rank: 126.0974609375
test mean_rank: 10.01
test final_rank: 7.0
test traces_to_disclosure: 391.0

Epoch 20 completed.
train loss: 5.515934918481922
train acc: 0.007318304172274563
train rank: 110.17212034544637
train weight_norm: 115.73472132957141
train grad_norm: 0.20023225717158524
train lr: 0.0009090519584092742
val loss: 5.569261384010315
val acc: 0.0037109375
val rank: 127.20263671875
test mean_rank: 110.636
test final_rank: 82.0
test traces_to_disclosure: nan

Epoch 20 completed.
train loss: 5.515875727780575
train acc: 0.007034404441453567
train rank: 110.16133916554509
train weight_norm: 115.77381616797469
train grad_norm: 0.20041281447735232
train lr: 0.0009090519584092742
val loss: 5.56962513923645
val acc: 0.00361328125
val rank: 127.4462890625
test mean_rank: 156.51
test final_rank: 137.0
test traces_to_disclosure: nan

Epoch 20 completed.
train loss: 5.516076612280003
train acc: 0.007081721063257066
train rank: 110.22441572734408
train weight_norm: 115.5548739884821
train grad_norm: 0.1986372894557186
train lr: 0.0009090519584092742
val loss: 5.56888724565506
val acc: 0.00478515625
val rank: 127.2783203125
test mean_rank: 129.677
test final_rank: 104.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.598, ECE: 0.005
Optimal temperature: 2.438
After temperature - NLL: 5.554, ECE: 0.001
Epoch 24 completed.
train loss: 5.481910810175366
train acc: 0.009500126177658143
train rank: 102.20469696332437
train weight_norm: 122.065152815893
train grad_norm: 0.49936441330441933
train lr: 0.0008697932256900982
val loss: 5.5532244682312015
val acc: 0.004296875
val rank: 127.1134765625
test mean_rank: 144.639
test final_rank: 208.0
test traces_to_disclosure: nan

Epoch 32 completed.
train loss: 5.083373274488693
train acc: 0.03902394571556752
train rank: 62.84829765309556
train weight_norm: 136.53210864881518
train grad_norm: 3.5532790030408683
train lr: 0.0007744912856171929
val loss: 5.915284729003906
val acc: 0.00283203125
val rank: 127.5693359375
test mean_rank: 123.43
test final_rank: 164.0
test traces_to_disclosure: nan

Epoch 28 completed.
train loss: 5.362837634850319
train acc: 0.017554466689098252
train rank: 85.10515155338716
train weight_norm: 129.23233699413169
train grad_norm: 1.4291719871010706
train lr: 0.0008247026328980229
val loss: 5.689982092380523
val acc: 0.00380859375
val rank: 126.54091796875
test mean_rank: 78.79
test final_rank: 69.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.564, ECE: 0.002
Optimal temperature: 1.770
After temperature - NLL: 5.551, ECE: 0.001
Epoch 28 completed.
train loss: 5.366068329817514
train acc: 0.01739674461641992
train rank: 85.44300800527142
train weight_norm: 129.21111996379787
train grad_norm: 1.446667356622387
train lr: 0.0008247026328980229
val loss: 5.692501151561737
val acc: 0.0041015625
val rank: 127.890625
test mean_rank: 71.9
test final_rank: 34.0
test traces_to_disclosure: nan

Epoch 18 completed.
train loss: 5.523008662951586
train acc: 0.006382486541049798
train rank: 112.39449970558546
train weight_norm: 112.77501019129939
train grad_norm: 0.17081942939448785
train lr: 0.0009262970277047872
val loss: 5.549623513221741
val acc: 0.0052734375
val rank: 126.377734375
test mean_rank: 10.775
test final_rank: 7.0
test traces_to_disclosure: 454.0

Before temperature - NLL: 5.602, ECE: 0.006
Optimal temperature: 2.450
After temperature - NLL: 5.555, ECE: 0.003
Before temperature - NLL: 5.563, ECE: 0.003
Optimal temperature: 1.773
After temperature - NLL: 5.550, ECE: 0.002
Epoch 24 completed.
train loss: 5.477944033303139
train acc: 0.009847114737550471
train rank: 101.35259820827726
train weight_norm: 122.26163609252382
train grad_norm: 0.547459687126677
train lr: 0.0008697932256900982
val loss: 5.555043935775757
val acc: 0.0029296875
val rank: 127.82802734375
test mean_rank: 152.11
test final_rank: 198.0
test traces_to_disclosure: nan

Epoch 18 completed.
train loss: 5.522865163846741
train acc: 0.006361456931359354
train rank: 112.35575790713324
train weight_norm: 112.64064211552537
train grad_norm: 0.171481240314997
train lr: 0.0009262970277047872
val loss: 5.5497196316719055
val acc: 0.0029296875
val rank: 126.14775390625
test mean_rank: 11.653
test final_rank: 4.0
test traces_to_disclosure: 473.0

Epoch 33 completed.
train loss: 5.003170744406904
train acc: 0.04651749663526245
train rank: 58.33671734802601
train weight_norm: 138.2817671238337
train grad_norm: 4.097700750700933
train lr: 0.0007612295264283511
val loss: 5.980434787273407
val acc: 0.0037109375
val rank: 127.14521484375
test mean_rank: 117.371
test final_rank: 32.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.568, ECE: 0.003
Optimal temperature: 1.770
After temperature - NLL: 5.552, ECE: 0.001
Epoch 21 completed.
train loss: 5.511628614299871
train acc: 0.007262225213100046
train rank: 108.9610531628533
train weight_norm: 117.21840714955208
train grad_norm: 0.22402671277279307
train lr: 0.0008998195399682029
val loss: 5.5703441262245175
val acc: 0.0033203125
val rank: 126.54091796875
test mean_rank: 152.602
test final_rank: 218.0
test traces_to_disclosure: nan

Epoch 21 completed.
train loss: 5.511475625301274
train acc: 0.007162334567070436
train rank: 108.86918180798565
train weight_norm: 117.26167135970914
train grad_norm: 0.22392402269635203
train lr: 0.0008998195399682029
val loss: 5.572490286827088
val acc: 0.004296875
val rank: 127.03037109375
test mean_rank: 130.212
test final_rank: 181.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.607, ECE: 0.006
Optimal temperature: 2.438
After temperature - NLL: 5.555, ECE: 0.002
Epoch 29 completed.
train loss: 5.314131288156214
train acc: 0.021038372027815166
train rank: 80.05705683602513
train weight_norm: 131.0445590656996
train grad_norm: 1.8577170570808526
train lr: 0.0008126002229375134
val loss: 5.7252411365509035
val acc: 0.0037109375
val rank: 126.5728515625
test mean_rank: 110.412
test final_rank: 195.0
test traces_to_disclosure: nan

Epoch 21 completed.
train loss: 5.511724623504269
train acc: 0.007314799237326156
train rank: 108.9805090567519
train weight_norm: 117.04755674132025
train grad_norm: 0.22276540655537452
train lr: 0.0008998195399682029
val loss: 5.571806478500366
val acc: 0.0037109375
val rank: 126.94736328125
test mean_rank: 141.233
test final_rank: 197.0
test traces_to_disclosure: nan

Epoch 19 completed.
train loss: 5.519781187116538
train acc: 0.006713702893674294
train rank: 111.34700082716466
train weight_norm: 114.20478357569851
train grad_norm: 0.18399698050066293
train lr: 0.000917880691952835
val loss: 5.551843392848968
val acc: 0.00400390625
val rank: 127.42626953125
test mean_rank: 104.418
test final_rank: 229.0
test traces_to_disclosure: nan

Epoch 29 completed.
train loss: 5.309699589278785
train acc: 0.020826323463436516
train rank: 79.61365978297442
train weight_norm: 131.08385752779205
train grad_norm: 1.8104665517062584
train lr: 0.0008126002229375134
val loss: 5.732621800899506
val acc: 0.0033203125
val rank: 126.9263671875
test mean_rank: 145.482
test final_rank: 113.0
test traces_to_disclosure: nan

Epoch 25 completed.
train loss: 5.464865884742378
train acc: 0.010863545872588603
train rank: 99.03954442855539
train weight_norm: 123.76782574524007
train grad_norm: 0.6609348057455529
train lr: 0.0008590410271926295
val loss: 5.554226517677307
val acc: 0.004296875
val rank: 126.6515625
test mean_rank: 83.048
test final_rank: 15.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.568, ECE: 0.003
Optimal temperature: 1.770
After temperature - NLL: 5.552, ECE: 0.001
Before temperature - NLL: 5.616, ECE: 0.006
Optimal temperature: 2.877
After temperature - NLL: 5.553, ECE: 0.001
Epoch 34 completed.
train loss: 4.921753344272701
train acc: 0.054524520524899055
train rank: 54.35876338885151
train weight_norm: 139.97574998475093
train grad_norm: 4.621684843022792
train lr: 0.0007477099652355478
val loss: 6.060827672481537
val acc: 0.00576171875
val rank: 127.38203125
test mean_rank: 121.65
test final_rank: 140.0
test traces_to_disclosure: nan

Epoch 19 completed.
train loss: 5.520001614238179
train acc: 0.006668138739344999
train rank: 111.3978136215792
train weight_norm: 114.25050023267123
train grad_norm: 0.18291249985371438
train lr: 0.000917880691952835
val loss: 5.551666164398194
val acc: 0.00380859375
val rank: 127.29814453125
test mean_rank: 118.399
test final_rank: 214.0
test traces_to_disclosure: nan

Epoch 25 completed.
train loss: 5.458227901407398
train acc: 0.011030030282637954
train rank: 97.83116202613279
train weight_norm: 124.01856461064759
train grad_norm: 0.7318824600362469
train lr: 0.0008590410271926295
val loss: 5.55301798582077
val acc: 0.0037109375
val rank: 127.352734375
test mean_rank: 51.866
test final_rank: 17.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.568, ECE: 0.004
Optimal temperature: 1.773
After temperature - NLL: 5.553, ECE: 0.002
Epoch 30 completed.
train loss: 5.253537073430591
train acc: 0.025698183041722746
train rank: 74.69247525515925
train weight_norm: 132.88731636828558
train grad_norm: 2.284124159213139
train lr: 0.000800189314297648
val loss: 5.776192283630371
val acc: 0.0033203125
val rank: 127.1236328125
test mean_rank: 71.19
test final_rank: 60.0
test traces_to_disclosure: nan

Epoch 19 completed.
train loss: 5.519598211285885
train acc: 0.006613812247644684
train rank: 111.27120836137281
train weight_norm: 114.10771709554966
train grad_norm: 0.1851183407168674
train lr: 0.000917880691952835
val loss: 5.552135491371155
val acc: 0.00341796875
val rank: 127.387890625
test mean_rank: 100.418
test final_rank: 209.0
test traces_to_disclosure: nan

Epoch 22 completed.
train loss: 5.5054681708642645
train acc: 0.008201547779273217
train rank: 107.39613475773889
train weight_norm: 118.7661321164993
train grad_norm: 0.2645992306972565
train lr: 0.0008901925479119812
val loss: 5.577106606960297
val acc: 0.00380859375
val rank: 126.9318359375
test mean_rank: 190.608
test final_rank: 164.0
test traces_to_disclosure: nan

Epoch 22 completed.
train loss: 5.505582596379687
train acc: 0.00786507402422611
train rank: 107.37585870906237
train weight_norm: 118.81667095236813
train grad_norm: 0.26334648651859555
train lr: 0.0008901925479119812
val loss: 5.578447782993317
val acc: 0.00419921875
val rank: 127.22216796875
test mean_rank: 209.119
test final_rank: 180.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.628, ECE: 0.007
Optimal temperature: 2.865
After temperature - NLL: 5.555, ECE: 0.001
Epoch 35 completed.
train loss: 4.841535632414581
train acc: 0.06246495065051592
train rank: 50.765553148833554
train weight_norm: 141.60891710584104
train grad_norm: 5.183227867027388
train lr: 0.0007339459442134423
val loss: 6.124800133705139
val acc: 0.0041015625
val rank: 127.041796875
test mean_rank: 174.401
test final_rank: 141.0
test traces_to_disclosure: nan

Epoch 30 completed.
train loss: 5.248419991412362
train acc: 0.025822608232391204
train rank: 74.24837020524899
train weight_norm: 132.93742598148435
train grad_norm: 2.216367376085307
train lr: 0.000800189314297648
val loss: 5.781149065494537
val acc: 0.00302734375
val rank: 127.02236328125
test mean_rank: 67.349
test final_rank: 13.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.569, ECE: 0.003
Optimal temperature: 2.077
After temperature - NLL: 5.551, ECE: 0.001
Epoch 22 completed.
train loss: 5.505830882214922
train acc: 0.0077178667563930015
train rank: 107.45461459735309
train weight_norm: 118.59160097312551
train grad_norm: 0.2614059101087018
train lr: 0.0008901925479119812
val loss: 5.578951978683472
val acc: 0.004296875
val rank: 127.53515625
test mean_rank: 192.144
test final_rank: 153.0
test traces_to_disclosure: nan

Epoch 26 completed.
train loss: 5.440846742242374
train acc: 0.012023679340511441
train rank: 95.07825293012563
train weight_norm: 125.50597650388188
train grad_norm: 0.8715902033732681
train lr: 0.0008479344985488699
val loss: 5.555005812644959
val acc: 0.00439453125
val rank: 127.26474609375
test mean_rank: 171.694
test final_rank: 195.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.636, ECE: 0.009
Optimal temperature: 2.877
After temperature - NLL: 5.556, ECE: 0.003
Epoch 20 completed.
train loss: 5.5159005021343
train acc: 0.007235938200986991
train rank: 110.08960015702107
train weight_norm: 115.70518183124426
train grad_norm: 0.20237051128226138
train lr: 0.0009090519584092742
val loss: 5.549654603004456
val acc: 0.004296875
val rank: 126.73466796875
test mean_rank: 177.222
test final_rank: 166.0
test traces_to_disclosure: nan

Epoch 26 completed.
train loss: 5.431485636237492
train acc: 0.012549419582772543
train rank: 93.71709567070437
train weight_norm: 125.83251409531387
train grad_norm: 0.9695783588405595
train lr: 0.0008479344985488699
val loss: 5.555967247486114
val acc: 0.0037109375
val rank: 127.53037109375
test mean_rank: 105.518
test final_rank: 144.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.569, ECE: 0.004
Optimal temperature: 2.074
After temperature - NLL: 5.550, ECE: 0.002
Epoch 31 completed.
train loss: 5.183344332077622
train acc: 0.03061210183938986
train rank: 69.36450096736205
train weight_norm: 134.721917159119
train grad_norm: 2.754013276213887
train lr: 0.0007874821550468655
val loss: 5.8281308770179745
val acc: 0.00400390625
val rank: 127.10322265625
test mean_rank: 94.064
test final_rank: 5.0
test traces_to_disclosure: nan

Epoch 20 completed.
train loss: 5.515972993576029
train acc: 0.0070098698968147155
train rank: 110.05795234690444
train weight_norm: 115.72535702240046
train grad_norm: 0.20078238465585527
train lr: 0.0009090519584092742
val loss: 5.5497886657714846
val acc: 0.0037109375
val rank: 126.7681640625
test mean_rank: 185.268
test final_rank: 183.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.569, ECE: 0.004
Optimal temperature: 1.773
After temperature - NLL: 5.553, ECE: 0.003
Epoch 31 completed.
train loss: 5.179337922528807
train acc: 0.03151987999102737
train rank: 69.04232384196949
train weight_norm: 134.77341664558284
train grad_norm: 2.7001009955529307
train lr: 0.0007874821550468655
val loss: 5.841976070404053
val acc: 0.00283203125
val rank: 127.75869140625
test mean_rank: 228.721
test final_rank: 188.0
test traces_to_disclosure: nan

Epoch 36 completed.
train loss: 4.761876405328311
train acc: 0.07001633299685958
train rank: 47.48025670143563
train weight_norm: 143.15951859543358
train grad_norm: 5.625194708189817
train lr: 0.0007199510467890352
val loss: 6.199255084991455
val acc: 0.00439453125
val rank: 126.98623046875
test mean_rank: 170.926
test final_rank: 193.0
test traces_to_disclosure: 6.0

Epoch 20 completed.
train loss: 5.51540316932134
train acc: 0.006787306527590848
train rank: 109.90661801816958
train weight_norm: 115.60765528179718
train grad_norm: 0.20407278866716042
train lr: 0.0009090519584092742
val loss: 5.552019917964936
val acc: 0.0029296875
val rank: 126.90166015625
test mean_rank: 168.841
test final_rank: 190.0
test traces_to_disclosure: nan

Epoch 23 completed.
train loss: 5.497316156389896
train acc: 0.008275151413189772
train rank: 105.48744006561238
train weight_norm: 120.38850206783506
train grad_norm: 0.3199013638995954
train lr: 0.0008801804829194873
val loss: 5.5819604873657225
val acc: 0.0046875
val rank: 126.7501953125
test mean_rank: 159.1
test final_rank: 193.0
test traces_to_disclosure: nan

Epoch 23 completed.
train loss: 5.497186198048444
train acc: 0.008380299461641993
train rank: 105.41664738952444
train weight_norm: 120.34516848148154
train grad_norm: 0.3227841149236816
train lr: 0.0008801804829194873
val loss: 5.580627024173737
val acc: 0.0037109375
val rank: 126.6888671875
test mean_rank: 201.325
test final_rank: 215.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.656, ECE: 0.009
Optimal temperature: 2.867
After temperature - NLL: 5.558, ECE: 0.002
Before temperature - NLL: 5.665, ECE: 0.010
Optimal temperature: 3.373
After temperature - NLL: 5.555, ECE: 0.002
Epoch 27 completed.
train loss: 5.408336928202037
train acc: 0.014394767833109017
train rank: 90.5280640141319
train weight_norm: 127.3092031848443
train grad_norm: 1.1555898291892988
train lr: 0.0008364846005616848
val loss: 5.557843637466431
val acc: 0.00400390625
val rank: 126.871875
test mean_rank: 98.376
test final_rank: 190.0
test traces_to_disclosure: nan

Epoch 27 completed.
train loss: 5.394635404584225
train acc: 0.015132556639748765
train rank: 88.7866037881337
train weight_norm: 127.64866240733825
train grad_norm: 1.2747880269540277
train lr: 0.0008364846005616848
val loss: 5.553959453105927
val acc: 0.0041015625
val rank: 126.6123046875
test mean_rank: 163.64
test final_rank: 156.0
test traces_to_disclosure: nan

Epoch 32 completed.
train loss: 5.109591939086709
train acc: 0.03657750112157919
train rank: 64.4078184583894
train weight_norm: 136.53413201618793
train grad_norm: 3.2722615026854864
train lr: 0.0007744912856171929
val loss: 5.885812377929687
val acc: 0.003515625
val rank: 126.51240234375
test mean_rank: 132.664
test final_rank: 199.0
test traces_to_disclosure: nan

Epoch 23 completed.
train loss: 5.497800686478134
train acc: 0.008481942575145805
train rank: 105.53131133636158
train weight_norm: 120.16059737730995
train grad_norm: 0.317315906035545
train lr: 0.0008801804829194873
val loss: 5.5807682275772095
val acc: 0.00498046875
val rank: 126.55654296875
test mean_rank: 151.574
test final_rank: 176.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.572, ECE: 0.003
Optimal temperature: 2.077
After temperature - NLL: 5.551, ECE: 0.001
Epoch 37 completed.
train loss: 4.684225657425851
train acc: 0.0775992597577389
train rank: 44.59056927153432
train weight_norm: 144.63578519645657
train grad_norm: 6.178957130960254
train lr: 0.0007057390842364583
val loss: 6.27899022102356
val acc: 0.0029296875
val rank: 126.8228515625
test mean_rank: 22.641
test final_rank: 4.0
test traces_to_disclosure: 698.0

Epoch 32 completed.
train loss: 5.1056204535277665
train acc: 0.03698933097801704
train rank: 64.22525691173172
train weight_norm: 136.5853445091032
train grad_norm: 3.1516782809571797
train lr: 0.0007744912856171929
val loss: 5.899505054950714
val acc: 0.00419921875
val rank: 127.40830078125
test mean_rank: 104.968
test final_rank: 130.0
test traces_to_disclosure: nan

Epoch 21 completed.
train loss: 5.511246649124741
train acc: 0.00756014468371467
train rank: 108.86588366419919
train weight_norm: 117.2372005120524
train grad_norm: 0.22906232129896262
train lr: 0.0008998195399682029
val loss: 5.550212562084198
val acc: 0.00537109375
val rank: 126.707421875
test mean_rank: 133.279
test final_rank: 122.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.572, ECE: 0.004
Optimal temperature: 2.074
After temperature - NLL: 5.551, ECE: 0.002
Before temperature - NLL: 5.691, ECE: 0.011
Optimal temperature: 3.371
After temperature - NLL: 5.558, ECE: 0.002
Epoch 21 completed.
train loss: 5.511638502092734
train acc: 0.007418194818304172
train rank: 108.9940486204576
train weight_norm: 117.24967700060081
train grad_norm: 0.2275022885767567
train lr: 0.0008998195399682029
val loss: 5.549987304210663
val acc: 0.00390625
val rank: 126.65439453125
test mean_rank: 134.807
test final_rank: 163.0
test traces_to_disclosure: nan

Epoch 28 completed.
train loss: 5.365545138696643
train acc: 0.017014706707043515
train rank: 85.36834412853297
train weight_norm: 129.12640328612633
train grad_norm: 1.541401920110668
train lr: 0.0008247026328980229
val loss: 5.5575479388237
val acc: 0.00390625
val rank: 127.253515625
test mean_rank: 27.982
test final_rank: 51.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.571, ECE: 0.002
Optimal temperature: 2.077
After temperature - NLL: 5.551, ECE: 0.000
Before temperature - NLL: 5.700, ECE: 0.012
Optimal temperature: 3.374
After temperature - NLL: 5.559, ECE: 0.002
Epoch 24 completed.
train loss: 5.486077880474311
train acc: 0.009042732166890983
train rank: 102.96824704183491
train weight_norm: 122.02232264538641
train grad_norm: 0.4032269905756299
train lr: 0.0008697932256900982
val loss: 5.592528069019318
val acc: 0.003515625
val rank: 127.006640625
test mean_rank: 184.548
test final_rank: 104.0
test traces_to_disclosure: nan

Epoch 24 completed.
train loss: 5.485916252572636
train acc: 0.008942841520861373
train rank: 102.93790832492148
train weight_norm: 121.97736682234626
train grad_norm: 0.40972028707411556
train lr: 0.0008697932256900982
val loss: 5.589674043655395
val acc: 0.00341796875
val rank: 126.24404296875
test mean_rank: 155.5
test final_rank: 118.0
test traces_to_disclosure: nan

Epoch 33 completed.
train loss: 5.029967228464612
train acc: 0.044332169694930465
train rank: 59.79657532806191
train weight_norm: 138.3015079566868
train grad_norm: 3.8102656495252036
train lr: 0.0007612295264283511
val loss: 5.958461201190948
val acc: 0.0041015625
val rank: 126.86572265625
test mean_rank: 161.37
test final_rank: 104.0
test traces_to_disclosure: nan

Epoch 21 completed.
train loss: 5.510596653333743
train acc: 0.007665292732166891
train rank: 108.72227596455808
train weight_norm: 117.13407894358159
train grad_norm: 0.23280380568690412
train lr: 0.0008998195399682029
val loss: 5.550393736362457
val acc: 0.00478515625
val rank: 126.980078125
test mean_rank: 70.17
test final_rank: 54.0
test traces_to_disclosure: nan

Epoch 38 completed.
train loss: 4.610555187369099
train acc: 0.08560102624495289
train rank: 42.05512561686855
train weight_norm: 146.04500101749957
train grad_norm: 6.6985367016740645
train lr: 0.0006913240820469203
val loss: 6.343096303939819
val acc: 0.00322265625
val rank: 126.14296875
test mean_rank: 198.264
test final_rank: 179.0
test traces_to_disclosure: nan

Epoch 28 completed.
train loss: 5.347755668943053
train acc: 0.01846750224315837
train rank: 83.49071542732167
train weight_norm: 129.52717126901382
train grad_norm: 1.6579526330652168
train lr: 0.0008247026328980229
val loss: 5.5584202885627745
val acc: 0.0052734375
val rank: 127.4783203125
test mean_rank: 32.7
test final_rank: 6.0
test traces_to_disclosure: nan

Epoch 33 completed.
train loss: 5.027990295620658
train acc: 0.043427896478241364
train rank: 59.613072706370566
train weight_norm: 138.33785864807575
train grad_norm: 3.762388030047327
train lr: 0.0007612295264283511
val loss: 5.968827712535858
val acc: 0.00517578125
val rank: 127.61005859375
test mean_rank: 219.543
test final_rank: 167.0
test traces_to_disclosure: nan

Epoch 24 completed.
train loss: 5.48674518102592
train acc: 0.00903221736204576
train rank: 103.13492247083896
train weight_norm: 121.79270926148196
train grad_norm: 0.40081280413431664
train lr: 0.0008697932256900982
val loss: 5.591582155227661
val acc: 0.00546875
val rank: 127.230078125
test mean_rank: 189.389
test final_rank: 112.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.728, ECE: 0.014
Optimal temperature: 3.372
After temperature - NLL: 5.561, ECE: 0.002
Before temperature - NLL: 5.580, ECE: 0.004
Optimal temperature: 2.077
After temperature - NLL: 5.553, ECE: 0.002
Before temperature - NLL: 5.580, ECE: 0.003
Optimal temperature: 2.074
After temperature - NLL: 5.553, ECE: 0.001
Epoch 29 completed.
train loss: 5.3144797335402645
train acc: 0.020514384253028265
train rank: 80.02623268562135
train weight_norm: 130.95704681756888
train grad_norm: 1.9294058544130215
train lr: 0.0008126002229375134
val loss: 5.56047271490097
val acc: 0.00390625
val rank: 127.17294921875
test mean_rank: 99.108
test final_rank: 205.0
test traces_to_disclosure: nan

Epoch 22 completed.
train loss: 5.5043327400854425
train acc: 0.008127944145356662
train rank: 107.03501955753701
train weight_norm: 118.7727097211191
train grad_norm: 0.2720558176262935
train lr: 0.0008901925479119812
val loss: 5.552278673648834
val acc: 0.00380859375
val rank: 126.89853515625
test mean_rank: 13.578
test final_rank: 3.0
test traces_to_disclosure: nan

Epoch 22 completed.
train loss: 5.505072579569964
train acc: 0.007681064939434724
train rank: 107.20425358905338
train weight_norm: 118.78920157451259
train grad_norm: 0.26528484426137416
train lr: 0.0008901925479119812
val loss: 5.5522189259529116
val acc: 0.0046875
val rank: 126.9130859375
test mean_rank: 9.573
test final_rank: 2.0
test traces_to_disclosure: 725.0

Epoch 39 completed.
train loss: 4.537610923618199
train acc: 0.0949819846343652
train rank: 39.77269620625841
train weight_norm: 147.3703262515027
train grad_norm: 7.099521439545265
train lr: 0.0006767202660872397
val loss: 6.416797339916229
val acc: 0.00380859375
val rank: 126.37744140625
test mean_rank: 222.153
test final_rank: 230.0
test traces_to_disclosure: nan

Epoch 34 completed.
train loss: 4.949388873047655
train acc: 0.05193437359802602
train rank: 55.63008916554509
train weight_norm: 140.01109891118293
train grad_norm: 4.349025897501503
train lr: 0.0007477099652355478
val loss: 6.031477308273315
val acc: 0.00498046875
val rank: 127.2564453125
test mean_rank: 81.273
test final_rank: 89.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.749, ECE: 0.017
Optimal temperature: 3.970
After temperature - NLL: 5.558, ECE: 0.003
Epoch 34 completed.
train loss: 4.947280025097114
train acc: 0.050525389748766254
train rank: 55.44884722689546
train weight_norm: 140.04195400662533
train grad_norm: 4.235478282709006
train lr: 0.0007477099652355478
val loss: 6.043337488174439
val acc: 0.0046875
val rank: 127.521875
test mean_rank: 77.611
test final_rank: 143.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.580, ECE: 0.004
Optimal temperature: 2.078
After temperature - NLL: 5.553, ECE: 0.001
Epoch 29 completed.
train loss: 5.2911350133441495
train acc: 0.022512197173620456
train rank: 78.03936918180798
train weight_norm: 131.38456308710963
train grad_norm: 2.0820400884121995
train lr: 0.0008126002229375134
val loss: 5.557781100273132
val acc: 0.00380859375
val rank: 127.3796875
test mean_rank: 117.868
test final_rank: 198.0
test traces_to_disclosure: nan

Epoch 25 completed.
train loss: 5.471408377425346
train acc: 0.010222142777030058
train rank: 100.20577122588607
train weight_norm: 123.70975385401339
train grad_norm: 0.5265868083175936
train lr: 0.0008590410271926295
val loss: 5.601291131973267
val acc: 0.003125
val rank: 126.7189453125
test mean_rank: 17.64
test final_rank: 45.0
test traces_to_disclosure: nan

Epoch 25 completed.
train loss: 5.470693465036467
train acc: 0.010330795760430686
train rank: 100.00683988055182
train weight_norm: 123.64796172437526
train grad_norm: 0.530524131757003
train lr: 0.0008590410271926295
val loss: 5.604205930233002
val acc: 0.0046875
val rank: 127.318359375
test mean_rank: 74.641
test final_rank: 132.0
test traces_to_disclosure: nan

Epoch 22 completed.
train loss: 5.503641664420291
train acc: 0.007623233512786003
train rank: 106.84012589726333
train weight_norm: 118.69729767286775
train grad_norm: 0.27422795694607766
train lr: 0.0008901925479119812
val loss: 5.552515506744385
val acc: 0.00390625
val rank: 126.9697265625
test mean_rank: 27.252
test final_rank: 10.0
test traces_to_disclosure: 0.0

Epoch 40 completed.
train loss: 4.474155894519503
train acc: 0.10041463380439658
train rank: 37.8358901833782
train weight_norm: 148.62904632559605
train grad_norm: 7.6698949695681
train lr: 0.0006619420485606271
val loss: 6.50072717666626
val acc: 0.00302734375
val rank: 126.96982421875
test mean_rank: 197.495
test final_rank: 219.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.775, ECE: 0.017
Optimal temperature: 3.962
After temperature - NLL: 5.560, ECE: 0.002
Epoch 25 completed.
train loss: 5.472468596929496
train acc: 0.010052153432032302
train rank: 100.33772151188876
train weight_norm: 123.4341951070595
train grad_norm: 0.5176361284951586
train lr: 0.0008590410271926295
val loss: 5.60220981836319
val acc: 0.00390625
val rank: 127.2287109375
test mean_rank: 25.791
test final_rank: 49.0
test traces_to_disclosure: nan

Epoch 30 completed.
train loss: 5.251273318222682
train acc: 0.025128631112606548
train rank: 74.49055420031404
train weight_norm: 132.7780699949595
train grad_norm: 2.3941312786129183
train lr: 0.000800189314297648
val loss: 5.558946490287781
val acc: 0.00439453125
val rank: 127.063671875
test mean_rank: 200.097
test final_rank: 226.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.581, ECE: 0.003
Optimal temperature: 2.075
After temperature - NLL: 5.552, ECE: 0.000
Epoch 35 completed.
train loss: 4.867709069361116
train acc: 0.05876373934499775
train rank: 51.8152110671826
train weight_norm: 141.6923502872474
train grad_norm: 4.716729578252527
train lr: 0.0007339459442134423
val loss: 6.112760448455811
val acc: 0.0033203125
val rank: 127.3697265625
test mean_rank: 246.109
test final_rank: 252.0
test traces_to_disclosure: nan

Epoch 35 completed.
train loss: 4.8688544020518
train acc: 0.059117737774786905
train rank: 51.91226797330642
train weight_norm: 141.6572438008814
train grad_norm: 4.877295098893525
train lr: 0.0007339459442134423
val loss: 6.101281869411468
val acc: 0.00439453125
val rank: 127.46826171875
test mean_rank: 197.885
test final_rank: 147.0
test traces_to_disclosure: 1.0

Before temperature - NLL: 5.582, ECE: 0.004
Optimal temperature: 2.077
After temperature - NLL: 5.553, ECE: 0.001
Before temperature - NLL: 5.792, ECE: 0.019
Optimal temperature: 3.971
After temperature - NLL: 5.560, ECE: 0.003
Epoch 23 completed.
train loss: 5.496837229619597
train acc: 0.008587090623598026
train rank: 105.27984802602064
train weight_norm: 120.37812934077331
train grad_norm: 0.32665817667982433
train lr: 0.0008801804829194873
val loss: 5.551903760433197
val acc: 0.0052734375
val rank: 126.46435546875
test mean_rank: 30.597
test final_rank: 11.0
test traces_to_disclosure: nan

Epoch 23 completed.
train loss: 5.495670043924775
train acc: 0.0085275067294751
train rank: 105.0038589333782
train weight_norm: 120.37991657587573
train grad_norm: 0.33516201530961026
train lr: 0.0008801804829194873
val loss: 5.552239000797272
val acc: 0.0046875
val rank: 126.405859375
test mean_rank: 18.176
test final_rank: 5.0
test traces_to_disclosure: nan

Epoch 30 completed.
train loss: 5.224105216933773
train acc: 0.027303443248093317
train rank: 72.44969717362046
train weight_norm: 133.2799719094176
train grad_norm: 2.5920751772988266
train lr: 0.000800189314297648
val loss: 5.559289300441742
val acc: 0.00458984375
val rank: 126.86552734375
test mean_rank: 190.318
test final_rank: 178.0
test traces_to_disclosure: nan

Epoch 41 completed.
train loss: 4.408084555557887
train acc: 0.10890358624943923
train rank: 36.03689995513683
train weight_norm: 149.8050849773832
train grad_norm: 7.933776943127439
train lr: 0.0006470040137835858
val loss: 6.582879841327667
val acc: 0.0033203125
val rank: 127.15107421875
test mean_rank: 182.293
test final_rank: 157.0
test traces_to_disclosure: nan

Epoch 26 completed.
train loss: 5.449742153547654
train acc: 0.011610097016599371
train rank: 96.49055770524899
train weight_norm: 125.41604604396751
train grad_norm: 0.6860320818961722
train lr: 0.0008479344985488699
val loss: 5.618296957015991
val acc: 0.003515625
val rank: 126.91328125
test mean_rank: 88.669
test final_rank: 122.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.583, ECE: 0.005
Optimal temperature: 2.079
After temperature - NLL: 5.553, ECE: 0.002
Epoch 26 completed.
train loss: 5.449108388831445
train acc: 0.011653908703454466
train rank: 96.34583894122926
train weight_norm: 125.36972632842414
train grad_norm: 0.7026267433940949
train lr: 0.0008479344985488699
val loss: 5.621544492244721
val acc: 0.00419921875
val rank: 127.25830078125
test mean_rank: 112.64
test final_rank: 140.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.830, ECE: 0.022
Optimal temperature: 3.962
After temperature - NLL: 5.563, ECE: 0.003
Epoch 23 completed.
train loss: 5.494690930378068
train acc: 0.008392566733961418
train rank: 104.81262092025572
train weight_norm: 120.2962345901544
train grad_norm: 0.33881755996878493
train lr: 0.0008801804829194873
val loss: 5.553214955329895
val acc: 0.00400390625
val rank: 126.91162109375
test mean_rank: 34.208
test final_rank: 24.0
test traces_to_disclosure: nan

Epoch 36 completed.
train loss: 4.789003493487434
train acc: 0.06729475100942127
train rank: 48.540369840735764
train weight_norm: 143.2214598135271
train grad_norm: 5.494850256644762
train lr: 0.0007199510467890352
val loss: 6.172842752933502
val acc: 0.003515625
val rank: 127.04248046875
test mean_rank: 252.957
test final_rank: 252.0
test traces_to_disclosure: nan

Epoch 31 completed.
train loss: 5.183513677938469
train acc: 0.030771576379542396
train rank: 69.40509862886945
train weight_norm: 134.62312714324904
train grad_norm: 2.8956997898247843
train lr: 0.0007874821550468655
val loss: 5.562899398803711
val acc: 0.00322265625
val rank: 127.0951171875
test mean_rank: 218.62
test final_rank: 176.0
test traces_to_disclosure: nan

Epoch 26 completed.
train loss: 5.451442475273985
train acc: 0.011708235195154779
train rank: 96.71540804452671
train weight_norm: 125.11923491260477
train grad_norm: 0.6792801870465663
train lr: 0.0008479344985488699
val loss: 5.621872401237487
val acc: 0.00380859375
val rank: 127.48193359375
test mean_rank: 96.281
test final_rank: 162.0
test traces_to_disclosure: nan

Epoch 36 completed.
train loss: 4.791256604894174
train acc: 0.06639573519515478
train rank: 48.59875679957379
train weight_norm: 143.25853594258783
train grad_norm: 5.166820944282956
train lr: 0.0007199510467890352
val loss: 6.182458972930908
val acc: 0.0041015625
val rank: 127.41337890625
test mean_rank: 208.621
test final_rank: 203.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.860, ECE: 0.023
Optimal temperature: 3.974
After temperature - NLL: 5.566, ECE: 0.003
Before temperature - NLL: 5.594, ECE: 0.004
Optimal temperature: 2.440
After temperature - NLL: 5.553, ECE: 0.001
Epoch 31 completed.
train loss: 5.150779169629432
train acc: 0.033193486428891875
train rank: 67.08498240522655
train weight_norm: 135.12970440624653
train grad_norm: 3.10458863090189
train lr: 0.0007874821550468655
val loss: 5.564286315441132
val acc: 0.0037109375
val rank: 127.202734375
test mean_rank: 173.987
test final_rank: 174.0
test traces_to_disclosure: nan

Epoch 42 completed.
train loss: 4.343888842401722
train acc: 0.11638837483176312
train rank: 34.28331791161956
train weight_norm: 150.92215507120162
train grad_norm: 8.370772594248361
train lr: 0.0006319209037929501
val loss: 6.645669722557068
val acc: 0.0029296875
val rank: 127.2662109375
test mean_rank: 137.524
test final_rank: 168.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.593, ECE: 0.005
Optimal temperature: 2.438
After temperature - NLL: 5.553, ECE: 0.002
Epoch 24 completed.
train loss: 5.484086604651019
train acc: 0.009484353970390309
train rank: 102.58802468876178
train weight_norm: 122.03212782232588
train grad_norm: 0.4266318621128647
train lr: 0.0008697932256900982
val loss: 5.552888119220734
val acc: 0.0041015625
val rank: 127.25537109375
test mean_rank: 157.057
test final_rank: 209.0
test traces_to_disclosure: nan

Epoch 24 completed.
train loss: 5.485505417250047
train acc: 0.009258285666218035
train rank: 102.91898868606998
train weight_norm: 122.02593857360463
train grad_norm: 0.4136206418671683
train lr: 0.0008697932256900982
val loss: 5.552733790874481
val acc: 0.003515625
val rank: 127.24560546875
test mean_rank: 196.102
test final_rank: 229.0
test traces_to_disclosure: nan

Epoch 37 completed.
train loss: 4.712273025897759
train acc: 0.07561196164199192
train rank: 45.64422281572453
train weight_norm: 144.72360482217206
train grad_norm: 5.896601243872295
train lr: 0.0007057390842364583
val loss: 6.248528158664703
val acc: 0.0044921875
val rank: 127.33154296875
test mean_rank: 180.133
test final_rank: 108.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.884, ECE: 0.027
Optimal temperature: 3.964
After temperature - NLL: 5.565, ECE: 0.004
Epoch 27 completed.
train loss: 5.422151394198432
train acc: 0.01322937696276357
train rank: 92.35330620513682
train weight_norm: 127.16334186231975
train grad_norm: 0.9169103915800475
train lr: 0.0008364846005616848
val loss: 5.637844669818878
val acc: 0.002734375
val rank: 126.5939453125
test mean_rank: 194.011
test final_rank: 229.0
test traces_to_disclosure: nan

Epoch 27 completed.
train loss: 5.420034335407242
train acc: 0.013532553835800808
train rank: 92.1165618691117
train weight_norm: 127.11770884214063
train grad_norm: 0.9338386059792005
train lr: 0.0008364846005616848
val loss: 5.6403938174247745
val acc: 0.0041015625
val rank: 127.30498046875
test mean_rank: 178.038
test final_rank: 189.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.596, ECE: 0.005
Optimal temperature: 2.443
After temperature - NLL: 5.554, ECE: 0.002
Epoch 32 completed.
train loss: 5.109236287236374
train acc: 0.03695077669358457
train rank: 64.46008404834006
train weight_norm: 136.41203389683483
train grad_norm: 3.4320542786015005
train lr: 0.0007744912856171929
val loss: 5.564905965328217
val acc: 0.00322265625
val rank: 126.36298828125
test mean_rank: 166.622
test final_rank: 132.0
test traces_to_disclosure: nan

Epoch 37 completed.
train loss: 4.714483095531027
train acc: 0.07425029441453566
train rank: 45.65415930630327
train weight_norm: 144.74834700716426
train grad_norm: 5.626353564080298
train lr: 0.0007057390842364583
val loss: 6.262645018100739
val acc: 0.00263671875
val rank: 127.80615234375
test mean_rank: 94.414
test final_rank: 11.0
test traces_to_disclosure: nan

Epoch 43 completed.
train loss: 4.282974588116919
train acc: 0.1239099652310453
train rank: 32.74113076211305
train weight_norm: 151.9805546031285
train grad_norm: 8.617899960883834
train lr: 0.000616707603797273
val loss: 6.70455778837204
val acc: 0.00234375
val rank: 126.63125
test mean_rank: 108.361
test final_rank: 95.0
test traces_to_disclosure: nan

Epoch 24 completed.
train loss: 5.482644063146085
train acc: 0.009510640982503364
train rank: 102.31415783423061
train weight_norm: 121.9589129844178
train grad_norm: 0.4305019209800551
train lr: 0.0008697932256900982
val loss: 5.553667163848877
val acc: 0.004296875
val rank: 127.60732421875
test mean_rank: 195.498
test final_rank: 221.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.923, ECE: 0.028
Optimal temperature: 4.673
After temperature - NLL: 5.563, ECE: 0.003
Epoch 27 completed.
train loss: 5.423056392618336
train acc: 0.012859606325706594
train rank: 92.41963885150291
train weight_norm: 126.85534377658377
train grad_norm: 0.8971720813596622
train lr: 0.0008364846005616848
val loss: 5.642418670654297
val acc: 0.0033203125
val rank: 127.57158203125
test mean_rank: 219.781
test final_rank: 236.0
test traces_to_disclosure: nan

Epoch 32 completed.
train loss: 5.0733476885234685
train acc: 0.04000007009869897
train rank: 62.34691145132346
train weight_norm: 136.93982278227153
train grad_norm: 3.6816884001548984
train lr: 0.0007744912856171929
val loss: 5.56123389005661
val acc: 0.0048828125
val rank: 127.14599609375
test mean_rank: 109.933
test final_rank: 96.0
test traces_to_disclosure: nan

Epoch 38 completed.
train loss: 4.63546493460962
train acc: 0.08342971904441454
train rank: 42.925816299349485
train weight_norm: 146.14743672833148
train grad_norm: 6.320946469682282
train lr: 0.0006913240820469203
val loss: 6.32492413520813
val acc: 0.0048828125
val rank: 127.41630859375
test mean_rank: 130.096
test final_rank: 84.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.605, ECE: 0.006
Optimal temperature: 2.441
After temperature - NLL: 5.554, ECE: 0.002
Before temperature - NLL: 5.603, ECE: 0.006
Optimal temperature: 2.438
After temperature - NLL: 5.554, ECE: 0.001
Epoch 25 completed.
train loss: 5.467341969183284
train acc: 0.010383369784656796
train rank: 99.31267524674743
train weight_norm: 123.73318147191834
train grad_norm: 0.5575570260442261
train lr: 0.0008590410271926295
val loss: 5.553306353092194
val acc: 0.00380859375
val rank: 126.23994140625
test mean_rank: 38.573
test final_rank: 8.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.964, ECE: 0.031
Optimal temperature: 4.667
After temperature - NLL: 5.565, ECE: 0.003
Epoch 25 completed.
train loss: 5.469953061433692
train acc: 0.010136271870794078
train rank: 99.84067967698519
train weight_norm: 123.72380327091136
train grad_norm: 0.5367025069064358
train lr: 0.0008590410271926295
val loss: 5.553149747848511
val acc: 0.00400390625
val rank: 126.59091796875
test mean_rank: 59.662
test final_rank: 7.0
test traces_to_disclosure: nan

Epoch 38 completed.
train loss: 4.642071180356464
train acc: 0.08138984690444145
train rank: 43.09569874383131
train weight_norm: 146.16126822060474
train grad_norm: 6.208567202050127
train lr: 0.0006913240820469203
val loss: 6.315211987495422
val acc: 0.00322265625
val rank: 126.72197265625
test mean_rank: 80.219
test final_rank: 75.0
test traces_to_disclosure: 116.0

Epoch 44 completed.
train loss: 4.226680438579493
train acc: 0.13069902422611035
train rank: 31.399818444369668
train weight_norm: 152.9745393813393
train grad_norm: 9.202561375949319
train lr: 0.0006013791274869292
val loss: 6.7825472235679625
val acc: 0.00263671875
val rank: 127.13173828125
test mean_rank: 115.687
test final_rank: 175.0
test traces_to_disclosure: nan

Epoch 28 completed.
train loss: 5.38367208593787
train acc: 0.01577220726783311
train rank: 87.41095537516824
train weight_norm: 128.9117021329188
train grad_norm: 1.1756611123416174
train lr: 0.0008247026328980229
val loss: 5.674975180625916
val acc: 0.0033203125
val rank: 127.3798828125
test mean_rank: 104.287
test final_rank: 87.0
test traces_to_disclosure: nan

Epoch 33 completed.
train loss: 5.030271659147691
train acc: 0.0437310733512786
train rank: 59.79611267664872
train weight_norm: 138.17118437896903
train grad_norm: 4.014490111757074
train lr: 0.0007612295264283511
val loss: 5.564877545833587
val acc: 0.0025390625
val rank: 127.33349609375
test mean_rank: 104.479
test final_rank: 19.0
test traces_to_disclosure: nan

Epoch 28 completed.
train loss: 5.381412119756316
train acc: 0.016508243606998655
train rank: 87.13053954968595
train weight_norm: 128.8858162831755
train grad_norm: 1.213454752095117
train lr: 0.0008247026328980229
val loss: 5.676056909561157
val acc: 0.0044921875
val rank: 127.77197265625
test mean_rank: 134.722
test final_rank: 182.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.991, ECE: 0.034
Optimal temperature: 4.673
After temperature - NLL: 5.566, ECE: 0.004
Epoch 28 completed.
train loss: 5.384643684325597
train acc: 0.015975493494840738
train rank: 87.53698232110813
train weight_norm: 128.61750798221766
train grad_norm: 1.1690764232942608
train lr: 0.0008247026328980229
val loss: 5.678188812732697
val acc: 0.00390625
val rank: 127.4791015625
test mean_rank: 105.657
test final_rank: 159.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.606, ECE: 0.006
Optimal temperature: 2.444
After temperature - NLL: 5.554, ECE: 0.002
Epoch 33 completed.
train loss: 4.992722191688671
train acc: 0.047516403095558546
train rank: 57.891078889075814
train weight_norm: 138.71840043060448
train grad_norm: 4.174341878097164
train lr: 0.0007612295264283511
val loss: 5.565263855457306
val acc: 0.005078125
val rank: 127.35830078125
test mean_rank: 136.295
test final_rank: 100.0
test traces_to_disclosure: nan

Epoch 39 completed.
train loss: 4.562291608684637
train acc: 0.09138942631224764
train rank: 40.57142181191117
train weight_norm: 147.49994633009575
train grad_norm: 6.836131131483872
train lr: 0.0006767202660872397
val loss: 6.4011748194694515
val acc: 0.00458984375
val rank: 127.7375
test mean_rank: 233.13
test final_rank: 247.0
test traces_to_disclosure: nan

Epoch 25 completed.
train loss: 5.465459547646113
train acc: 0.01039388458950202
train rank: 99.0305963296321
train weight_norm: 123.64681296634868
train grad_norm: 0.5596628872214434
train lr: 0.0008590410271926295
val loss: 5.554138505458832
val acc: 0.0037109375
val rank: 126.62119140625
test mean_rank: 64.173
test final_rank: 7.0
test traces_to_disclosure: nan

Epoch 45 completed.
train loss: 4.173356778528617
train acc: 0.13837483176312249
train rank: 30.17402352512337
train weight_norm: 153.9123128487009
train grad_norm: 9.377798381972847
train lr: 0.0005859506022174055
val loss: 6.830564463138581
val acc: 0.00302734375
val rank: 126.70908203125
test mean_rank: 35.314
test final_rank: 2.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.622, ECE: 0.007
Optimal temperature: 2.865
After temperature - NLL: 5.554, ECE: 0.002
Epoch 39 completed.
train loss: 4.567605334367919
train acc: 0.09056751906684611
train rank: 40.66997182032301
train weight_norm: 147.50669537234796
train grad_norm: 6.569807578033835
train lr: 0.0006767202660872397
val loss: 6.404614293575287
val acc: 0.00322265625
val rank: 126.8900390625
test mean_rank: 228.186
test final_rank: 252.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.034, ECE: 0.036
Optimal temperature: 4.668
After temperature - NLL: 5.568, ECE: 0.003
Before temperature - NLL: 5.623, ECE: 0.006
Optimal temperature: 2.866
After temperature - NLL: 5.554, ECE: 0.001
Epoch 26 completed.
train loss: 5.448097467101599
train acc: 0.011366504037685061
train rank: 96.22650642104084
train weight_norm: 125.44005733438401
train grad_norm: 0.712677928598013
train lr: 0.0008479344985488699
val loss: 5.554497337341308
val acc: 0.00380859375
val rank: 127.54013671875
test mean_rank: 97.214
test final_rank: 132.0
test traces_to_disclosure: nan

Epoch 34 completed.
train loss: 4.95110834655659
train acc: 0.0516382065948856
train rank: 55.74286219997756
train weight_norm: 139.8923479681735
train grad_norm: 4.558649697459128
train lr: 0.0007477099652355478
val loss: 5.568943107128144
val acc: 0.004296875
val rank: 127.74580078125
test mean_rank: 161.055
test final_rank: 139.0
test traces_to_disclosure: nan

Epoch 26 completed.
train loss: 5.444368468319262
train acc: 0.011589067406908926
train rank: 95.60601551985195
train weight_norm: 125.4796373614998
train grad_norm: 0.7403923840933403
train lr: 0.0008479344985488699
val loss: 5.553499293327332
val acc: 0.00439453125
val rank: 126.81845703125
test mean_rank: 78.534
test final_rank: 33.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.069, ECE: 0.040
Optimal temperature: 4.674
After temperature - NLL: 5.570, ECE: 0.004
Epoch 29 completed.
train loss: 5.336719844094196
train acc: 0.01893541105877075
train rank: 82.24924468651862
train weight_norm: 130.6899898151322
train grad_norm: 1.5078935170502072
train lr: 0.0008126002229375134
val loss: 5.706682550907135
val acc: 0.00390625
val rank: 126.60478515625
test mean_rank: 198.03
test final_rank: 181.0
test traces_to_disclosure: nan

Epoch 29 completed.
train loss: 5.332920899140883
train acc: 0.019594338829071332
train rank: 81.87587097633468
train weight_norm: 130.68458670798825
train grad_norm: 1.5500148146286563
train lr: 0.0008126002229375134
val loss: 5.701669728755951
val acc: 0.00400390625
val rank: 126.51767578125
test mean_rank: 140.564
test final_rank: 117.0
test traces_to_disclosure: nan

Epoch 40 completed.
train loss: 4.495012238401102
train acc: 0.09900915489008526
train rank: 38.50365739961867
train weight_norm: 148.7744397207434
train grad_norm: 7.363062372106167
train lr: 0.0006619420485606271
val loss: 6.48587019443512
val acc: 0.00380859375
val rank: 127.8857421875
test mean_rank: 146.798
test final_rank: 184.0
test traces_to_disclosure: nan

Epoch 29 completed.
train loss: 5.33800210477847
train acc: 0.01927013234634365
train rank: 82.33860475549574
train weight_norm: 130.40961820106668
train grad_norm: 1.501129637764324
train lr: 0.0008126002229375134
val loss: 5.7041658639907835
val acc: 0.0044921875
val rank: 127.27236328125
test mean_rank: 177.111
test final_rank: 177.0
test traces_to_disclosure: nan

Epoch 34 completed.
train loss: 4.909996319587266
train acc: 0.055521674517720956
train rank: 53.815449402759086
train weight_norm: 140.421803713179
train grad_norm: 4.780467038433333
train lr: 0.0007477099652355478
val loss: 5.569005620479584
val acc: 0.0046875
val rank: 127.68037109375
test mean_rank: 149.341
test final_rank: 82.0
test traces_to_disclosure: nan

Epoch 46 completed.
train loss: 4.117142518468372
train acc: 0.14541274113952443
train rank: 28.934741616195605
train weight_norm: 154.79939637063433
train grad_norm: 9.720826507580277
train lr: 0.0005704372540804354
val loss: 6.914367616176605
val acc: 0.002734375
val rank: 127.29033203125
test mean_rank: 112.599
test final_rank: 164.0
test traces_to_disclosure: nan

Epoch 40 completed.
train loss: 4.501568402769107
train acc: 0.09741265702108567
train rank: 38.630019066846124
train weight_norm: 148.78898835010622
train grad_norm: 7.066684209938977
train lr: 0.0006619420485606271
val loss: 6.472370910644531
val acc: 0.00322265625
val rank: 126.739453125
test mean_rank: 91.379
test final_rank: 122.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.622, ECE: 0.007
Optimal temperature: 2.861
After temperature - NLL: 5.553, ECE: 0.002
Epoch 26 completed.
train loss: 5.4420615603111955
train acc: 0.011899254149842978
train rank: 95.26086004093763
train weight_norm: 125.39128501204168
train grad_norm: 0.7432503833203755
train lr: 0.0008479344985488699
val loss: 5.553562438488006
val acc: 0.003515625
val rank: 126.88056640625
test mean_rank: 94.524
test final_rank: 104.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.101, ECE: 0.041
Optimal temperature: 4.670
After temperature - NLL: 5.571, ECE: 0.003
Before temperature - NLL: 5.645, ECE: 0.008
Optimal temperature: 2.865
After temperature - NLL: 5.557, ECE: 0.001
Epoch 35 completed.
train loss: 4.87064180528171
train acc: 0.0587847689546882
train rank: 51.9370723979363
train weight_norm: 141.5176696927393
train grad_norm: 5.112943524635425
train lr: 0.0007339459442134423
val loss: 5.572216486930847
val acc: 0.005078125
val rank: 127.916015625
test mean_rank: 193.635
test final_rank: 231.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.137, ECE: 0.045
Optimal temperature: 5.496
After temperature - NLL: 5.565, ECE: 0.003
Epoch 41 completed.
train loss: 4.428212460406215
train acc: 0.10609087595334232
train rank: 36.591710127860026
train weight_norm: 149.98028202486117
train grad_norm: 7.7153129814216905
train lr: 0.0006470040137835858
val loss: 6.536393010616303
val acc: 0.0041015625
val rank: 127.044921875
test mean_rank: 86.643
test final_rank: 9.0
test traces_to_disclosure: nan

Epoch 27 completed.
train loss: 5.417924635824252
train acc: 0.013469465006729475
train rank: 91.80535869504261
train weight_norm: 127.20259129642143
train grad_norm: 0.9393669489631398
train lr: 0.0008364846005616848
val loss: 5.557514727115631
val acc: 0.00478515625
val rank: 127.69912109375
test mean_rank: 163.846
test final_rank: 221.0
test traces_to_disclosure: nan

Epoch 47 completed.
train loss: 4.066189589121781
train acc: 0.1526714614176761
train rank: 27.878042283535216
train weight_norm: 155.65003384485695
train grad_norm: 9.998227577933244
train lr: 0.0005548543928776817
val loss: 6.976073586940766
val acc: 0.00224609375
val rank: 127.0955078125
test mean_rank: 211.564
test final_rank: 141.0
test traces_to_disclosure: nan

Epoch 30 completed.
train loss: 5.281306856573831
train acc: 0.023544400515926427
train rank: 76.99191762000896
train weight_norm: 132.47303626205502
train grad_norm: 1.8532312847523624
train lr: 0.000800189314297648
val loss: 5.755068790912628
val acc: 0.003515625
val rank: 127.38388671875
test mean_rank: 57.075
test final_rank: 3.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.645, ECE: 0.008
Optimal temperature: 2.866
After temperature - NLL: 5.556, ECE: 0.001
Epoch 35 completed.
train loss: 4.830540309202623
train acc: 0.06249649506505159
train rank: 50.32203517552715
train weight_norm: 142.0392881454536
train grad_norm: 5.276404810317752
train lr: 0.0007339459442134423
val loss: 5.565491342544556
val acc: 0.0037109375
val rank: 127.92626953125
test mean_rank: 158.983
test final_rank: 118.0
test traces_to_disclosure: nan

Epoch 30 completed.
train loss: 5.275489585717305
train acc: 0.02401756673396142
train rank: 76.47336599932706
train weight_norm: 132.48204519147436
train grad_norm: 1.9452262972625343
train lr: 0.000800189314297648
val loss: 5.758532285690308
val acc: 0.0044921875
val rank: 126.96904296875
test mean_rank: 141.145
test final_rank: 79.0
test traces_to_disclosure: nan

Epoch 41 completed.
train loss: 4.435032824648502
train acc: 0.105090217025572
train rank: 36.790548592418126
train weight_norm: 150.00305596744002
train grad_norm: 7.417848553115447
train lr: 0.0006470040137835858
val loss: 6.546201944351196
val acc: 0.00380859375
val rank: 126.975
test mean_rank: 132.555
test final_rank: 143.0
test traces_to_disclosure: nan

Epoch 27 completed.
train loss: 5.41385545961629
train acc: 0.014084581090174967
train rank: 91.28216478802153
train weight_norm: 127.24763247050642
train grad_norm: 0.9602812718364233
train lr: 0.0008364846005616848
val loss: 5.555332899093628
val acc: 0.004296875
val rank: 126.580859375
test mean_rank: 90.346
test final_rank: 104.0
test traces_to_disclosure: nan

Epoch 30 completed.
train loss: 5.282059211910654
train acc: 0.023253490915208615
train rank: 77.01603157245401
train weight_norm: 132.1982752660225
train grad_norm: 1.8585934567723759
train lr: 0.000800189314297648
val loss: 5.75416909456253
val acc: 0.00302734375
val rank: 128.03681640625
test mean_rank: 68.053
test final_rank: 15.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.649, ECE: 0.009
Optimal temperature: 2.861
After temperature - NLL: 5.557, ECE: 0.002
Before temperature - NLL: 6.170, ECE: 0.048
Optimal temperature: 5.484
After temperature - NLL: 5.565, ECE: 0.002
Epoch 27 completed.
train loss: 5.410056196343691
train acc: 0.01415818472409152
train rank: 90.77153256785553
train weight_norm: 127.173621992587
train grad_norm: 0.9687401282197446
train lr: 0.0008364846005616848
val loss: 5.556639504432678
val acc: 0.00361328125
val rank: 126.508984375
test mean_rank: 52.836
test final_rank: 88.0
test traces_to_disclosure: nan

Epoch 36 completed.
train loss: 4.791075852164349
train acc: 0.06721063257065948
train rank: 48.693100886047546
train weight_norm: 143.0845838695038
train grad_norm: 5.65797808288318
train lr: 0.0007199510467890352
val loss: 5.5652431607246395
val acc: 0.0044921875
val rank: 127.029296875
test mean_rank: 127.449
test final_rank: 172.0
test traces_to_disclosure: nan

Epoch 48 completed.
train loss: 4.019378376520498
train acc: 0.15807081370569764
train rank: 26.918031838829073
train weight_norm: 156.45309877221942
train grad_norm: 10.261465458017554
train lr: 0.0005392173970118083
val loss: 7.029672062397003
val acc: 0.002734375
val rank: 126.7015625
test mean_rank: 213.431
test final_rank: 173.0
test traces_to_disclosure: nan

Epoch 42 completed.
train loss: 4.364719420711574
train acc: 0.11391389075818754
train rank: 34.8992453875056
train weight_norm: 151.11201789041138
train grad_norm: 8.094992207807287
train lr: 0.0006319209037929501
val loss: 6.614504361152649
val acc: 0.00419921875
val rank: 127.37509765625
test mean_rank: 149.582
test final_rank: 167.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.217, ECE: 0.051
Optimal temperature: 5.496
After temperature - NLL: 5.567, ECE: 0.002
Epoch 42 completed.
train loss: 4.37176019185966
train acc: 0.11267139131897712
train rank: 35.02081055125617
train weight_norm: 151.1416365789875
train grad_norm: 7.879852555359333
train lr: 0.0006319209037929501
val loss: 6.608090317249298
val acc: 0.00390625
val rank: 127.01611328125
test mean_rank: 117.456
test final_rank: 173.0
test traces_to_disclosure: nan

Epoch 36 completed.
train loss: 4.751196025037188
train acc: 0.07042991532077164
train rank: 47.17938432312695
train weight_norm: 143.62183317100852
train grad_norm: 5.819926780456881
train lr: 0.0007199510467890352
val loss: 5.567687082290649
val acc: 0.00478515625
val rank: 127.62216796875
test mean_rank: 94.476
test final_rank: 71.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.677, ECE: 0.009
Optimal temperature: 3.371
After temperature - NLL: 5.557, ECE: 0.001
Epoch 31 completed.
train loss: 5.217549136638
train acc: 0.027587342978914315
train rank: 71.80924917283537
train weight_norm: 134.25092871416018
train grad_norm: 2.2718099850967612
train lr: 0.0007874821550468655
val loss: 5.8007768273353575
val acc: 0.003515625
val rank: 126.92666015625
test mean_rank: 225.52
test final_rank: 189.0
test traces_to_disclosure: nan

Epoch 31 completed.
train loss: 5.2095759701119135
train acc: 0.02861604138627187
train rank: 71.1887442519067
train weight_norm: 134.28198448483934
train grad_norm: 2.3740959765468173
train lr: 0.0007874821550468655
val loss: 5.804642021656036
val acc: 0.0033203125
val rank: 127.3119140625
test mean_rank: 252.888
test final_rank: 243.0
test traces_to_disclosure: nan

Epoch 28 completed.
train loss: 5.378879581133097
train acc: 0.01593518674293405
train rank: 86.8986758355765
train weight_norm: 128.9911816381499
train grad_norm: 1.2225843222411588
train lr: 0.0008247026328980229
val loss: 5.5568090915679935
val acc: 0.00478515625
val rank: 127.68203125
test mean_rank: 70.146
test final_rank: 87.0
test traces_to_disclosure: nan

Epoch 49 completed.
train loss: 3.974894146579111
train acc: 0.16477049685957829
train rank: 26.012093778039482
train weight_norm: 157.199955809145
train grad_norm: 10.558084664047366
train lr: 0.000523541698309858
val loss: 7.103229689598083
val acc: 0.0033203125
val rank: 127.783203125
test mean_rank: 60.756
test final_rank: 40.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.247, ECE: 0.054
Optimal temperature: 5.484
After temperature - NLL: 5.569, ECE: 0.003
Before temperature - NLL: 5.680, ECE: 0.010
Optimal temperature: 3.372
After temperature - NLL: 5.557, ECE: 0.001
Epoch 43 completed.
train loss: 4.30558322480357
train acc: 0.12230470502467475
train rank: 33.392615803050695
train weight_norm: 152.18468440275387
train grad_norm: 8.540314316014863
train lr: 0.000616707603797273
val loss: 6.691059541702271
val acc: 0.00380859375
val rank: 127.944921875
test mean_rank: 145.969
test final_rank: 171.0
test traces_to_disclosure: nan

Epoch 31 completed.
train loss: 5.217350302602529
train acc: 0.02843378476895469
train rank: 71.7963247252131
train weight_norm: 133.98004887408294
train grad_norm: 2.2810574400577934
train lr: 0.0007874821550468655
val loss: 5.812189674377441
val acc: 0.00390625
val rank: 128.26875
test mean_rank: 236.46
test final_rank: 187.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.680, ECE: 0.012
Optimal temperature: 3.358
After temperature - NLL: 5.556, ECE: 0.003
Epoch 37 completed.
train loss: 4.715687362855729
train acc: 0.07447110531628533
train rank: 45.7590549994392
train weight_norm: 144.59224654787184
train grad_norm: 6.164144163368538
train lr: 0.0007057390842364583
val loss: 5.568691253662109
val acc: 0.00400390625
val rank: 127.2337890625
test mean_rank: 202.195
test final_rank: 190.0
test traces_to_disclosure: nan

Epoch 28 completed.
train loss: 5.374880896602954
train acc: 0.01613321556751907
train rank: 86.48410862494393
train weight_norm: 129.04171091531353
train grad_norm: 1.2531855972018777
train lr: 0.0008247026328980229
val loss: 5.556853497028351
val acc: 0.00458984375
val rank: 127.6978515625
test mean_rank: 50.574
test final_rank: 59.0
test traces_to_disclosure: nan

Epoch 43 completed.
train loss: 4.310435515233036
train acc: 0.11936932200538358
train rank: 33.43438060789592
train weight_norm: 152.22774224158238
train grad_norm: 8.185029099254695
train lr: 0.000616707603797273
val loss: 6.683425009250641
val acc: 0.0037109375
val rank: 127.09921875
test mean_rank: 144.841
test final_rank: 154.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.285, ECE: 0.056
Optimal temperature: 5.497
After temperature - NLL: 5.570, ECE: 0.002
Epoch 28 completed.
train loss: 5.369044962994664
train acc: 0.01668349035441902
train rank: 85.75887624775685
train weight_norm: 128.98762985329668
train grad_norm: 1.2662530403077947
train lr: 0.0008247026328980229
val loss: 5.556443774700165
val acc: 0.00302734375
val rank: 127.11982421875
test mean_rank: 26.439
test final_rank: 9.0
test traces_to_disclosure: nan

Epoch 37 completed.
train loss: 4.674865967813443
train acc: 0.07963562696276356
train rank: 44.35465560509196
train weight_norm: 145.09167533099364
train grad_norm: 6.3732507593354955
train lr: 0.0007057390842364583
val loss: 5.569845902919769
val acc: 0.00478515625
val rank: 127.5060546875
test mean_rank: 157.49
test final_rank: 220.0
test traces_to_disclosure: nan

Epoch 50 completed.
train loss: 3.92702847342151
train acc: 0.17112669638851502
train rank: 25.089370583781964
train weight_norm: 157.9117317987157
train grad_norm: 10.791394157263877
train lr: 0.0005078427667938984
val loss: 7.151860821247101
val acc: 0.00244140625
val rank: 127.42490234375
test mean_rank: 114.9
test final_rank: 109.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.711, ECE: 0.012
Optimal temperature: 3.371
After temperature - NLL: 5.560, ECE: 0.001
Epoch 44 completed.
train loss: 4.245953643947719
train acc: 0.12946353465679677
train rank: 31.93209363784208
train weight_norm: 153.19633877994394
train grad_norm: 8.687274639230644
train lr: 0.0006013791274869292
val loss: 6.748513031005859
val acc: 0.00361328125
val rank: 127.48994140625
test mean_rank: 143.116
test final_rank: 147.0
test traces_to_disclosure: nan

Epoch 32 completed.
train loss: 5.147701248666961
train acc: 0.03373850381336923
train rank: 66.8241574136384
train weight_norm: 136.0066253254959
train grad_norm: 2.6709282839095425
train lr: 0.0007744912856171929
val loss: 5.856579709053039
val acc: 0.00390625
val rank: 127.3439453125
test mean_rank: 222.541
test final_rank: 216.0
test traces_to_disclosure: nan

Epoch 32 completed.
train loss: 5.137193502680289
train acc: 0.03398910666218035
train rank: 66.0320316004935
train weight_norm: 136.05636300881022
train grad_norm: 2.8144942457004927
train lr: 0.0007744912856171929
val loss: 5.854080522060395
val acc: 0.004296875
val rank: 126.67216796875
test mean_rank: 243.911
test final_rank: 251.0
test traces_to_disclosure: nan

Epoch 29 completed.
train loss: 5.330202471038695
train acc: 0.01944187415881561
train rank: 81.59073926087932
train weight_norm: 130.79746140327916
train grad_norm: 1.5534664417302515
train lr: 0.0008126002229375134
val loss: 5.55918321609497
val acc: 0.0044921875
val rank: 127.43349609375
test mean_rank: 101.623
test final_rank: 195.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.329, ECE: 0.060
Optimal temperature: 5.484
After temperature - NLL: 5.572, ECE: 0.002
Before temperature - NLL: 6.355, ECE: 0.063
Optimal temperature: 5.497
After temperature - NLL: 5.571, ECE: 0.003
Epoch 51 completed.
train loss: 3.8817760986081686
train acc: 0.1786956034096007
train rank: 24.331428401188877
train weight_norm: 158.59065383168962
train grad_norm: 11.093524928115205
train lr: 0.0004921360954139836
val loss: 7.2097691059112545
val acc: 0.00224609375
val rank: 127.5064453125
test mean_rank: 114.985
test final_rank: 55.0
test traces_to_disclosure: nan

Epoch 44 completed.
train loss: 4.252034750151602
train acc: 0.12815794638851502
train rank: 32.00190317967699
train weight_norm: 153.23771311711866
train grad_norm: 8.491159395592494
train lr: 0.0006013791274869292
val loss: 6.751411259174347
val acc: 0.0033203125
val rank: 127.25400390625
test mean_rank: 64.554
test final_rank: 74.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.713, ECE: 0.013
Optimal temperature: 3.372
After temperature - NLL: 5.560, ECE: 0.002
Epoch 38 completed.
train loss: 4.639343437564485
train acc: 0.0836435200762674
train rank: 43.09366237662629
train weight_norm: 145.99936494260263
train grad_norm: 6.578268536743111
train lr: 0.0006913240820469203
val loss: 5.571844816207886
val acc: 0.00400390625
val rank: 127.269921875
test mean_rank: 163.496
test final_rank: 199.0
test traces_to_disclosure: 10.0

Epoch 38 completed.
train loss: 4.5995236816508935
train acc: 0.08740957267833109
train rank: 41.80119132738896
train weight_norm: 146.478130942163
train grad_norm: 6.782265283197558
train lr: 0.0006913240820469203
val loss: 5.572413063049316
val acc: 0.00546875
val rank: 127.5412109375
test mean_rank: 203.647
test final_rank: 209.0
test traces_to_disclosure: nan

Epoch 32 completed.
train loss: 5.147031642225838
train acc: 0.03376829576043069
train rank: 66.7850546068865
train weight_norm: 135.7417704118835
train grad_norm: 2.7089249941891973
train lr: 0.0007744912856171929
val loss: 5.856189751625061
val acc: 0.00400390625
val rank: 127.521875
test mean_rank: 225.891
test final_rank: 229.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.718, ECE: 0.014
Optimal temperature: 3.358
After temperature - NLL: 5.560, ECE: 0.002
Epoch 29 completed.
train loss: 5.325728513350557
train acc: 0.019909782974427994
train rank: 81.19885423676536
train weight_norm: 130.8567702562766
train grad_norm: 1.5763331855277565
train lr: 0.0008126002229375134
val loss: 5.55911294221878
val acc: 0.004296875
val rank: 127.0392578125
test mean_rank: 82.242
test final_rank: 168.0
test traces_to_disclosure: nan

Epoch 29 completed.
train loss: 5.318612228973717
train acc: 0.020298830753701213
train rank: 80.44083319313593
train weight_norm: 130.80612321596718
train grad_norm: 1.607278797733259
train lr: 0.0008126002229375134
val loss: 5.559231770038605
val acc: 0.00390625
val rank: 126.49873046875
test mean_rank: 90.02
test final_rank: 205.0
test traces_to_disclosure: nan

Epoch 45 completed.
train loss: 4.19013841604641
train acc: 0.13711130271422162
train rank: 30.617932298676532
train weight_norm: 154.1554887255107
train grad_norm: 9.07096449558915
train lr: 0.0005859506022174055
val loss: 6.824167728424072
val acc: 0.00390625
val rank: 127.92470703125
test mean_rank: 161.418
test final_rank: 91.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.755, ECE: 0.015
Optimal temperature: 3.959
After temperature - NLL: 5.558, ECE: 0.001
Epoch 33 completed.
train loss: 5.07409726883489
train acc: 0.039665348811126065
train rank: 62.18824655114401
train weight_norm: 137.71747765408142
train grad_norm: 3.2090717735935295
train lr: 0.0007612295264283511
val loss: 5.927413213253021
val acc: 0.0048828125
val rank: 127.77890625
test mean_rank: 122.561
test final_rank: 23.0
test traces_to_disclosure: nan

Epoch 33 completed.
train loss: 5.061616896299462
train acc: 0.04162285497981157
train rank: 61.505972409152086
train weight_norm: 137.7902357999481
train grad_norm: 3.253601194636044
train lr: 0.0007612295264283511
val loss: 5.920856356620789
val acc: 0.003515625
val rank: 126.8869140625
test mean_rank: 74.254
test final_rank: 3.0
test traces_to_disclosure: nan

Epoch 52 completed.
train loss: 3.839640021484601
train acc: 0.18362178947958724
train rank: 23.524560831650962
train weight_norm: 159.2390209334612
train grad_norm: 11.323900403844844
train lr: 0.00047643718475847286
val loss: 7.271619701385498
val acc: 0.002734375
val rank: 127.38046875
test mean_rank: 101.326
test final_rank: 167.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.432, ECE: 0.069
Optimal temperature: 5.498
After temperature - NLL: 5.575, ECE: 0.003
Epoch 30 completed.
train loss: 5.2715886746248675
train acc: 0.023418222857783763
train rank: 76.19654623710184
train weight_norm: 132.61498658944288
train grad_norm: 1.9472613207378353
train lr: 0.000800189314297648
val loss: 5.558147335052491
val acc: 0.0048828125
val rank: 127.173046875
test mean_rank: 140.947
test final_rank: 207.0
test traces_to_disclosure: nan

Epoch 45 completed.
train loss: 4.197183771377296
train acc: 0.13459651188873936
train rank: 30.72600872027815
train weight_norm: 154.20029844560108
train grad_norm: 8.81363736020817
train lr: 0.0005859506022174055
val loss: 6.818396735191345
val acc: 0.004296875
val rank: 126.7970703125
test mean_rank: 180.563
test final_rank: 185.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.391, ECE: 0.067
Optimal temperature: 5.487
After temperature - NLL: 5.573, ECE: 0.004
Epoch 39 completed.
train loss: 4.5296758026646735
train acc: 0.0953780422835352
train rank: 39.62640723138179
train weight_norm: 147.79718215675322
train grad_norm: 7.2852636396744765
train lr: 0.0006767202660872397
val loss: 5.574901008605957
val acc: 0.0060546875
val rank: 127.4697265625
test mean_rank: 146.623
test final_rank: 139.0
test traces_to_disclosure: nan

Epoch 46 completed.
train loss: 4.138753217129817
train acc: 0.14373913470165994
train rank: 29.465288876738445
train weight_norm: 155.0705159785225
train grad_norm: 9.724104735696827
train lr: 0.0005704372540804354
val loss: 6.881421744823456
val acc: 0.00498046875
val rank: 127.6728515625
test mean_rank: 89.688
test final_rank: 70.0
test traces_to_disclosure: nan

Epoch 39 completed.
train loss: 4.569508624429818
train acc: 0.09047113335576493
train rank: 40.77818318192015
train weight_norm: 147.34871867158895
train grad_norm: 7.170436024231826
train lr: 0.0006767202660872397
val loss: 5.572308015823364
val acc: 0.003515625
val rank: 126.8080078125
test mean_rank: 202.909
test final_rank: 210.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.760, ECE: 0.016
Optimal temperature: 3.938
After temperature - NLL: 5.558, ECE: 0.002
Epoch 33 completed.
train loss: 5.0712008572523235
train acc: 0.04009996074472858
train rank: 62.00396933882907
train weight_norm: 137.47278522409738
train grad_norm: 3.1577102422013574
train lr: 0.0007612295264283511
val loss: 5.926616048812866
val acc: 0.0037109375
val rank: 128.11630859375
test mean_rank: 173.163
test final_rank: 85.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.763, ECE: 0.016
Optimal temperature: 3.969
After temperature - NLL: 5.559, ECE: 0.002
Epoch 30 completed.
train loss: 5.25798013296936
train acc: 0.024902562808434274
train rank: 75.00339452949754
train weight_norm: 132.62317808371117
train grad_norm: 1.998810290868268
train lr: 0.000800189314297648
val loss: 5.557197856903076
val acc: 0.00439453125
val rank: 126.46103515625
test mean_rank: 182.503
test final_rank: 175.0
test traces_to_disclosure: nan

Epoch 30 completed.
train loss: 5.266253581117653
train acc: 0.02378799349484073
train rank: 75.74716976502917
train weight_norm: 132.66903541441297
train grad_norm: 1.9714658304517394
train lr: 0.000800189314297648
val loss: 5.5587554454803465
val acc: 0.00322265625
val rank: 127.83798828125
test mean_rank: 127.294
test final_rank: 70.0
test traces_to_disclosure: nan

Epoch 46 completed.
train loss: 4.14327298680353
train acc: 0.14228108176312249
train rank: 29.521802447846568
train weight_norm: 155.10758147109848
train grad_norm: 9.06517061888442
train lr: 0.0005704372540804354
val loss: 6.876267051696777
val acc: 0.00380859375
val rank: 127.15849609375
test mean_rank: 121.319
test final_rank: 68.0
test traces_to_disclosure: nan

Epoch 53 completed.
train loss: 3.800776336587775
train acc: 0.18894578566621803
train rank: 22.90595909039928
train weight_norm: 159.84744464378656
train grad_norm: 11.849532311875834
train lr: 0.0004607615277568329
val loss: 7.320471167564392
val acc: 0.002734375
val rank: 127.32490234375
test mean_rank: 113.295
test final_rank: 201.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.462, ECE: 0.074
Optimal temperature: 5.493
After temperature - NLL: 5.575, ECE: 0.005
Before temperature - NLL: 6.498, ECE: 0.077
Optimal temperature: 5.504
After temperature - NLL: 5.575, ECE: 0.003
Epoch 34 completed.
train loss: 4.9831721516348635
train acc: 0.04763206594885599
train rank: 57.18769978129206
train weight_norm: 139.4780719947028
train grad_norm: 3.733548002466029
train lr: 0.0007477099652355478
val loss: 5.979209232330322
val acc: 0.00400390625
val rank: 126.29765625
test mean_rank: 89.516
test final_rank: 93.0
test traces_to_disclosure: nan

Epoch 34 completed.
train loss: 4.995805744848854
train acc: 0.046929326491700306
train rank: 57.8711077697398
train weight_norm: 139.39062774270792
train grad_norm: 3.613702835947551
train lr: 0.0007477099652355478
val loss: 5.986468017101288
val acc: 0.00439453125
val rank: 127.53603515625
test mean_rank: 179.26
test final_rank: 217.0
test traces_to_disclosure: nan

Epoch 40 completed.
train loss: 4.501302187728369
train acc: 0.09832569257514581
train rank: 38.7242457379991
train weight_norm: 148.6202114790062
train grad_norm: 7.61056602554277
train lr: 0.0006619420485606271
val loss: 5.575521194934845
val acc: 0.003125
val rank: 126.96787109375
test mean_rank: 177.259
test final_rank: 176.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.810, ECE: 0.017
Optimal temperature: 3.960
After temperature - NLL: 5.562, ECE: 0.000
Epoch 47 completed.
train loss: 4.088253476257119
train acc: 0.14992183995065053
train rank: 28.36463941229251
train weight_norm: 155.92855197761273
train grad_norm: 9.775483263057035
train lr: 0.0005548543928776817
val loss: 6.9620759129524235
val acc: 0.0029296875
val rank: 128.4197265625
test mean_rank: 152.686
test final_rank: 134.0
test traces_to_disclosure: nan

Epoch 40 completed.
train loss: 4.460113364305663
train acc: 0.10324136384028713
train rank: 37.59117036787797
train weight_norm: 149.05136356883688
train grad_norm: 7.641421662983133
train lr: 0.0006619420485606271
val loss: 5.575939548015595
val acc: 0.005078125
val rank: 127.15419921875
test mean_rank: 172.015
test final_rank: 162.0
test traces_to_disclosure: nan

Epoch 54 completed.
train loss: 3.7586434850140824
train acc: 0.19477799742036786
train rank: 22.19292038189771
train weight_norm: 160.42739162957784
train grad_norm: 11.74262984080936
train lr: 0.00044512459438997856
val loss: 7.358315169811249
val acc: 0.00283203125
val rank: 127.37998046875
test mean_rank: 173.51
test final_rank: 248.0
test traces_to_disclosure: nan

Epoch 31 completed.
train loss: 5.205287914738199
train acc: 0.028831594885598923
train rank: 70.83583059948408
train weight_norm: 134.4308805814542
train grad_norm: 2.3723764389902433
train lr: 0.0007874821550468655
val loss: 5.562308561801911
val acc: 0.00478515625
val rank: 127.50439453125
test mean_rank: 118.271
test final_rank: 43.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.812, ECE: 0.021
Optimal temperature: 3.939
After temperature - NLL: 5.560, ECE: 0.003
Epoch 34 completed.
train loss: 4.9918054982438225
train acc: 0.04803338100044863
train rank: 57.695403628308654
train weight_norm: 139.16596585541987
train grad_norm: 3.60969643531393
train lr: 0.0007477099652355478
val loss: 5.996197783946991
val acc: 0.00380859375
val rank: 127.82685546875
test mean_rank: 121.447
test final_rank: 187.0
test traces_to_disclosure: nan

Epoch 31 completed.
train loss: 5.190883514537785
train acc: 0.02957814602960969
train rank: 69.77791855933154
train weight_norm: 134.44369720392356
train grad_norm: 2.4460884807115053
train lr: 0.0007874821550468655
val loss: 5.559979963302612
val acc: 0.003515625
val rank: 126.3244140625
test mean_rank: 192.423
test final_rank: 213.0
test traces_to_disclosure: nan

Epoch 47 completed.
train loss: 4.091342992127984
train acc: 0.14845677714221622
train rank: 28.45433595502468
train weight_norm: 155.97075719531048
train grad_norm: 9.34499789043089
train lr: 0.0005548543928776817
val loss: 6.930550742149353
val acc: 0.00498046875
val rank: 127.2259765625
test mean_rank: 91.173
test final_rank: 96.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.812, ECE: 0.020
Optimal temperature: 3.969
After temperature - NLL: 5.563, ECE: 0.003
Before temperature - NLL: 6.542, ECE: 0.080
Optimal temperature: 6.460
After temperature - NLL: 5.570, ECE: 0.003
Before temperature - NLL: 6.574, ECE: 0.084
Optimal temperature: 6.464
After temperature - NLL: 5.569, ECE: 0.003
Epoch 31 completed.
train loss: 5.200300760256329
train acc: 0.029571136159712873
train rank: 70.52783093595784
train weight_norm: 134.49676717988208
train grad_norm: 2.386535432594523
train lr: 0.0007874821550468655
val loss: 5.561259257793426
val acc: 0.0033203125
val rank: 127.586328125
test mean_rank: 113.095
test final_rank: 110.0
test traces_to_disclosure: nan

Epoch 48 completed.
train loss: 4.037552074339958
train acc: 0.15679151244952894
train rank: 27.328331791161958
train weight_norm: 156.73547022001569
train grad_norm: 10.02300432584594
train lr: 0.0005392173970118083
val loss: 7.020307660102844
val acc: 0.00322265625
val rank: 128.075
test mean_rank: 100.951
test final_rank: 174.0
test traces_to_disclosure: nan

Epoch 41 completed.
train loss: 4.433937172870456
train acc: 0.10628014244055632
train rank: 36.74786899955137
train weight_norm: 149.81541434352567
train grad_norm: 7.985293258867403
train lr: 0.0006470040137835858
val loss: 5.570365524291992
val acc: 0.0033203125
val rank: 127.72431640625
test mean_rank: 21.15
test final_rank: 19.0
test traces_to_disclosure: nan

Epoch 55 completed.
train loss: 3.7219976993781563
train acc: 0.20041568528488113
train rank: 21.594564897375506
train weight_norm: 160.98414390052622
train grad_norm: 12.161292121330206
train lr: 0.0004295418164232739
val loss: 7.4108080744743345
val acc: 0.00283203125
val rank: 126.80615234375
test mean_rank: 89.812
test final_rank: 130.0
test traces_to_disclosure: nan

Epoch 35 completed.
train loss: 4.904227885070431
train acc: 0.05489253869448183
train rank: 53.280974862606556
train weight_norm: 141.10551330938029
train grad_norm: 4.240373641608442
train lr: 0.0007339459442134423
val loss: 6.049649572372436
val acc: 0.00283203125
val rank: 126.38486328125
test mean_rank: 207.217
test final_rank: 173.0
test traces_to_disclosure: nan

Epoch 41 completed.
train loss: 4.3947233877785274
train acc: 0.11162867317182591
train rank: 35.77278032469717
train weight_norm: 150.23469151543347
train grad_norm: 8.083444337245021
train lr: 0.0006470040137835858
val loss: 5.569906485080719
val acc: 0.00419921875
val rank: 127.321484375
test mean_rank: 73.039
test final_rank: 70.0
test traces_to_disclosure: nan

Epoch 35 completed.
train loss: 4.918103254017888
train acc: 0.05417577949753253
train rank: 53.983624943921036
train weight_norm: 140.99873857172668
train grad_norm: 4.0338541454108245
train lr: 0.0007339459442134423
val loss: 6.053554809093475
val acc: 0.00361328125
val rank: 127.6224609375
test mean_rank: 214.809
test final_rank: 141.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.872, ECE: 0.023
Optimal temperature: 3.962
After temperature - NLL: 5.567, ECE: 0.002
Epoch 48 completed.
train loss: 4.045516683468106
train acc: 0.1540716829295648
train rank: 27.447387421489452
train weight_norm: 156.78284318859104
train grad_norm: 9.873055819549434
train lr: 0.0005392173970118083
val loss: 6.998937165737152
val acc: 0.00341796875
val rank: 126.9671875
test mean_rank: 242.208
test final_rank: 226.0
test traces_to_disclosure: nan

Epoch 32 completed.
train loss: 5.133140533159751
train acc: 0.03490214221624046
train rank: 65.88451940331989
train weight_norm: 136.19851063434334
train grad_norm: 2.840671722290099
train lr: 0.0007744912856171929
val loss: 5.566243958473206
val acc: 0.00400390625
val rank: 127.797265625
test mean_rank: 207.934
test final_rank: 200.0
test traces_to_disclosure: nan

Epoch 35 completed.
train loss: 4.913381340365712
train acc: 0.05409166105877076
train rank: 53.801750364513225
train weight_norm: 140.79542501276595
train grad_norm: 4.118970672698225
train lr: 0.0007339459442134423
val loss: 6.048963177204132
val acc: 0.00439453125
val rank: 127.18408203125
test mean_rank: 162.014
test final_rank: 170.0
test traces_to_disclosure: 1.0

Before temperature - NLL: 5.870, ECE: 0.025
Optimal temperature: 3.939
After temperature - NLL: 5.564, ECE: 0.003
Before temperature - NLL: 6.622, ECE: 0.087
Optimal temperature: 6.460
After temperature - NLL: 5.573, ECE: 0.004
Epoch 49 completed.
train loss: 3.989700191595352
train acc: 0.16355253196500674
train rank: 26.359613335576494
train weight_norm: 157.50878901534625
train grad_norm: 10.631022601519959
train lr: 0.000523541698309858
val loss: 7.072516310214996
val acc: 0.0033203125
val rank: 127.972265625
test mean_rank: 142.152
test final_rank: 85.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.645, ECE: 0.089
Optimal temperature: 6.464
After temperature - NLL: 5.571, ECE: 0.002
Epoch 32 completed.
train loss: 5.1184220185671325
train acc: 0.035881771534320324
train rank: 64.95755173283983
train weight_norm: 136.21447473513058
train grad_norm: 2.8654346030755256
train lr: 0.0007744912856171929
val loss: 5.563251113891601
val acc: 0.0041015625
val rank: 126.09443359375
test mean_rank: 129.264
test final_rank: 99.0
test traces_to_disclosure: nan

Epoch 56 completed.
train loss: 3.682614211278841
train acc: 0.2053944453790938
train rank: 20.97256512169134
train weight_norm: 161.5041847594624
train grad_norm: 12.278237911129033
train lr: 0.0004140285721772396
val loss: 7.465328788757324
val acc: 0.00302734375
val rank: 127.24736328125
test mean_rank: 218.821
test final_rank: 213.0
test traces_to_disclosure: nan

Epoch 42 completed.
train loss: 4.372176454975339
train acc: 0.11306043909825034
train rank: 35.04266382065949
train weight_norm: 150.98430040965317
train grad_norm: 8.486573883564255
train lr: 0.0006319209037929501
val loss: 5.572759842872619
val acc: 0.0037109375
val rank: 127.6416015625
test mean_rank: 68.71
test final_rank: 115.0
test traces_to_disclosure: nan

Epoch 42 completed.
train loss: 4.332320180587461
train acc: 0.11930272824136386
train rank: 34.12687338772993
train weight_norm: 151.38979489109872
train grad_norm: 8.50352691805711
train lr: 0.0006319209037929501
val loss: 5.57250702381134
val acc: 0.00400390625
val rank: 127.70791015625
test mean_rank: 119.601
test final_rank: 114.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.880, ECE: 0.024
Optimal temperature: 3.970
After temperature - NLL: 5.568, ECE: 0.003
Epoch 49 completed.
train loss: 3.998812263137078
train acc: 0.16076085127860026
train rank: 26.51911065780619
train weight_norm: 157.54891446022128
train grad_norm: 9.931985681594632
train lr: 0.000523541698309858
val loss: 7.046620190143585
val acc: 0.0033203125
val rank: 127.047265625
test mean_rank: 233.387
test final_rank: 230.0
test traces_to_disclosure: nan

Epoch 36 completed.
train loss: 4.8263148497765025
train acc: 0.06280492934051143
train rank: 49.87764797835353
train weight_norm: 142.65709021574804
train grad_norm: 4.664167296566505
train lr: 0.0007199510467890352
val loss: 6.1225573182106015
val acc: 0.00341796875
val rank: 126.501953125
test mean_rank: 167.936
test final_rank: 119.0
test traces_to_disclosure: nan

Epoch 36 completed.
train loss: 4.840541722155195
train acc: 0.0618305574248542
train rank: 50.59946830136833
train weight_norm: 142.55532481604985
train grad_norm: 4.5013741225701
train lr: 0.0007199510467890352
val loss: 6.128789710998535
val acc: 0.00390625
val rank: 128.1353515625
test mean_rank: 194.994
test final_rank: 104.0
test traces_to_disclosure: nan

Epoch 32 completed.
train loss: 5.129284625740103
train acc: 0.03478647936294302
train rank: 65.7152923816734
train weight_norm: 136.26994119956396
train grad_norm: 2.8499162850601287
train lr: 0.0007744912856171929
val loss: 5.566944050788879
val acc: 0.00439453125
val rank: 128.02470703125
test mean_rank: 60.177
test final_rank: 86.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.939, ECE: 0.027
Optimal temperature: 4.672
After temperature - NLL: 5.565, ECE: 0.001
Epoch 57 completed.
train loss: 3.643512841990947
train acc: 0.21164724932705248
train rank: 20.31617667676088
train weight_norm: 162.00615013417178
train grad_norm: 12.200003634350503
train lr: 0.00039860017135100997
val loss: 7.523177587985993
val acc: 0.002734375
val rank: 127.31064453125
test mean_rank: 61.653
test final_rank: 5.0
test traces_to_disclosure: nan

Epoch 33 completed.
train loss: 5.053376779261059
train acc: 0.042043447173620456
train rank: 61.078755888290715
train weight_norm: 137.94405054958926
train grad_norm: 3.2710966033476887
train lr: 0.0007612295264283511
val loss: 5.5648923993110655
val acc: 0.0048828125
val rank: 128.2466796875
test mean_rank: 117.662
test final_rank: 65.0
test traces_to_disclosure: nan

Epoch 36 completed.
train loss: 4.834858110743609
train acc: 0.062459693248093306
train rank: 50.289150123373716
train weight_norm: 142.3543972617824
train grad_norm: 4.494250086249151
train lr: 0.0007199510467890352
val loss: 6.122507953643799
val acc: 0.00361328125
val rank: 126.83896484375
test mean_rank: 146.782
test final_rank: 150.0
test traces_to_disclosure: nan

Epoch 50 completed.
train loss: 3.9435024996304415
train acc: 0.16972296994167788
train rank: 25.45017910217586
train weight_norm: 158.2419737678591
train grad_norm: 10.551002190641913
train lr: 0.0005078427667938984
val loss: 7.112147510051727
val acc: 0.003125
val rank: 127.569140625
test mean_rank: 195.365
test final_rank: 185.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.690, ECE: 0.093
Optimal temperature: 6.460
After temperature - NLL: 5.575, ECE: 0.004
Before temperature - NLL: 6.701, ECE: 0.097
Optimal temperature: 6.464
After temperature - NLL: 5.570, ECE: 0.003
Epoch 43 completed.
train loss: 4.311259852444018
train acc: 0.12083438481381785
train rank: 33.52375294414536
train weight_norm: 152.05697233271243
train grad_norm: 8.823011533799509
train lr: 0.000616707603797273
val loss: 5.575661981105805
val acc: 0.004296875
val rank: 128.3169921875
test mean_rank: 88.999
test final_rank: 86.0
test traces_to_disclosure: nan

Epoch 43 completed.
train loss: 4.27248677912182
train acc: 0.12606374775684165
train rank: 32.56820077669359
train weight_norm: 152.44822322652453
train grad_norm: 8.73845352070697
train lr: 0.000616707603797273
val loss: 5.570591592788697
val acc: 0.005859375
val rank: 126.46396484375
test mean_rank: 109.201
test final_rank: 49.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.937, ECE: 0.030
Optimal temperature: 4.624
After temperature - NLL: 5.563, ECE: 0.003
Epoch 50 completed.
train loss: 3.952020100276531
train acc: 0.1684454211529834
train rank: 25.63501184668013
train weight_norm: 158.27887206655961
train grad_norm: 10.161495935410429
train lr: 0.0005078427667938984
val loss: 7.1135564088821415
val acc: 0.0041015625
val rank: 127.09951171875
test mean_rank: 139.819
test final_rank: 108.0
test traces_to_disclosure: nan

Epoch 33 completed.
train loss: 5.042502541882193
train acc: 0.04308441285329744
train rank: 60.5028267300359
train weight_norm: 137.9557931937243
train grad_norm: 3.2894313676763267
train lr: 0.0007612295264283511
val loss: 5.561516904830933
val acc: 0.00390625
val rank: 126.44326171875
test mean_rank: 47.443
test final_rank: 18.0
test traces_to_disclosure: nan

Epoch 58 completed.
train loss: 3.606195616690018
train acc: 0.21807179508748317
train rank: 19.75682410834455
train weight_norm: 162.48358348078526
train grad_norm: 12.378307954114256
train lr: 0.0003832718399135072
val loss: 7.561448764801026
val acc: 0.0025390625
val rank: 127.03798828125
test mean_rank: 32.586
test final_rank: 16.0
test traces_to_disclosure: nan

Epoch 37 completed.
train loss: 4.750606795499655
train acc: 0.07027920311799013
train rank: 46.91496326828173
train weight_norm: 144.1311996366228
train grad_norm: 5.067731709867143
train lr: 0.0007057390842364583
val loss: 6.200520813465118
val acc: 0.00361328125
val rank: 126.80908203125
test mean_rank: 159.568
test final_rank: 159.0
test traces_to_disclosure: 3.0

Epoch 37 completed.
train loss: 4.7636154041315955
train acc: 0.06760493775235532
train rank: 47.36202297835353
train weight_norm: 144.0402079397136
train grad_norm: 4.915253996433891
train lr: 0.0007057390842364583
val loss: 6.2033070683479306
val acc: 0.00390625
val rank: 128.09443359375
test mean_rank: 160.673
test final_rank: 41.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.934, ECE: 0.028
Optimal temperature: 4.669
After temperature - NLL: 5.563, ECE: 0.002
Epoch 51 completed.
train loss: 3.898248272660924
train acc: 0.1758618635038134
train rank: 24.6353535778376
train weight_norm: 158.93968684670588
train grad_norm: 10.837125167624922
train lr: 0.0004921360954139836
val loss: 7.195691549777985
val acc: 0.00380859375
val rank: 128.44736328125
test mean_rank: 138.937
test final_rank: 137.0
test traces_to_disclosure: nan

Epoch 33 completed.
train loss: 5.052456341713948
train acc: 0.04146688537460745
train rank: 61.02962721511888
train weight_norm: 138.01261737885184
train grad_norm: 3.280622348200689
train lr: 0.0007612295264283511
val loss: 5.561932599544525
val acc: 0.0044921875
val rank: 127.02841796875
test mean_rank: 62.178
test final_rank: 67.0
test traces_to_disclosure: nan

Before temperature - NLL: 5.999, ECE: 0.033
Optimal temperature: 4.674
After temperature - NLL: 5.567, ECE: 0.002
Before temperature - NLL: 6.775, ECE: 0.103
Optimal temperature: 6.465
After temperature - NLL: 5.573, ECE: 0.003
Before temperature - NLL: 6.743, ECE: 0.099
Optimal temperature: 6.462
After temperature - NLL: 5.575, ECE: 0.004
Epoch 34 completed.
train loss: 4.976461909179893
train acc: 0.048485517608793174
train rank: 57.00049069089277
train weight_norm: 139.6622842854228
train grad_norm: 3.7770087197212536
train lr: 0.0007477099652355478
val loss: 5.566531646251678
val acc: 0.00439453125
val rank: 127.92529296875
test mean_rank: 68.3
test final_rank: 60.0
test traces_to_disclosure: nan

Epoch 37 completed.
train loss: 4.756595058364149
train acc: 0.07027394571556753
train rank: 47.204283381000444
train weight_norm: 143.85016526627496
train grad_norm: 4.9488717489228256
train lr: 0.0007057390842364583
val loss: 6.203251433372498
val acc: 0.0037109375
val rank: 127.430859375
test mean_rank: 155.312
test final_rank: 77.0
test traces_to_disclosure: nan

Epoch 51 completed.
train loss: 3.903862695193387
train acc: 0.1737536451323463
train rank: 24.656411227007624
train weight_norm: 158.9737786572794
train grad_norm: 10.438620498449154
train lr: 0.0004921360954139836
val loss: 7.177692079544068
val acc: 0.0041015625
val rank: 127.69462890625
test mean_rank: 146.902
test final_rank: 75.0
test traces_to_disclosure: nan

Epoch 44 completed.
train loss: 4.215537818893289
train acc: 0.13315423115746972
train rank: 31.233011580305067
train weight_norm: 153.44218225093172
train grad_norm: 9.243578401529447
train lr: 0.0006013791274869292
val loss: 5.5743353247642515
val acc: 0.005859375
val rank: 127.31611328125
test mean_rank: 97.619
test final_rank: 127.0
test traces_to_disclosure: nan

Epoch 44 completed.
train loss: 4.252502464510069
train acc: 0.12818423340062807
train rank: 32.048496032413645
train weight_norm: 153.06612509561864
train grad_norm: 9.102498313681206
train lr: 0.0006013791274869292
val loss: 5.575946617126465
val acc: 0.00390625
val rank: 127.588671875
test mean_rank: 172.24
test final_rank: 176.0
test traces_to_disclosure: nan

Epoch 59 completed.
train loss: 3.57345899534418
train acc: 0.22271232895917453
train rank: 19.31019550527142
train weight_norm: 162.9387559167312
train grad_norm: 12.62234580221305
train lr: 0.00036805870507724853
val loss: 7.607459044456482
val acc: 0.00244140625
val rank: 127.0171875
test mean_rank: 119.345
test final_rank: 73.0
test traces_to_disclosure: nan

Epoch 52 completed.
train loss: 3.8548128088261846
train acc: 0.18135059163301925
train rank: 23.815158493158364
train weight_norm: 159.59749283599007
train grad_norm: 10.852689422477301
train lr: 0.00047643718475847286
val loss: 7.260624742507934
val acc: 0.0033203125
val rank: 128.246484375
test mean_rank: 131.069
test final_rank: 34.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.011, ECE: 0.035
Optimal temperature: 4.625
After temperature - NLL: 5.568, ECE: 0.004
Epoch 34 completed.
train loss: 4.963863712942295
train acc: 0.05008552041274115
train rank: 56.348984620345455
train weight_norm: 139.65485924237584
train grad_norm: 3.7597515027919988
train lr: 0.0007477099652355478
val loss: 5.566747188568115
val acc: 0.00322265625
val rank: 127.4947265625
test mean_rank: 59.41
test final_rank: 34.0
test traces_to_disclosure: nan

Epoch 38 completed.
train loss: 4.675991114825612
train acc: 0.0778428527366532
train rank: 44.18210064771198
train weight_norm: 145.53585302171444
train grad_norm: 5.49795879501168
train lr: 0.0006913240820469203
val loss: 6.249693131446838
val acc: 0.0037109375
val rank: 125.8240234375
test mean_rank: 200.592
test final_rank: 221.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.008, ECE: 0.032
Optimal temperature: 4.669
After temperature - NLL: 5.568, ECE: 0.001
Epoch 38 completed.
train loss: 4.688618947487339
train acc: 0.07763606157469717
train rank: 44.6668752102961
train weight_norm: 145.45685772944586
train grad_norm: 5.364225818654658
train lr: 0.0006913240820469203
val loss: 6.291097629070282
val acc: 0.002734375
val rank: 128.7271484375
test mean_rank: 184.73
test final_rank: 227.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.846, ECE: 0.109
Optimal temperature: 6.466
After temperature - NLL: 5.576, ECE: 0.003
Epoch 60 completed.
train loss: 3.539456928402065
train acc: 0.2287145300583221
train rank: 18.85545648272768
train weight_norm: 163.3687522550323
train grad_norm: 12.733065801489749
train lr: 0.00035297578036961284
val loss: 7.661864387989044
val acc: 0.00263671875
val rank: 127.07802734375
test mean_rank: 244.112
test final_rank: 243.0
test traces_to_disclosure: nan

Epoch 34 completed.
train loss: 4.975151085757311
train acc: 0.04902527759084791
train rank: 56.91675429004038
train weight_norm: 139.71921677612266
train grad_norm: 3.7445603382102184
train lr: 0.0007477099652355478
val loss: 5.566781497001648
val acc: 0.00439453125
val rank: 128.10458984375
test mean_rank: 106.543
test final_rank: 28.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.813, ECE: 0.105
Optimal temperature: 6.464
After temperature - NLL: 5.577, ECE: 0.003
Epoch 52 completed.
train loss: 3.863592779652427
train acc: 0.17918629430237779
train rank: 23.98481486933602
train weight_norm: 159.63817834998602
train grad_norm: 10.621902597532197
train lr: 0.00047643718475847286
val loss: 7.232147622108459
val acc: 0.00419921875
val rank: 127.663671875
test mean_rank: 191.296
test final_rank: 123.0
test traces_to_disclosure: nan

Epoch 45 completed.
train loss: 4.160827763147983
train acc: 0.14102281011664422
train rank: 30.008215567519063
train weight_norm: 154.3811207222273
train grad_norm: 9.594613975082352
train lr: 0.0005859506022174055
val loss: 5.576876211166382
val acc: 0.0048828125
val rank: 127.32080078125
test mean_rank: 168.83
test final_rank: 128.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.077, ECE: 0.038
Optimal temperature: 4.674
After temperature - NLL: 5.571, ECE: 0.002
Epoch 38 completed.
train loss: 4.681418047297851
train acc: 0.07799356493943473
train rank: 44.433343147151184
train weight_norm: 145.270276348364
train grad_norm: 5.3951505480150646
train lr: 0.0006913240820469203
val loss: 6.28046578168869
val acc: 0.0029296875
val rank: 127.87685546875
test mean_rank: 23.407
test final_rank: 8.0
test traces_to_disclosure: nan

Epoch 45 completed.
train loss: 4.198397788192831
train acc: 0.13479629318079858
train rank: 30.77262610755944
train weight_norm: 154.0241754556427
train grad_norm: 9.495236358856907
train lr: 0.0005859506022174055
val loss: 5.577741408348084
val acc: 0.004296875
val rank: 127.8310546875
test mean_rank: 43.265
test final_rank: 29.0
test traces_to_disclosure: nan

Epoch 53 completed.
train loss: 3.815172608415339
train acc: 0.18814841296545534
train rank: 23.162038400067296
train weight_norm: 160.2219486540318
train grad_norm: 11.36511357824654
train lr: 0.0004607615277568329
val loss: 7.293677806854248
val acc: 0.0037109375
val rank: 127.81591796875
test mean_rank: 121.571
test final_rank: 152.0
test traces_to_disclosure: nan

Epoch 35 completed.
train loss: 4.896148627731713
train acc: 0.05686231213548677
train rank: 53.1126766487214
train weight_norm: 141.28838453790877
train grad_norm: 4.190276434346842
train lr: 0.0007339459442134423
val loss: 5.571377074718475
val acc: 0.005078125
val rank: 128.34951171875
test mean_rank: 158.955
test final_rank: 144.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.085, ECE: 0.040
Optimal temperature: 4.629
After temperature - NLL: 5.572, ECE: 0.003
Epoch 35 completed.
train loss: 4.885409992443922
train acc: 0.05848509701659937
train rank: 52.67951225325259
train weight_norm: 141.26597639412753
train grad_norm: 4.204370288062402
train lr: 0.0007339459442134423
val loss: 5.571096658706665
val acc: 0.00390625
val rank: 127.69208984375
test mean_rank: 101.517
test final_rank: 27.0
test traces_to_disclosure: nan

Epoch 61 completed.
train loss: 3.505230592686588
train acc: 0.23401749663526245
train rank: 18.34012764973082
train weight_norm: 163.7759303579225
train grad_norm: 13.106924467359082
train lr: 0.0003380379508163031
val loss: 7.715870904922485
val acc: 0.0025390625
val rank: 127.30068359375
test mean_rank: 175.407
test final_rank: 172.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.912, ECE: 0.115
Optimal temperature: 6.470
After temperature - NLL: 5.578, ECE: 0.004
Epoch 39 completed.
train loss: 4.601635372654747
train acc: 0.08667528880663974
train rank: 41.69367219044415
train weight_norm: 146.8775493979057
train grad_norm: 5.9281537555384825
train lr: 0.0006767202660872397
val loss: 6.337032842636108
val acc: 0.0037109375
val rank: 126.71435546875
test mean_rank: 131.19
test final_rank: 162.0
test traces_to_disclosure: nan

Epoch 39 completed.
train loss: 4.615489366718769
train acc: 0.08528558209959623
train rank: 42.115310607335125
train weight_norm: 146.7961304139706
train grad_norm: 5.75474253884109
train lr: 0.0006767202660872397
val loss: 6.354991281032563
val acc: 0.0037109375
val rank: 128.2564453125
test mean_rank: 234.357
test final_rank: 252.0
test traces_to_disclosure: nan

Epoch 46 completed.
train loss: 4.109129996832415
train acc: 0.14653607279048902
train rank: 28.828391375056075
train weight_norm: 155.26459155588356
train grad_norm: 9.845728542986611
train lr: 0.0005704372540804354
val loss: 5.579406106472016
val acc: 0.0041015625
val rank: 127.51904296875
test mean_rank: 116.852
test final_rank: 179.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.066, ECE: 0.038
Optimal temperature: 4.669
After temperature - NLL: 5.569, ECE: 0.002
Epoch 54 completed.
train loss: 3.7737323974696655
train acc: 0.19394557537012114
train rank: 22.477077725437415
train weight_norm: 160.81716927778203
train grad_norm: 11.40744077410677
train lr: 0.00044512459438997856
val loss: 7.34606773853302
val acc: 0.0037109375
val rank: 128.06455078125
test mean_rank: 177.545
test final_rank: 141.0
test traces_to_disclosure: nan

Epoch 53 completed.
train loss: 3.822125202874637
train acc: 0.18632584679228356
train rank: 23.267894445379092
train weight_norm: 160.26946825057524
train grad_norm: 10.90115976577182
train lr: 0.0004607615277568329
val loss: 7.271311569213867
val acc: 0.00419921875
val rank: 127.0923828125
test mean_rank: 218.219
test final_rank: 241.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.867, ECE: 0.110
Optimal temperature: 6.467
After temperature - NLL: 5.578, ECE: 0.004
Epoch 35 completed.
train loss: 4.89605458427727
train acc: 0.05586165320771646
train rank: 53.18016592362046
train weight_norm: 141.33243304556623
train grad_norm: 4.206563359600617
train lr: 0.0007339459442134423
val loss: 5.567847847938538
val acc: 0.00537109375
val rank: 127.16435546875
test mean_rank: 122.391
test final_rank: 81.0
test traces_to_disclosure: nan

Epoch 46 completed.
train loss: 4.145390056825743
train acc: 0.14113672050246748
train rank: 29.569285554060112
train weight_norm: 154.92858284094453
train grad_norm: 10.017696036049818
train lr: 0.0005704372540804354
val loss: 5.578675007820129
val acc: 0.00419921875
val rank: 127.49931640625
test mean_rank: 229.042
test final_rank: 224.0
test traces_to_disclosure: nan

Epoch 39 completed.
train loss: 4.609354365722328
train acc: 0.08529960183938987
train rank: 41.943917535890535
train weight_norm: 146.6183607440695
train grad_norm: 5.769985526611147
train lr: 0.0006767202660872397
val loss: 6.338490056991577
val acc: 0.0052734375
val rank: 126.82939453125
test mean_rank: 83.13
test final_rank: 55.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.140, ECE: 0.044
Optimal temperature: 5.500
After temperature - NLL: 5.566, ECE: 0.002
Epoch 62 completed.
train loss: 3.473128485968424
train acc: 0.2391434639973082
train rank: 17.892538694481832
train weight_norm: 164.16790871157502
train grad_norm: 13.029468664192747
train lr: 0.0003232599582516232
val loss: 7.762024104595184
val acc: 0.002734375
val rank: 127.5109375
test mean_rank: 6.83
test final_rank: 16.0
test traces_to_disclosure: 86.0

Epoch 36 completed.
train loss: 4.817184640132242
train acc: 0.06352168853746074
train rank: 49.63298774674741
train weight_norm: 142.85438318663995
train grad_norm: 4.642916391821322
train lr: 0.0007199510467890352
val loss: 5.5656826257705685
val acc: 0.0048828125
val rank: 127.70234375
test mean_rank: 85.593
test final_rank: 85.0
test traces_to_disclosure: nan

Epoch 54 completed.
train loss: 3.7801803961737157
train acc: 0.19147985363391656
train rank: 22.541146183826832
train weight_norm: 160.86065409028578
train grad_norm: 11.062459921759356
train lr: 0.00044512459438997856
val loss: 7.32584068775177
val acc: 0.00361328125
val rank: 127.2779296875
test mean_rank: 150.697
test final_rank: 99.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.969, ECE: 0.119
Optimal temperature: 6.472
After temperature - NLL: 5.579, ECE: 0.002
Before temperature - NLL: 6.150, ECE: 0.046
Optimal temperature: 5.441
After temperature - NLL: 5.566, ECE: 0.003
Epoch 55 completed.
train loss: 3.7346991870156208
train acc: 0.1994378084342755
train rank: 21.80927020244504
train weight_norm: 161.3831526700874
train grad_norm: 11.6888466471509
train lr: 0.0004295418164232739
val loss: 7.397698616981506
val acc: 0.00322265625
val rank: 127.93876953125
test mean_rank: 168.791
test final_rank: 140.0
test traces_to_disclosure: nan

Epoch 40 completed.
train loss: 4.533038371023227
train acc: 0.09355372364288918
train rank: 39.447622252131
train weight_norm: 148.1571439263217
train grad_norm: 6.267724811997202
train lr: 0.0006619420485606271
val loss: 6.394537830352784
val acc: 0.00439453125
val rank: 126.0767578125
test mean_rank: 200.751
test final_rank: 254.0
test traces_to_disclosure: nan

Epoch 47 completed.
train loss: 4.057960898526424
train acc: 0.15409621747420368
train rank: 27.726891963885148
train weight_norm: 156.10618465414552
train grad_norm: 10.097705349748773
train lr: 0.0005548543928776817
val loss: 5.580479609966278
val acc: 0.00439453125
val rank: 127.42900390625
test mean_rank: 218.594
test final_rank: 226.0
test traces_to_disclosure: nan

Epoch 36 completed.
train loss: 4.8079798988506575
train acc: 0.06567196612830865
train rank: 49.34999579407806
train weight_norm: 142.81222029681734
train grad_norm: 4.6173377654189345
train lr: 0.0007199510467890352
val loss: 5.565194392204285
val acc: 0.004296875
val rank: 127.1830078125
test mean_rank: 175.801
test final_rank: 229.0
test traces_to_disclosure: nan

Epoch 40 completed.
train loss: 4.547302005428966
train acc: 0.09270027198295201
train rank: 39.977736653207714
train weight_norm: 148.0763642037825
train grad_norm: 6.14643611129725
train lr: 0.0006619420485606271
val loss: 6.429155480861664
val acc: 0.0037109375
val rank: 128.88115234375
test mean_rank: 220.731
test final_rank: 210.0
test traces_to_disclosure: nan

Epoch 63 completed.
train loss: 3.441227817920464
train acc: 0.24493361653207715
train rank: 17.48453447454015
train weight_norm: 164.53851087939304
train grad_norm: 13.197294289427969
train lr: 0.000308656386770065
val loss: 7.808907842636108
val acc: 0.00234375
val rank: 127.5041015625
test mean_rank: 128.693
test final_rank: 112.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.943, ECE: 0.117
Optimal temperature: 6.468
After temperature - NLL: 5.582, ECE: 0.004
Before temperature - NLL: 6.211, ECE: 0.051
Optimal temperature: 5.501
After temperature - NLL: 5.568, ECE: 0.003
Epoch 47 completed.
train loss: 4.094952058984646
train acc: 0.14860573687752354
train rank: 28.489734045536117
train weight_norm: 155.78986021258714
train grad_norm: 10.222867061221725
train lr: 0.0005548543928776817
val loss: 5.582977902889252
val acc: 0.00380859375
val rank: 128.18369140625
test mean_rank: 192.145
test final_rank: 207.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.141, ECE: 0.045
Optimal temperature: 5.490
After temperature - NLL: 5.565, ECE: 0.002
Epoch 37 completed.
train loss: 4.740123988160535
train acc: 0.07251710408254822
train rank: 46.665708066958274
train weight_norm: 144.3736528377588
train grad_norm: 5.098559273740027
train lr: 0.0007057390842364583
val loss: 5.567369437217712
val acc: 0.00380859375
val rank: 127.3796875
test mean_rank: 101.882
test final_rank: 130.0
test traces_to_disclosure: nan

Epoch 55 completed.
train loss: 3.7427135274355696
train acc: 0.19671973138178558
train rank: 21.89877572622252
train weight_norm: 161.43211519544124
train grad_norm: 11.217903600435216
train lr: 0.0004295418164232739
val loss: 7.383361172676087
val acc: 0.00400390625
val rank: 127.33662109375
test mean_rank: 173.243
test final_rank: 174.0
test traces_to_disclosure: nan

Epoch 40 completed.
train loss: 4.538579776502073
train acc: 0.09349589221624045
train rank: 39.692065177770296
train weight_norm: 147.8915758539808
train grad_norm: 6.144298773927824
train lr: 0.0006619420485606271
val loss: 6.41847939491272
val acc: 0.00419921875
val rank: 127.29306640625
test mean_rank: 208.761
test final_rank: 212.0
test traces_to_disclosure: nan

Epoch 36 completed.
train loss: 4.819574175099184
train acc: 0.06337973867205024
train rank: 49.82763956650965
train weight_norm: 142.88796609615386
train grad_norm: 4.688811639947684
train lr: 0.0007199510467890352
val loss: 5.564566135406494
val acc: 0.00419921875
val rank: 127.45283203125
test mean_rank: 164.017
test final_rank: 229.0
test traces_to_disclosure: nan

Epoch 56 completed.
train loss: 3.6959357556873185
train acc: 0.2057729783535218
train rank: 21.15646380103185
train weight_norm: 161.91943878260767
train grad_norm: 11.945569810067818
train lr: 0.0004140285721772396
val loss: 7.447350549697876
val acc: 0.003515625
val rank: 127.6490234375
test mean_rank: 174.304
test final_rank: 240.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.019, ECE: 0.125
Optimal temperature: 6.475
After temperature - NLL: 5.580, ECE: 0.003
Before temperature - NLL: 7.001, ECE: 0.121
Optimal temperature: 6.474
After temperature - NLL: 5.583, ECE: 0.003
Epoch 64 completed.
train loss: 3.410134357526838
train acc: 0.24854019459398832
train rank: 17.066570981942572
train weight_norm: 164.89230601018664
train grad_norm: 13.193906166449231
train lr: 0.0002942416483335689
val loss: 7.847612607479095
val acc: 0.00302734375
val rank: 127.1298828125
test mean_rank: 52.962
test final_rank: 39.0
test traces_to_disclosure: nan

Epoch 48 completed.
train loss: 4.006835525481891
train acc: 0.16089403880663977
train rank: 26.757921152983396
train weight_norm: 156.91328692897827
train grad_norm: 10.339094353274145
train lr: 0.0005392173970118083
val loss: 5.5813510656356815
val acc: 0.0041015625
val rank: 127.38369140625
test mean_rank: 115.725
test final_rank: 80.0
test traces_to_disclosure: nan

Epoch 48 completed.
train loss: 4.042300442506937
train acc: 0.15644978129205922
train rank: 27.440207562247643
train weight_norm: 156.60062170335166
train grad_norm: 10.490429159621918
train lr: 0.0005392173970118083
val loss: 5.583471298217773
val acc: 0.00439453125
val rank: 127.92294921875
test mean_rank: 139.786
test final_rank: 80.0
test traces_to_disclosure: nan

Epoch 41 completed.
train loss: 4.468186560742467
train acc: 0.10220039816061015
train rank: 37.61346175414984
train weight_norm: 149.3571053063826
train grad_norm: 6.675321848186619
train lr: 0.0006470040137835858
val loss: 6.4629146456718445
val acc: 0.0046875
val rank: 126.3080078125
test mean_rank: 113.165
test final_rank: 45.0
test traces_to_disclosure: nan

Epoch 41 completed.
train loss: 4.480812758808983
train acc: 0.10039535666218034
train rank: 37.92756876682369
train weight_norm: 149.28144304129447
train grad_norm: 6.516591538695108
train lr: 0.0006470040137835858
val loss: 6.50878005027771
val acc: 0.00400390625
val rank: 129.19365234375
test mean_rank: 49.519
test final_rank: 12.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.222, ECE: 0.052
Optimal temperature: 5.441
After temperature - NLL: 5.568, ECE: 0.003
Epoch 37 completed.
train loss: 4.731037700160194
train acc: 0.0716478802153432
train rank: 46.364118929452665
train weight_norm: 144.3169891373548
train grad_norm: 5.068966410997244
train lr: 0.0007057390842364583
val loss: 5.566709887981415
val acc: 0.00380859375
val rank: 126.58798828125
test mean_rank: 143.968
test final_rank: 37.0
test traces_to_disclosure: nan

Epoch 65 completed.
train loss: 3.37923664809236
train acc: 0.2545914647824136
train rank: 16.68452255776133
train weight_norm: 165.2402990699297
train grad_norm: 13.296238361217053
train lr: 0.00028002996854866136
val loss: 7.906980895996094
val acc: 0.0025390625
val rank: 127.5404296875
test mean_rank: 23.136
test final_rank: 27.0
test traces_to_disclosure: nan

Epoch 56 completed.
train loss: 3.7005082556569238
train acc: 0.2033791077837595
train rank: 21.205695869784655
train weight_norm: 161.96899726244635
train grad_norm: 11.501058665817014
train lr: 0.0004140285721772396
val loss: 7.436691927909851
val acc: 0.00390625
val rank: 126.96123046875
test mean_rank: 150.612
test final_rank: 147.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.295, ECE: 0.056
Optimal temperature: 5.501
After temperature - NLL: 5.572, ECE: 0.002
Epoch 57 completed.
train loss: 3.6564354325367656
train acc: 0.21103388571108117
train rank: 20.516786885935396
train weight_norm: 162.43572622625496
train grad_norm: 12.108565704758265
train lr: 0.00039860017135100997
val loss: 7.50682647228241
val acc: 0.0060546875
val rank: 128.1458984375
test mean_rank: 234.606
test final_rank: 254.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.099, ECE: 0.133
Optimal temperature: 6.475
After temperature - NLL: 5.583, ECE: 0.003
Epoch 38 completed.
train loss: 4.66752157557861
train acc: 0.07915545087483176
train rank: 44.01650999607447
train weight_norm: 145.77802644027622
train grad_norm: 5.5020511367305245
train lr: 0.0006913240820469203
val loss: 5.5705358505249025
val acc: 0.00478515625
val rank: 127.7291015625
test mean_rank: 139.791
test final_rank: 188.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.213, ECE: 0.051
Optimal temperature: 5.490
After temperature - NLL: 5.568, ECE: 0.003
Epoch 41 completed.
train loss: 4.471859615551832
train acc: 0.10159754934948406
train rank: 37.72493621018394
train weight_norm: 149.10253136847294
train grad_norm: 6.5673777971200895
train lr: 0.0006470040137835858
val loss: 6.492363750934601
val acc: 0.00302734375
val rank: 127.525
test mean_rank: 97.735
test final_rank: 89.0
test traces_to_disclosure: nan

Epoch 49 completed.
train loss: 3.960677691455805
train acc: 0.16746929676985195
train rank: 25.85758923564379
train weight_norm: 157.6750814800412
train grad_norm: 10.948261036078787
train lr: 0.000523541698309858
val loss: 5.582491719722748
val acc: 0.00458984375
val rank: 127.175
test mean_rank: 137.175
test final_rank: 123.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.073, ECE: 0.129
Optimal temperature: 6.476
After temperature - NLL: 5.585, ECE: 0.005
Epoch 37 completed.
train loss: 4.743089553324724
train acc: 0.07119399113952446
train rank: 46.77722983961417
train weight_norm: 144.39342703483106
train grad_norm: 5.0303325597316775
train lr: 0.0007057390842364583
val loss: 5.5671322584152225
val acc: 0.0041015625
val rank: 127.49638671875
test mean_rank: 157.551
test final_rank: 171.0
test traces_to_disclosure: nan

Epoch 49 completed.
train loss: 3.9956980608353545
train acc: 0.1617194509869897
train rank: 26.44301326267384
train weight_norm: 157.37646954810452
train grad_norm: 10.839404171615953
train lr: 0.000523541698309858
val loss: 5.586844801902771
val acc: 0.0033203125
val rank: 128.3875
test mean_rank: 190.352
test final_rank: 180.0
test traces_to_disclosure: nan

Epoch 57 completed.
train loss: 3.664168418817533
train acc: 0.20894319201435624
train rank: 20.683183672611037
train weight_norm: 162.48709128911315
train grad_norm: 11.632770213618112
train lr: 0.00039860017135100997
val loss: 7.494899582862854
val acc: 0.00361328125
val rank: 127.28466796875
test mean_rank: 39.275
test final_rank: 35.0
test traces_to_disclosure: nan

Epoch 66 completed.
train loss: 3.3479404856988593
train acc: 0.259438789816061
train rank: 16.298369854755496
train weight_norm: 165.5684494584557
train grad_norm: 13.559310039081552
train lr: 0.00026603537262749225
val loss: 7.938501679897309
val acc: 0.00244140625
val rank: 127.234375
test mean_rank: 98.157
test final_rank: 56.0
test traces_to_disclosure: nan

Epoch 42 completed.
train loss: 4.401279971224142
train acc: 0.10979559219380888
train rank: 35.71950180854643
train weight_norm: 150.49208205001008
train grad_norm: 6.976007045044802
train lr: 0.0006319209037929501
val loss: 6.542364704608917
val acc: 0.00302734375
val rank: 126.359375
test mean_rank: 52.361
test final_rank: 36.0
test traces_to_disclosure: nan

Epoch 42 completed.
train loss: 4.415309560090344
train acc: 0.10742976110363392
train rank: 36.05257402422611
train weight_norm: 150.42225263500325
train grad_norm: 6.844952381679401
train lr: 0.0006319209037929501
val loss: 6.551505553722381
val acc: 0.00361328125
val rank: 128.18837890625
test mean_rank: 61.771
test final_rank: 53.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.293, ECE: 0.058
Optimal temperature: 5.441
After temperature - NLL: 5.571, ECE: 0.003
Epoch 58 completed.
train loss: 3.6215328846131807
train acc: 0.2167048704576043
train rank: 20.080164872139974
train weight_norm: 162.92786708528646
train grad_norm: 12.478313596315017
train lr: 0.0003832718399135072
val loss: 7.548393988609314
val acc: 0.0037109375
val rank: 128.0412109375
test mean_rank: 207.346
test final_rank: 121.0
test traces_to_disclosure: nan

Epoch 38 completed.
train loss: 4.658781298718253
train acc: 0.08108491756393002
train rank: 43.765758187528036
train weight_norm: 145.71722213689347
train grad_norm: 5.435744248514771
train lr: 0.0006913240820469203
val loss: 5.569848346710205
val acc: 0.003515625
val rank: 127.28837890625
test mean_rank: 150.46
test final_rank: 158.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.130, ECE: 0.137
Optimal temperature: 6.481
After temperature - NLL: 5.582, ECE: 0.003
Epoch 50 completed.
train loss: 3.915699630855391
train acc: 0.17371333838043965
train rank: 25.020700145805296
train weight_norm: 158.39890129792613
train grad_norm: 10.971834476906226
train lr: 0.0005078427667938984
val loss: 5.583885645866394
val acc: 0.0048828125
val rank: 127.29150390625
test mean_rank: 232.456
test final_rank: 228.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.356, ECE: 0.064
Optimal temperature: 5.502
After temperature - NLL: 5.572, ECE: 0.003
Epoch 42 completed.
train loss: 4.409633971479988
train acc: 0.10797477848811125
train rank: 35.9285659208165
train weight_norm: 150.24090262355884
train grad_norm: 6.826995781868165
train lr: 0.0006319209037929501
val loss: 6.55356525182724
val acc: 0.0044921875
val rank: 127.7603515625
test mean_rank: 206.109
test final_rank: 196.0
test traces_to_disclosure: nan

Epoch 39 completed.
train loss: 4.594469220609396
train acc: 0.08768996747420367
train rank: 41.603364036563484
train weight_norm: 147.11458332909876
train grad_norm: 5.9082126350761905
train lr: 0.0006767202660872397
val loss: 5.572253298759461
val acc: 0.00361328125
val rank: 127.296484375
test mean_rank: 167.055
test final_rank: 228.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.115, ECE: 0.133
Optimal temperature: 6.482
After temperature - NLL: 5.585, ECE: 0.004
Epoch 59 completed.
train loss: 3.5846698075573022
train acc: 0.2217397095109915
train rank: 19.491221890421716
train weight_norm: 163.39230687255807
train grad_norm: 12.260110962302615
train lr: 0.00036805870507724853
val loss: 7.605196464061737
val acc: 0.0033203125
val rank: 128.00126953125
test mean_rank: 129.996
test final_rank: 158.0
test traces_to_disclosure: nan

Epoch 58 completed.
train loss: 3.6284357484224508
train acc: 0.21544309387617766
train rank: 20.09560586305518
train weight_norm: 162.97709779353792
train grad_norm: 11.709681524284301
train lr: 0.0003832718399135072
val loss: 7.534595382213593
val acc: 0.00400390625
val rank: 127.16474609375
test mean_rank: 55.662
test final_rank: 58.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.303, ECE: 0.056
Optimal temperature: 5.490
After temperature - NLL: 5.574, ECE: 0.003
Epoch 67 completed.
train loss: 3.3229833409731673
train acc: 0.2640057200538358
train rank: 16.000101643113503
train weight_norm: 165.87994660623409
train grad_norm: 13.582581294756107
train lr: 0.0002522716715466487
val loss: 7.986408960819245
val acc: 0.00283203125
val rank: 126.96572265625
test mean_rank: 44.887
test final_rank: 0.0
test traces_to_disclosure: 960.0

Epoch 50 completed.
train loss: 3.949457350521678
train acc: 0.167770721175415
train rank: 25.540105218147154
train weight_norm: 158.10200199974574
train grad_norm: 10.944935629563801
train lr: 0.0005078427667938984
val loss: 5.586675465106964
val acc: 0.0037109375
val rank: 128.03203125
test mean_rank: 193.333
test final_rank: 172.0
test traces_to_disclosure: nan

Epoch 38 completed.
train loss: 4.668852750898852
train acc: 0.07906257009869896
train rank: 44.0579278123598
train weight_norm: 145.79740373862452
train grad_norm: 5.489648971746501
train lr: 0.0006913240820469203
val loss: 5.57185308933258
val acc: 0.00380859375
val rank: 128.23349609375
test mean_rank: 198.015
test final_rank: 207.0
test traces_to_disclosure: nan

Epoch 43 completed.
train loss: 4.338756401798767
train acc: 0.11791302153432032
train rank: 34.11741356830417
train weight_norm: 151.585367859097
train grad_norm: 7.301860105757898
train lr: 0.000616707603797273
val loss: 6.60370591878891
val acc: 0.00478515625
val rank: 126.720703125
test mean_rank: 122.712
test final_rank: 141.0
test traces_to_disclosure: nan

Epoch 43 completed.
train loss: 4.3542866604164505
train acc: 0.11519143954688202
train rank: 34.492175232727675
train weight_norm: 151.50188471486226
train grad_norm: 7.066694719592888
train lr: 0.000616707603797273
val loss: 6.62780042886734
val acc: 0.0037109375
val rank: 128.539453125
test mean_rank: 190.529
test final_rank: 243.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.181, ECE: 0.142
Optimal temperature: 6.484
After temperature - NLL: 5.582, ECE: 0.003
Before temperature - NLL: 6.375, ECE: 0.065
Optimal temperature: 5.447
After temperature - NLL: 5.576, ECE: 0.004
Epoch 68 completed.
train loss: 3.294133829396634
train acc: 0.2679960884925976
train rank: 15.621989260879316
train weight_norm: 166.1729056837699
train grad_norm: 13.922544419561534
train lr: 0.00023875244841738502
val loss: 8.027825915813446
val acc: 0.00283203125
val rank: 127.19677734375
test mean_rank: 103.662
test final_rank: 138.0
test traces_to_disclosure: nan

Epoch 43 completed.
train loss: 4.3473048617669745
train acc: 0.11583284264244056
train rank: 34.28854376962764
train weight_norm: 151.31669943722315
train grad_norm: 7.1626283489286156
train lr: 0.000616707603797273
val loss: 6.621944391727448
val acc: 0.0033203125
val rank: 127.5083984375
test mean_rank: 244.759
test final_rank: 252.0
test traces_to_disclosure: nan

Epoch 51 completed.
train loss: 3.8697978904718986
train acc: 0.18037797218483623
train rank: 24.168848488672054
train weight_norm: 159.0808163724683
train grad_norm: 11.291438439605033
train lr: 0.0004921360954139836
val loss: 5.5832159399986265
val acc: 0.00634765625
val rank: 126.825390625
test mean_rank: 153.371
test final_rank: 179.0
test traces_to_disclosure: nan

Epoch 39 completed.
train loss: 4.5873766118713215
train acc: 0.08844703342305966
train rank: 41.36787972465231
train weight_norm: 147.04749966177909
train grad_norm: 5.854323404691723
train lr: 0.0006767202660872397
val loss: 5.5730348944664
val acc: 0.0033203125
val rank: 127.25341796875
test mean_rank: 156.365
test final_rank: 248.0
test traces_to_disclosure: nan

Epoch 60 completed.
train loss: 3.5499896390280847
train acc: 0.2276437724315837
train rank: 18.982471820323013
train weight_norm: 163.83704335257275
train grad_norm: 12.448256269470706
train lr: 0.00035297578036961284
val loss: 7.654371500015259
val acc: 0.0033203125
val rank: 128.017578125
test mean_rank: 175.677
test final_rank: 153.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.429, ECE: 0.069
Optimal temperature: 5.503
After temperature - NLL: 5.575, ECE: 0.003
Before temperature - NLL: 7.178, ECE: 0.138
Optimal temperature: 6.488
After temperature - NLL: 5.587, ECE: 0.004
Epoch 59 completed.
train loss: 3.5937977863994615
train acc: 0.22089326772095114
train rank: 19.600397109129656
train weight_norm: 163.43840340516195
train grad_norm: 11.913391131191604
train lr: 0.00036805870507724853
val loss: 7.591722619533539
val acc: 0.0033203125
val rank: 127.58544921875
test mean_rank: 108.675
test final_rank: 79.0
test traces_to_disclosure: nan

Epoch 40 completed.
train loss: 4.52638033164783
train acc: 0.09501528151637505
train rank: 39.38508895524899
train weight_norm: 148.37067346851006
train grad_norm: 6.3143782951051035
train lr: 0.0006619420485606271
val loss: 5.574362719058991
val acc: 0.0041015625
val rank: 127.46650390625
test mean_rank: 192.377
test final_rank: 223.0
test traces_to_disclosure: nan

Epoch 51 completed.
train loss: 3.904880792905312
train acc: 0.17499614457155674
train rank: 24.741577641318976
train weight_norm: 158.797493482879
train grad_norm: 11.234970578122496
train lr: 0.0004921360954139836
val loss: 5.5890203475952145
val acc: 0.00380859375
val rank: 128.2193359375
test mean_rank: 153.491
test final_rank: 109.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.374, ECE: 0.063
Optimal temperature: 5.495
After temperature - NLL: 5.576, ECE: 0.004
Before temperature - NLL: 7.247, ECE: 0.148
Optimal temperature: 6.490
After temperature - NLL: 5.584, ECE: 0.003
Epoch 69 completed.
train loss: 3.2701764353833
train acc: 0.27335688649618667
train rank: 15.354382220165991
train weight_norm: 166.45163762792168
train grad_norm: 14.00147988522093
train lr: 0.000225491045080734
val loss: 8.058513867855073
val acc: 0.00283203125
val rank: 127.27578125
test mean_rank: 138.663
test final_rank: 145.0
test traces_to_disclosure: nan

Epoch 39 completed.
train loss: 4.59805575482457
train acc: 0.08708186126065501
train rank: 41.71955613503813
train weight_norm: 147.13073550744323
train grad_norm: 5.855221384981253
train lr: 0.0006767202660872397
val loss: 5.574318373203278
val acc: 0.00361328125
val rank: 128.39072265625
test mean_rank: 167.784
test final_rank: 98.0
test traces_to_disclosure: 6.0

Epoch 52 completed.
train loss: 3.8283782374329394
train acc: 0.18633460912965452
train rank: 23.441835604531178
train weight_norm: 159.7280372753806
train grad_norm: 11.33375106999697
train lr: 0.00047643718475847286
val loss: 5.584800171852112
val acc: 0.00576171875
val rank: 126.55400390625
test mean_rank: 47.903
test final_rank: 13.0
test traces_to_disclosure: nan

Epoch 44 completed.
train loss: 4.281301792345008
train acc: 0.12422540937640196
train rank: 32.65665657245402
train weight_norm: 152.605931701755
train grad_norm: 7.638157723938029
train lr: 0.0006013791274869292
val loss: 6.6769741654396055
val acc: 0.00322265625
val rank: 126.67021484375
test mean_rank: 163.527
test final_rank: 93.0
test traces_to_disclosure: nan

Epoch 44 completed.
train loss: 4.294696149081593
train acc: 0.12363833277254374
train rank: 33.0065279413414
train weight_norm: 152.5240915771824
train grad_norm: 7.431261032663031
train lr: 0.0006013791274869292
val loss: 6.698407697677612
val acc: 0.0041015625
val rank: 128.98876953125
test mean_rank: 94.903
test final_rank: 53.0
test traces_to_disclosure: nan

Epoch 61 completed.
train loss: 3.517564788320344
train acc: 0.23265407694033202
train rank: 18.5381249299013
train weight_norm: 164.2536859171671
train grad_norm: 12.609032567225967
train lr: 0.0003380379508163031
val loss: 7.692641854286194
val acc: 0.0041015625
val rank: 127.75361328125
test mean_rank: 91.248
test final_rank: 48.0
test traces_to_disclosure: nan

Epoch 60 completed.
train loss: 3.5598024612801553
train acc: 0.22530247588604754
train rank: 19.097225143001346
train weight_norm: 163.8827879112956
train grad_norm: 12.060581363496821
train lr: 0.00035297578036961284
val loss: 7.641417455673218
val acc: 0.00341796875
val rank: 127.33681640625
test mean_rank: 195.802
test final_rank: 204.0
test traces_to_disclosure: nan

Epoch 44 completed.
train loss: 4.288903291581617
train acc: 0.1236611148497084
train rank: 32.82488468764019
train weight_norm: 152.32761410720803
train grad_norm: 7.5106279939113625
train lr: 0.0006013791274869292
val loss: 6.683419692516327
val acc: 0.00263671875
val rank: 127.363671875
test mean_rank: 165.124
test final_rank: 172.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.233, ECE: 0.143
Optimal temperature: 7.636
After temperature - NLL: 5.576, ECE: 0.004
Before temperature - NLL: 6.436, ECE: 0.071
Optimal temperature: 5.450
After temperature - NLL: 5.576, ECE: 0.004
Epoch 52 completed.
train loss: 3.862155338636478
train acc: 0.1809335043741588
train rank: 23.987971063257067
train weight_norm: 159.4585957153113
train grad_norm: 11.396040886154259
train lr: 0.00047643718475847286
val loss: 5.576756072044373
val acc: 0.0037109375
val rank: 127.76572265625
test mean_rank: 86.787
test final_rank: 193.0
test traces_to_disclosure: nan

Epoch 40 completed.
train loss: 4.521041617258722
train acc: 0.09517826099147599
train rank: 39.242753546994166
train weight_norm: 148.30070967006822
train grad_norm: 6.264963351166879
train lr: 0.0006619420485606271
val loss: 5.576415288448334
val acc: 0.00361328125
val rank: 127.7701171875
test mean_rank: 199.479
test final_rank: 181.0
test traces_to_disclosure: nan

Epoch 70 completed.
train loss: 3.2404971982717194
train acc: 0.27703531572454015
train rank: 14.99711543853746
train weight_norm: 166.71200708289913
train grad_norm: 13.837281382994579
train lr: 0.00021250054894072056
val loss: 8.100190138816833
val acc: 0.00263671875
val rank: 127.2400390625
test mean_rank: 123.844
test final_rank: 201.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.501, ECE: 0.077
Optimal temperature: 5.504
After temperature - NLL: 5.578, ECE: 0.004
Before temperature - NLL: 7.302, ECE: 0.154
Optimal temperature: 7.613
After temperature - NLL: 5.574, ECE: 0.003
Epoch 41 completed.
train loss: 4.457527923712339
train acc: 0.1026525347689547
train rank: 37.38459300695379
train weight_norm: 149.57261728715397
train grad_norm: 6.649613906145341
train lr: 0.0006470040137835858
val loss: 5.5774942398071286
val acc: 0.0029296875
val rank: 127.55068359375
test mean_rank: 52.05
test final_rank: 29.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.435, ECE: 0.069
Optimal temperature: 5.500
After temperature - NLL: 5.577, ECE: 0.003
Epoch 62 completed.
train loss: 3.4857975396943126
train acc: 0.2376626289816061
train rank: 18.06070897824136
train weight_norm: 164.6537987836488
train grad_norm: 12.834282286361024
train lr: 0.0003232599582516232
val loss: 7.735656678676605
val acc: 0.0033203125
val rank: 127.80888671875
test mean_rank: 148.669
test final_rank: 212.0
test traces_to_disclosure: nan

Epoch 53 completed.
train loss: 3.7859665545287715
train acc: 0.19309562864513233
train rank: 22.661621312808432
train weight_norm: 160.3560342097098
train grad_norm: 11.731912675589447
train lr: 0.0004607615277568329
val loss: 5.574239814281464
val acc: 0.0060546875
val rank: 126.515625
test mean_rank: 145.811
test final_rank: 154.0
test traces_to_disclosure: nan

Epoch 40 completed.
train loss: 4.5310746163410585
train acc: 0.09510991475998204
train rank: 39.59316993326604
train weight_norm: 148.39259390931684
train grad_norm: 6.253189878975989
train lr: 0.0006619420485606271
val loss: 5.575449860095977
val acc: 0.0052734375
val rank: 127.9603515625
test mean_rank: 187.355
test final_rank: 123.0
test traces_to_disclosure: nan

Epoch 45 completed.
train loss: 4.225997362932639
train acc: 0.13108106213548676
train rank: 31.30225507514581
train weight_norm: 153.5720555386469
train grad_norm: 7.879656842654733
train lr: 0.0005859506022174055
val loss: 6.744517707824707
val acc: 0.00302734375
val rank: 126.53583984375
test mean_rank: 184.803
test final_rank: 172.0
test traces_to_disclosure: nan

Epoch 45 completed.
train loss: 4.2395288206205715
train acc: 0.13078489513234637
train rank: 31.626065500224314
train weight_norm: 153.4859508026369
train grad_norm: 7.690407760588149
train lr: 0.0005859506022174055
val loss: 6.75248476266861
val acc: 0.00419921875
val rank: 128.55537109375
test mean_rank: 102.8
test final_rank: 83.0
test traces_to_disclosure: nan

Epoch 61 completed.
train loss: 3.5256852721782903
train acc: 0.22987466352624494
train rank: 18.656251752467476
train weight_norm: 164.30152264943467
train grad_norm: 12.381670793117554
train lr: 0.0003380379508163031
val loss: 7.703438758850098
val acc: 0.00341796875
val rank: 127.405859375
test mean_rank: 130.616
test final_rank: 40.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.290, ECE: 0.150
Optimal temperature: 7.636
After temperature - NLL: 5.578, ECE: 0.004
Epoch 71 completed.
train loss: 3.215023415245888
train acc: 0.2812149506505159
train rank: 14.737681906123822
train weight_norm: 166.96277675837538
train grad_norm: 13.84805666685833
train lr: 0.00019979378004867344
val loss: 8.137871313095093
val acc: 0.003125
val rank: 127.10205078125
test mean_rank: 95.129
test final_rank: 90.0
test traces_to_disclosure: nan

Epoch 45 completed.
train loss: 4.22918286426231
train acc: 0.1309846764244056
train rank: 31.411442561126062
train weight_norm: 153.29887243196836
train grad_norm: 7.793494340489222
train lr: 0.0005859506022174055
val loss: 6.750167667865753
val acc: 0.00341796875
val rank: 127.46650390625
test mean_rank: 99.767
test final_rank: 92.0
test traces_to_disclosure: nan

Epoch 53 completed.
train loss: 3.817284509278884
train acc: 0.18687787404665773
train rank: 23.17552538974877
train weight_norm: 160.13638715433092
train grad_norm: 11.42712200696322
train lr: 0.0004607615277568329
val loss: 5.578725755214691
val acc: 0.0037109375
val rank: 127.9591796875
test mean_rank: 140.619
test final_rank: 184.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.511, ECE: 0.077
Optimal temperature: 6.418
After temperature - NLL: 5.570, ECE: 0.003
Epoch 41 completed.
train loss: 4.455715142862312
train acc: 0.10428933938986092
train rank: 37.43859178723643
train weight_norm: 149.48822045346236
train grad_norm: 6.533023312962877
train lr: 0.0006470040137835858
val loss: 5.569196033477783
val acc: 0.003515625
val rank: 127.26416015625
test mean_rank: 85.05
test final_rank: 66.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.361, ECE: 0.157
Optimal temperature: 7.613
After temperature - NLL: 5.576, ECE: 0.002
Epoch 63 completed.
train loss: 3.454045756187285
train acc: 0.24343175190668465
train rank: 17.68373920480036
train weight_norm: 165.03201223871923
train grad_norm: 12.913910697289015
train lr: 0.000308656386770065
val loss: 7.780376672744751
val acc: 0.0037109375
val rank: 127.82705078125
test mean_rank: 192.351
test final_rank: 193.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.567, ECE: 0.081
Optimal temperature: 6.480
After temperature - NLL: 5.571, ECE: 0.003
Epoch 54 completed.
train loss: 3.7459124832101978
train acc: 0.1977939939434724
train rank: 22.011944818304173
train weight_norm: 160.9885784683535
train grad_norm: 11.796294155536621
train lr: 0.00044512459438997856
val loss: 5.5767874956130985
val acc: 0.0068359375
val rank: 127.01240234375
test mean_rank: 182.099
test final_rank: 237.0
test traces_to_disclosure: nan

Epoch 62 completed.
train loss: 3.4937607487951925
train acc: 0.2348604334903544
train rank: 18.137007907133242
train weight_norm: 164.70203507722053
train grad_norm: 12.428388937342058
train lr: 0.0003232599582516232
val loss: 7.745399487018585
val acc: 0.0037109375
val rank: 127.8455078125
test mean_rank: 227.357
test final_rank: 219.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.512, ECE: 0.076
Optimal temperature: 6.493
After temperature - NLL: 5.572, ECE: 0.003
Epoch 42 completed.
train loss: 4.393691980341401
train acc: 0.11114323968147152
train rank: 35.61556296265141
train weight_norm: 150.71156432019967
train grad_norm: 6.978699369200902
train lr: 0.0006319209037929501
val loss: 5.57060090303421
val acc: 0.0041015625
val rank: 127.81376953125
test mean_rank: 81.765
test final_rank: 83.0
test traces_to_disclosure: nan

Epoch 72 completed.
train loss: 3.1908992488804606
train acc: 0.28626030450874834
train rank: 14.447252481493944
train weight_norm: 167.19742053853577
train grad_norm: 13.827219515139697
train lr: 0.0001873832784513824
val loss: 8.169876897335053
val acc: 0.001953125
val rank: 127.19501953125
test mean_rank: 41.068
test final_rank: 60.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.352, ECE: 0.155
Optimal temperature: 7.637
After temperature - NLL: 5.580, ECE: 0.004
Epoch 46 completed.
train loss: 4.171441881043754
train acc: 0.1396646478241364
train rank: 30.07632521590399
train weight_norm: 154.4787167193218
train grad_norm: 8.190651821227963
train lr: 0.0005704372540804354
val loss: 6.806177580356598
val acc: 0.003515625
val rank: 126.648046875
test mean_rank: 187.894
test final_rank: 254.0
test traces_to_disclosure: nan

Epoch 41 completed.
train loss: 4.4652711712977124
train acc: 0.10181310284881111
train rank: 37.620929018057424
train weight_norm: 149.58140190126173
train grad_norm: 6.664118814070279
train lr: 0.0006470040137835858
val loss: 5.5702202916145325
val acc: 0.0037109375
val rank: 128.428125
test mean_rank: 7.911
test final_rank: 4.0
test traces_to_disclosure: 227.0

Epoch 46 completed.
train loss: 4.185258814014625
train acc: 0.13656628532974427
train rank: 30.350533801592647
train weight_norm: 154.4044543347928
train grad_norm: 7.992027536639106
train lr: 0.0005704372540804354
val loss: 6.813203287124634
val acc: 0.00439453125
val rank: 128.00791015625
test mean_rank: 48.977
test final_rank: 72.0
test traces_to_disclosure: nan

Epoch 54 completed.
train loss: 3.7797814137521697
train acc: 0.1929186294302378
train rank: 22.572555658366976
train weight_norm: 160.73440728297027
train grad_norm: 11.954720537847548
train lr: 0.00044512459438997856
val loss: 5.581324589252472
val acc: 0.00341796875
val rank: 128.44052734375
test mean_rank: 99.715
test final_rank: 129.0
test traces_to_disclosure: nan

Epoch 46 completed.
train loss: 4.17869678159742
train acc: 0.13705697622252133
train rank: 30.190284670816506
train weight_norm: 154.2027945771153
train grad_norm: 8.046595932754702
train lr: 0.0005704372540804354
val loss: 6.7941241979599
val acc: 0.00322265625
val rank: 126.8671875
test mean_rank: 94.954
test final_rank: 186.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.581, ECE: 0.082
Optimal temperature: 6.418
After temperature - NLL: 5.573, ECE: 0.003
Epoch 64 completed.
train loss: 3.421489232963059
train acc: 0.2478777618887393
train rank: 17.24008629149843
train weight_norm: 165.392922863863
train grad_norm: 12.862739999285223
train lr: 0.0002942416483335689
val loss: 7.822339749336242
val acc: 0.0033203125
val rank: 127.64267578125
test mean_rank: 30.925
test final_rank: 51.0
test traces_to_disclosure: nan

Epoch 63 completed.
train loss: 3.4611819021473984
train acc: 0.23993733176312249
train rank: 17.765225437415882
train weight_norm: 165.08006946087346
train grad_norm: 12.73228390878551
train lr: 0.000308656386770065
val loss: 7.795091736316681
val acc: 0.0037109375
val rank: 128.01796875
test mean_rank: 222.395
test final_rank: 249.0
test traces_to_disclosure: nan

Epoch 42 completed.
train loss: 4.391847282527754
train acc: 0.11138858512786003
train rank: 35.58873969549125
train weight_norm: 150.63586098669728
train grad_norm: 6.91075459755991
train lr: 0.0006319209037929501
val loss: 5.572600424289703
val acc: 0.0041015625
val rank: 127.95673828125
test mean_rank: 47.089
test final_rank: 4.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.406, ECE: 0.161
Optimal temperature: 7.614
After temperature - NLL: 5.577, ECE: 0.003
Epoch 73 completed.
train loss: 3.166753833098174
train acc: 0.2913354503140421
train rank: 14.189871088492598
train weight_norm: 167.41848950933309
train grad_norm: 13.732634189760878
train lr: 0.00017528129181558567
val loss: 8.198319435119629
val acc: 0.0029296875
val rank: 127.2359375
test mean_rank: 206.845
test final_rank: 223.0
test traces_to_disclosure: nan

Epoch 55 completed.
train loss: 3.706584446202377
train acc: 0.2041589558097802
train rank: 21.416025263571107
train weight_norm: 161.54882137280248
train grad_norm: 11.931021412189487
train lr: 0.0004295418164232739
val loss: 5.577176666259765
val acc: 0.00458984375
val rank: 126.86103515625
test mean_rank: 63.643
test final_rank: 63.0
test traces_to_disclosure: 1.0

Before temperature - NLL: 6.646, ECE: 0.089
Optimal temperature: 6.480
After temperature - NLL: 5.574, ECE: 0.004
Epoch 43 completed.
train loss: 4.332525946410476
train acc: 0.11793054620906238
train rank: 33.95386804620907
train weight_norm: 151.8198420691662
train grad_norm: 7.280818790683006
train lr: 0.000616707603797273
val loss: 5.5717840671539305
val acc: 0.00361328125
val rank: 127.46787109375
test mean_rank: 200.409
test final_rank: 235.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.393, ECE: 0.161
Optimal temperature: 7.637
After temperature - NLL: 5.580, ECE: 0.004
Epoch 65 completed.
train loss: 3.3890008419391124
train acc: 0.2530387786002692
train rank: 16.787932158479137
train weight_norm: 165.73780544631614
train grad_norm: 13.107390691306247
train lr: 0.00028002996854866136
val loss: 7.869168901443482
val acc: 0.003515625
val rank: 127.8833984375
test mean_rank: 110.712
test final_rank: 24.0
test traces_to_disclosure: nan

Epoch 55 completed.
train loss: 3.737884594646469
train acc: 0.1989418601390758
train rank: 21.843576505720055
train weight_norm: 161.30228057214632
train grad_norm: 12.11546632546989
train lr: 0.0004295418164232739
val loss: 5.581127095222473
val acc: 0.00322265625
val rank: 128.03095703125
test mean_rank: 212.281
test final_rank: 200.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.569, ECE: 0.082
Optimal temperature: 6.494
After temperature - NLL: 5.572, ECE: 0.003
Epoch 47 completed.
train loss: 4.132864586597817
train acc: 0.14403179676985195
train rank: 29.2158899730821
train weight_norm: 155.27100779489422
train grad_norm: 8.259056915460555
train lr: 0.0005548543928776817
val loss: 6.892240190505982
val acc: 0.00419921875
val rank: 128.75341796875
test mean_rank: 188.453
test final_rank: 207.0
test traces_to_disclosure: nan

Epoch 47 completed.
train loss: 4.119550407173495
train acc: 0.1459086894347241
train rank: 28.96992240074024
train weight_norm: 155.34212854622217
train grad_norm: 8.3971727167147
train lr: 0.0005548543928776817
val loss: 6.877654552459717
val acc: 0.00361328125
val rank: 127.24111328125
test mean_rank: 52.722
test final_rank: 8.0
test traces_to_disclosure: nan

Epoch 74 completed.
train loss: 3.146131886447583
train acc: 0.29412537853297444
train rank: 13.989346750224318
train weight_norm: 167.6272614736424
train grad_norm: 14.156634015597874
train lr: 0.00016349976334100182
val loss: 8.231289303302765
val acc: 0.00283203125
val rank: 127.3568359375
test mean_rank: 127.46
test final_rank: 150.0
test traces_to_disclosure: nan

Epoch 64 completed.
train loss: 3.430450672737522
train acc: 0.24450075706594884
train rank: 17.319585225998207
train weight_norm: 165.44365293853934
train grad_norm: 12.747671230892422
train lr: 0.0002942416483335689
val loss: 7.838484215736389
val acc: 0.00458984375
val rank: 127.984375
test mean_rank: 163.267
test final_rank: 175.0
test traces_to_disclosure: nan

Epoch 42 completed.
train loss: 4.399342880916467
train acc: 0.11054039087034544
train rank: 35.79030850437416
train weight_norm: 150.75798332794685
train grad_norm: 6.822162606528883
train lr: 0.0006319209037929501
val loss: 5.57033804655075
val acc: 0.00400390625
val rank: 128.023046875
test mean_rank: 33.634
test final_rank: 37.0
test traces_to_disclosure: nan

Epoch 47 completed.
train loss: 4.124249829578528
train acc: 0.14535666218034993
train rank: 29.009475591633024
train weight_norm: 155.0736005939267
train grad_norm: 8.281457969128667
train lr: 0.0005548543928776817
val loss: 6.866369509696961
val acc: 0.00380859375
val rank: 127.25009765625
test mean_rank: 163.955
test final_rank: 148.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.463, ECE: 0.171
Optimal temperature: 7.615
After temperature - NLL: 5.577, ECE: 0.004
Before temperature - NLL: 6.636, ECE: 0.088
Optimal temperature: 6.419
After temperature - NLL: 5.574, ECE: 0.004
Epoch 56 completed.
train loss: 3.6703094871336166
train acc: 0.20882051929116194
train rank: 20.81567196612831
train weight_norm: 162.07522661539178
train grad_norm: 12.225153733601376
train lr: 0.0004140285721772396
val loss: 5.577675402164459
val acc: 0.00380859375
val rank: 126.70693359375
test mean_rank: 74.377
test final_rank: 173.0
test traces_to_disclosure: 35.0

Before temperature - NLL: 7.444, ECE: 0.165
Optimal temperature: 7.638
After temperature - NLL: 5.580, ECE: 0.004
Epoch 43 completed.
train loss: 4.331270663606687
train acc: 0.1189522347465231
train rank: 34.04085001682369
train weight_norm: 151.69580821101894
train grad_norm: 7.197699555084051
train lr: 0.000616707603797273
val loss: 5.573865604400635
val acc: 0.0037109375
val rank: 128.05537109375
test mean_rank: 85.462
test final_rank: 116.0
test traces_to_disclosure: nan

Epoch 56 completed.
train loss: 3.6990565605471626
train acc: 0.20391536283086584
train rank: 21.21885339558098
train weight_norm: 161.84262414717062
train grad_norm: 12.123725559181793
train lr: 0.0004140285721772396
val loss: 5.581281471252441
val acc: 0.00361328125
val rank: 127.53134765625
test mean_rank: 139.986
test final_rank: 80.0
test traces_to_disclosure: nan

Epoch 66 completed.
train loss: 3.361425758210358
train acc: 0.2576512729923732
train rank: 16.436600984185734
train weight_norm: 166.0673990191461
train grad_norm: 13.27477802933246
train lr: 0.00026603537262749225
val loss: 7.917744958400727
val acc: 0.003125
val rank: 127.78642578125
test mean_rank: 73.965
test final_rank: 81.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.694, ECE: 0.095
Optimal temperature: 6.481
After temperature - NLL: 5.573, ECE: 0.003
Epoch 75 completed.
train loss: 3.120093273763541
train acc: 0.29969121523104536
train rank: 13.652417353633917
train weight_norm: 167.82086151702174
train grad_norm: 14.131609193669727
train lr: 0.00015205031997383474
val loss: 8.267540693283081
val acc: 0.0025390625
val rank: 127.4001953125
test mean_rank: 103.881
test final_rank: 170.0
test traces_to_disclosure: nan

Epoch 44 completed.
train loss: 4.274551370102175
train acc: 0.12579036283086587
train rank: 32.568873724203684
train weight_norm: 152.83832725052696
train grad_norm: 7.584937955061817
train lr: 0.0006013791274869292
val loss: 5.572221601009369
val acc: 0.004296875
val rank: 127.253125
test mean_rank: 167.407
test final_rank: 205.0
test traces_to_disclosure: 4.0

Epoch 65 completed.
train loss: 3.4015689788243333
train acc: 0.249509309107223
train rank: 16.96863258467923
train weight_norm: 165.79121062558616
train grad_norm: 12.751723569384268
train lr: 0.00028002996854866136
val loss: 7.8723097205162045
val acc: 0.00400390625
val rank: 127.59794921875
test mean_rank: 174.01
test final_rank: 177.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.500, ECE: 0.172
Optimal temperature: 7.616
After temperature - NLL: 5.578, ECE: 0.004
Epoch 48 completed.
train loss: 4.06836555944317
train acc: 0.15278011440107672
train rank: 27.863619476222524
train weight_norm: 156.1596898870721
train grad_norm: 8.77373227437109
train lr: 0.0005392173970118083
val loss: 6.932767701148987
val acc: 0.003515625
val rank: 126.573828125
test mean_rank: 198.828
test final_rank: 119.0
test traces_to_disclosure: nan

Epoch 48 completed.
train loss: 4.082794240794946
train acc: 0.1511485671825931
train rank: 28.159739162741136
train weight_norm: 156.08630775160606
train grad_norm: 8.438036129009902
train lr: 0.0005392173970118083
val loss: 6.947985219955444
val acc: 0.00498046875
val rank: 128.56640625
test mean_rank: 85.529
test final_rank: 75.0
test traces_to_disclosure: nan

Epoch 57 completed.
train loss: 3.6332703795118575
train acc: 0.21395349652310455
train rank: 20.251908437079408
train weight_norm: 162.5841144350182
train grad_norm: 12.417148836287502
train lr: 0.00039860017135100997
val loss: 5.578535199165344
val acc: 0.0060546875
val rank: 126.84716796875
test mean_rank: 153.272
test final_rank: 193.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.652, ECE: 0.087
Optimal temperature: 6.494
After temperature - NLL: 5.575, ECE: 0.003
Epoch 76 completed.
train loss: 3.1001298154828367
train acc: 0.3021218876177658
train rank: 13.464980442462988
train weight_norm: 168.0022487202685
train grad_norm: 14.136652975492533
train lr: 0.00014094426093237933
val loss: 8.304847049713135
val acc: 0.00283203125
val rank: 127.3427734375
test mean_rank: 40.709
test final_rank: 1.0
test traces_to_disclosure: 869.0

Before temperature - NLL: 7.507, ECE: 0.171
Optimal temperature: 7.639
After temperature - NLL: 5.582, ECE: 0.005
Epoch 48 completed.
train loss: 4.073518985694382
train acc: 0.15111001289816062
train rank: 27.912523833557653
train weight_norm: 155.88865565083688
train grad_norm: 8.452884447094489
train lr: 0.0005392173970118083
val loss: 6.92926036119461
val acc: 0.00361328125
val rank: 127.56044921875
test mean_rank: 227.93
test final_rank: 234.0
test traces_to_disclosure: nan

Epoch 67 completed.
train loss: 3.333835513883773
train acc: 0.2628946556751907
train rank: 16.124088716913416
train weight_norm: 166.37567474640423
train grad_norm: 13.314696344091443
train lr: 0.0002522716715466487
val loss: 7.953584921360016
val acc: 0.00556640625
val rank: 128.01513671875
test mean_rank: 26.464
test final_rank: 25.0
test traces_to_disclosure: 383.0

Epoch 43 completed.
train loss: 4.341217348745662
train acc: 0.11737150908479138
train rank: 34.25297393730372
train weight_norm: 151.8271823323656
train grad_norm: 7.288012300600055
train lr: 0.000616707603797273
val loss: 5.573998749256134
val acc: 0.00380859375
val rank: 128.5568359375
test mean_rank: 10.556
test final_rank: 10.0
test traces_to_disclosure: 115.0

Epoch 57 completed.
train loss: 3.6622099340523557
train acc: 0.21062556078959177
train rank: 20.651462258860477
train weight_norm: 162.35864551898686
train grad_norm: 12.285834936798455
train lr: 0.00039860017135100997
val loss: 5.583862626552582
val acc: 0.00322265625
val rank: 128.1642578125
test mean_rank: 68.27
test final_rank: 34.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.698, ECE: 0.095
Optimal temperature: 6.419
After temperature - NLL: 5.574, ECE: 0.004
Epoch 66 completed.
train loss: 3.370333281371988
train acc: 0.2546755832211754
train rank: 16.524627425414984
train weight_norm: 166.11409671910175
train grad_norm: 12.947248184686607
train lr: 0.00026603537262749225
val loss: 7.907110464572907
val acc: 0.00263671875
val rank: 127.33505859375
test mean_rank: 163.596
test final_rank: 239.0
test traces_to_disclosure: 2.0

Epoch 44 completed.
train loss: 4.2747027331694945
train acc: 0.1266157750112158
train rank: 32.63607033703454
train weight_norm: 152.6944549353507
train grad_norm: 7.552242237106451
train lr: 0.0006013791274869292
val loss: 5.573646426200867
val acc: 0.003125
val rank: 127.44599609375
test mean_rank: 241.997
test final_rank: 250.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.540, ECE: 0.176
Optimal temperature: 7.617
After temperature - NLL: 5.578, ECE: 0.003
Before temperature - NLL: 6.773, ECE: 0.100
Optimal temperature: 6.482
After temperature - NLL: 5.577, ECE: 0.004
Epoch 77 completed.
train loss: 3.082456212987168
train acc: 0.30584412853297444
train rank: 13.29496130551817
train weight_norm: 168.17333399095477
train grad_norm: 14.220074949686143
train lr: 0.00013019254655605928
val loss: 8.324563550949097
val acc: 0.00263671875
val rank: 127.35263671875
test mean_rank: 101.606
test final_rank: 122.0
test traces_to_disclosure: nan

Epoch 45 completed.
train loss: 4.219919400773491
train acc: 0.1324777787124271
train rank: 31.239979390982505
train weight_norm: 153.79097630464463
train grad_norm: 7.9444983657801815
train lr: 0.0005859506022174055
val loss: 5.575762128829956
val acc: 0.003515625
val rank: 127.63955078125
test mean_rank: 72.524
test final_rank: 86.0
test traces_to_disclosure: nan

Epoch 58 completed.
train loss: 3.597102464609159
train acc: 0.22013620177209514
train rank: 19.67917577949753
train weight_norm: 163.0653533441581
train grad_norm: 12.514139787255706
train lr: 0.0003832718399135072
val loss: 5.577384197711945
val acc: 0.00556640625
val rank: 126.2482421875
test mean_rank: 123.006
test final_rank: 110.0
test traces_to_disclosure: nan

Epoch 49 completed.
train loss: 4.023199080137353
train acc: 0.1582968820098699
train rank: 26.944027941341407
train weight_norm: 156.93927928602838
train grad_norm: 8.932739559223908
train lr: 0.000523541698309858
val loss: 6.98722734451294
val acc: 0.0033203125
val rank: 127.01826171875
test mean_rank: 197.364
test final_rank: 142.0
test traces_to_disclosure: nan

Epoch 68 completed.
train loss: 3.304698935106978
train acc: 0.26766136720502465
train rank: 15.762272529721846
train weight_norm: 166.66939087987768
train grad_norm: 13.195265802075106
train lr: 0.00023875244841738502
val loss: 8.003670382499696
val acc: 0.00400390625
val rank: 127.7283203125
test mean_rank: 233.405
test final_rank: 252.0
test traces_to_disclosure: nan

Epoch 49 completed.
train loss: 4.0340757280146935
train acc: 0.1563060789591745
train rank: 27.11663372027815
train weight_norm: 156.864257372592
train grad_norm: 8.696921884937248
train lr: 0.000523541698309858
val loss: 7.001581025123596
val acc: 0.0033203125
val rank: 128.70712890625
test mean_rank: 60.965
test final_rank: 56.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.768, ECE: 0.100
Optimal temperature: 6.419
After temperature - NLL: 5.577, ECE: 0.003
Before temperature - NLL: 7.552, ECE: 0.173
Optimal temperature: 7.640
After temperature - NLL: 5.583, ECE: 0.004
Epoch 49 completed.
train loss: 4.028118541391509
train acc: 0.15749775684163303
train rank: 27.016276917900402
train weight_norm: 156.66237759678472
train grad_norm: 8.8414428376415
train lr: 0.000523541698309858
val loss: 6.97808119058609
val acc: 0.0041015625
val rank: 127.11640625
test mean_rank: 82.34
test final_rank: 95.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.716, ECE: 0.094
Optimal temperature: 6.495
After temperature - NLL: 5.577, ECE: 0.004
Epoch 67 completed.
train loss: 3.341622101987836
train acc: 0.2600504009645581
train rank: 16.201521492261104
train weight_norm: 166.42254295775095
train grad_norm: 12.757452403186193
train lr: 0.0002522716715466487
val loss: 7.9725462079048155
val acc: 0.00341796875
val rank: 127.86748046875
test mean_rank: 52.206
test final_rank: 18.0
test traces_to_disclosure: nan

Epoch 45 completed.
train loss: 4.220345232400086
train acc: 0.13245324416778823
train rank: 31.301979937752357
train weight_norm: 153.63295417768563
train grad_norm: 7.790348077462528
train lr: 0.0005859506022174055
val loss: 5.575917530059814
val acc: 0.0044921875
val rank: 127.7513671875
test mean_rank: 150.286
test final_rank: 187.0
test traces_to_disclosure: nan

Epoch 58 completed.
train loss: 3.626125363289588
train acc: 0.21687485980260204
train rank: 20.15098383524002
train weight_norm: 162.8528136050271
train grad_norm: 12.84169749905223
train lr: 0.0003832718399135072
val loss: 5.584767866134643
val acc: 0.0037109375
val rank: 128.0724609375
test mean_rank: 195.706
test final_rank: 244.0
test traces_to_disclosure: nan

Epoch 44 completed.
train loss: 4.282269786216048
train acc: 0.12439364625392552
train rank: 32.73538442126514
train weight_norm: 152.8330705261156
train grad_norm: 7.563594742192351
train lr: 0.0006013791274869292
val loss: 5.576370131969452
val acc: 0.00302734375
val rank: 128.5220703125
test mean_rank: 118.615
test final_rank: 157.0
test traces_to_disclosure: nan

Epoch 78 completed.
train loss: 3.059812303828038
train acc: 0.30993964502018845
train rank: 13.046393071444593
train weight_norm: 168.32945631907072
train grad_norm: 14.068097599961044
train lr: 0.000119805787488893
val loss: 8.346518647670745
val acc: 0.0025390625
val rank: 127.3095703125
test mean_rank: 191.423
test final_rank: 208.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.598, ECE: 0.181
Optimal temperature: 7.619
After temperature - NLL: 5.580, ECE: 0.004
Epoch 69 completed.
train loss: 3.2794851188223264
train acc: 0.2726909488559892
train rank: 15.456107699641093
train weight_norm: 166.94612786902835
train grad_norm: 13.573450068552381
train lr: 0.000225491045080734
val loss: 8.04055496454239
val acc: 0.00498046875
val rank: 127.76826171875
test mean_rank: 152.346
test final_rank: 78.0
test traces_to_disclosure: nan

Epoch 59 completed.
train loss: 3.5613716771753445
train acc: 0.2250361008299686
train rank: 19.162327557200538
train weight_norm: 163.52348351326896
train grad_norm: 12.770061954638551
train lr: 0.00036805870507724853
val loss: 5.579696667194367
val acc: 0.00498046875
val rank: 126.7119140625
test mean_rank: 174.662
test final_rank: 146.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.826, ECE: 0.106
Optimal temperature: 6.483
After temperature - NLL: 5.578, ECE: 0.004
Epoch 50 completed.
train loss: 3.9779388355855825
train acc: 0.1655433350157021
train rank: 26.070601657133242
train weight_norm: 157.6659130540065
train grad_norm: 9.189877378021377
train lr: 0.0005078427667938984
val loss: 7.045180881023407
val acc: 0.00419921875
val rank: 126.9595703125
test mean_rank: 217.967
test final_rank: 207.0
test traces_to_disclosure: nan

Epoch 50 completed.
train loss: 3.987749137596038
train acc: 0.16399765870345445
train rank: 26.2298711585913
train weight_norm: 157.5953525658278
train grad_norm: 8.903293949528694
train lr: 0.0005078427667938984
val loss: 7.06610780954361
val acc: 0.003515625
val rank: 128.78935546875
test mean_rank: 216.775
test final_rank: 243.0
test traces_to_disclosure: nan

Epoch 46 completed.
train loss: 4.16714797077718
train acc: 0.13918447173620457
train rank: 30.00904273216689
train weight_norm: 154.68952567614272
train grad_norm: 8.194818665971198
train lr: 0.0005704372540804354
val loss: 5.57600200176239
val acc: 0.00390625
val rank: 127.1828125
test mean_rank: 180.303
test final_rank: 155.0
test traces_to_disclosure: nan

Epoch 79 completed.
train loss: 3.038882455787299
train acc: 0.3158226783310902
train rank: 12.844400165432932
train weight_norm: 168.47849442127122
train grad_norm: 14.172029997425229
train lr: 0.00010979423420807191
val loss: 8.385996055603027
val acc: 0.00234375
val rank: 127.44638671875
test mean_rank: 125.361
test final_rank: 85.0
test traces_to_disclosure: nan

Epoch 68 completed.
train loss: 3.3123897671859965
train acc: 0.26500287404665773
train rank: 15.855903361933605
train weight_norm: 166.71843268418775
train grad_norm: 12.982283316130143
train lr: 0.00023875244841738502
val loss: 8.008648204803468
val acc: 0.00419921875
val rank: 127.9142578125
test mean_rank: 110.542
test final_rank: 180.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.600, ECE: 0.178
Optimal temperature: 7.640
After temperature - NLL: 5.584, ECE: 0.005
Before temperature - NLL: 6.825, ECE: 0.106
Optimal temperature: 6.423
After temperature - NLL: 5.579, ECE: 0.004
Epoch 50 completed.
train loss: 3.9813724680832547
train acc: 0.1635367597577389
train rank: 26.05111597128757
train weight_norm: 157.38933012761527
train grad_norm: 9.106108209233113
train lr: 0.0005078427667938984
val loss: 7.061615777015686
val acc: 0.003515625
val rank: 127.89736328125
test mean_rank: 242.074
test final_rank: 253.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.778, ECE: 0.100
Optimal temperature: 6.495
After temperature - NLL: 5.579, ECE: 0.004
Epoch 59 completed.
train loss: 3.5889265351147865
train acc: 0.22172568977119786
train rank: 19.558719927658142
train weight_norm: 163.31382159476766
train grad_norm: 12.806904866207244
train lr: 0.00036805870507724853
val loss: 5.586014997959137
val acc: 0.00390625
val rank: 128.2056640625
test mean_rank: 222.918
test final_rank: 239.0
test traces_to_disclosure: nan

Epoch 70 completed.
train loss: 3.252052860016136
train acc: 0.27514265085240014
train rank: 15.120962314939435
train weight_norm: 167.209675969007
train grad_norm: 13.799577564700163
train lr: 0.00021250054894072056
val loss: 8.079970693588256
val acc: 0.00322265625
val rank: 128.0470703125
test mean_rank: 191.268
test final_rank: 244.0
test traces_to_disclosure: nan

Epoch 46 completed.
train loss: 4.167845260727935
train acc: 0.14009400235531627
train rank: 30.1465080333109
train weight_norm: 154.52887696908263
train grad_norm: 8.095866521458497
train lr: 0.0005704372540804354
val loss: 5.578772127628326
val acc: 0.00361328125
val rank: 128.03056640625
test mean_rank: 84.293
test final_rank: 154.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.659, ECE: 0.187
Optimal temperature: 7.620
After temperature - NLL: 5.582, ECE: 0.004
Epoch 45 completed.
train loss: 4.2269324871284
train acc: 0.13055882682817407
train rank: 31.442575145805296
train weight_norm: 153.78720255320601
train grad_norm: 7.889228170430122
train lr: 0.0005859506022174055
val loss: 5.576860320568085
val acc: 0.003125
val rank: 128.16201171875
test mean_rank: 74.241
test final_rank: 68.0
test traces_to_disclosure: nan

Epoch 60 completed.
train loss: 3.5269043233802146
train acc: 0.23024092922835354
train rank: 18.674561532637956
train weight_norm: 163.95991611729008
train grad_norm: 12.734637913227681
train lr: 0.00035297578036961284
val loss: 5.581324577331543
val acc: 0.00546875
val rank: 126.8611328125
test mean_rank: 106.842
test final_rank: 77.0
test traces_to_disclosure: nan

Epoch 69 completed.
train loss: 3.285709552456842
train acc: 0.26964516038582326
train rank: 15.519028291834902
train weight_norm: 166.9987729125698
train grad_norm: 13.008923471414596
train lr: 0.000225491045080734
val loss: 8.027304291725159
val acc: 0.00390625
val rank: 127.353125
test mean_rank: 91.972
test final_rank: 6.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.892, ECE: 0.113
Optimal temperature: 6.485
After temperature - NLL: 5.580, ECE: 0.005
Epoch 51 completed.
train loss: 3.930161411637092
train acc: 0.17233064154329295
train rank: 25.20472675527142
train weight_norm: 158.36309274344822
train grad_norm: 9.351226168128573
train lr: 0.0004921360954139836
val loss: 7.09377156496048
val acc: 0.00380859375
val rank: 127.028515625
test mean_rank: 195.528
test final_rank: 144.0
test traces_to_disclosure: nan

Epoch 80 completed.
train loss: 3.025046859743778
train acc: 0.3173823743831315
train rank: 12.710702669358454
train weight_norm: 168.6127588122432
train grad_norm: 14.230453360055877
train lr: 0.00010016776690797451
val loss: 8.40058387517929
val acc: 0.00263671875
val rank: 127.18515625
test mean_rank: 65.073
test final_rank: 21.0
test traces_to_disclosure: nan

Epoch 51 completed.
train loss: 3.9390111367442566
train acc: 0.1688730232166891
train rank: 25.318002747868995
train weight_norm: 158.29603361433624
train grad_norm: 9.063967240649925
train lr: 0.0004921360954139836
val loss: 7.119446420669556
val acc: 0.00390625
val rank: 128.94169921875
test mean_rank: 210.073
test final_rank: 132.0
test traces_to_disclosure: nan

Epoch 47 completed.
train loss: 4.114482498104768
train acc: 0.14671307200538358
train rank: 28.85203917115298
train weight_norm: 155.5397901532445
train grad_norm: 8.440063567205666
train lr: 0.0005548543928776817
val loss: 5.577601373195648
val acc: 0.00400390625
val rank: 127.398046875
test mean_rank: 169.365
test final_rank: 213.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.647, ECE: 0.183
Optimal temperature: 7.641
After temperature - NLL: 5.585, ECE: 0.004
Epoch 71 completed.
train loss: 3.2252101035009
train acc: 0.28134112830865854
train rank: 14.834037825257965
train weight_norm: 167.45734156451047
train grad_norm: 13.651206148628345
train lr: 0.00019979378004867344
val loss: 8.103729438781738
val acc: 0.0048828125
val rank: 127.73955078125
test mean_rank: 30.955
test final_rank: 27.0
test traces_to_disclosure: nan

Epoch 60 completed.
train loss: 3.5571010363053825
train acc: 0.22558812808434278
train rank: 19.098287138290715
train weight_norm: 163.75845876359836
train grad_norm: 12.871953928617586
train lr: 0.00035297578036961284
val loss: 5.587232458591461
val acc: 0.0037109375
val rank: 128.3080078125
test mean_rank: 156.231
test final_rank: 239.0
test traces_to_disclosure: nan

Epoch 51 completed.
train loss: 3.9329884119662752
train acc: 0.17231662180349933
train rank: 25.234590553499327
train weight_norm: 158.08166109326953
train grad_norm: 9.222201656211906
train lr: 0.0004921360954139836
val loss: 7.107498216629028
val acc: 0.003515625
val rank: 127.56123046875
test mean_rank: 99.06
test final_rank: 34.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.697, ECE: 0.192
Optimal temperature: 7.621
After temperature - NLL: 5.581, ECE: 0.004
Before temperature - NLL: 6.884, ECE: 0.113
Optimal temperature: 6.426
After temperature - NLL: 5.579, ECE: 0.004
Epoch 70 completed.
train loss: 3.261081898677718
train acc: 0.27392468595782865
train rank: 15.24569243494841
train weight_norm: 167.25974062493904
train grad_norm: 13.142485795335842
train lr: 0.00021250054894072056
val loss: 8.086950981616974
val acc: 0.0044921875
val rank: 127.82197265625
test mean_rank: 187.948
test final_rank: 168.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.829, ECE: 0.106
Optimal temperature: 6.496
After temperature - NLL: 5.579, ECE: 0.004
Epoch 61 completed.
train loss: 3.4943895943232213
train acc: 0.23586634982054736
train rank: 18.20437100437416
train weight_norm: 164.37427746360774
train grad_norm: 12.985834986638288
train lr: 0.0003380379508163031
val loss: 5.581395375728607
val acc: 0.00654296875
val rank: 126.48984375
test mean_rank: 119.337
test final_rank: 49.0
test traces_to_disclosure: nan

Epoch 81 completed.
train loss: 3.005251335744742
train acc: 0.32107307088380443
train rank: 12.496053443248092
train weight_norm: 168.73600146830313
train grad_norm: 14.299714538009466
train lr: 9.093588574960833e-05
val loss: 8.43848741054535
val acc: 0.0025390625
val rank: 127.587890625
test mean_rank: 71.304
test final_rank: 92.0
test traces_to_disclosure: nan

Epoch 47 completed.
train loss: 4.115724423692172
train acc: 0.14603661956034097
train rank: 28.941343161170927
train weight_norm: 155.36566059384913
train grad_norm: 8.316847076781409
train lr: 0.0005548543928776817
val loss: 5.578748524188995
val acc: 0.00322265625
val rank: 127.497265625
test mean_rank: 121.542
test final_rank: 151.0
test traces_to_disclosure: nan

Epoch 46 completed.
train loss: 4.173808068959581
train acc: 0.1373952024450426
train rank: 30.194441523665326
train weight_norm: 154.69684896981389
train grad_norm: 8.173825169207456
train lr: 0.0005704372540804354
val loss: 5.578879463672638
val acc: 0.00341796875
val rank: 128.4939453125
test mean_rank: 65.956
test final_rank: 10.0
test traces_to_disclosure: nan

Epoch 72 completed.
train loss: 3.2013356977645033
train acc: 0.28498801312247646
train rank: 14.574225759869895
train weight_norm: 167.6929655722193
train grad_norm: 13.790211303285004
train lr: 0.0001873832784513824
val loss: 8.149584937095643
val acc: 0.0056640625
val rank: 127.954296875
test mean_rank: 32.809
test final_rank: 38.0
test traces_to_disclosure: nan

Epoch 52 completed.
train loss: 3.887186710478319
train acc: 0.17794028992821895
train rank: 24.324704183490358
train weight_norm: 159.01858432456802
train grad_norm: 9.603881839216626
train lr: 0.00047643718475847286
val loss: 7.14883713722229
val acc: 0.0037109375
val rank: 127.00400390625
test mean_rank: 82.881
test final_rank: 115.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.695, ECE: 0.188
Optimal temperature: 7.645
After temperature - NLL: 5.586, ECE: 0.004
Before temperature - NLL: 6.957, ECE: 0.119
Optimal temperature: 6.486
After temperature - NLL: 5.582, ECE: 0.004
Epoch 52 completed.
train loss: 3.8975994583735716
train acc: 0.17669603802153433
train rank: 24.559645230484524
train weight_norm: 158.96648231601358
train grad_norm: 9.265729778570593
train lr: 0.00047643718475847286
val loss: 7.1617713332176205
val acc: 0.00400390625
val rank: 128.5908203125
test mean_rank: 82.699
test final_rank: 147.0
test traces_to_disclosure: nan

Epoch 61 completed.
train loss: 3.523685271454371
train acc: 0.23017083052938536
train rank: 18.603744322005383
train weight_norm: 164.17676585498836
train grad_norm: 13.051724783373379
train lr: 0.0003380379508163031
val loss: 5.587853991985321
val acc: 0.0037109375
val rank: 128.14072265625
test mean_rank: 143.12
test final_rank: 195.0
test traces_to_disclosure: nan

Epoch 48 completed.
train loss: 4.062703729157172
train acc: 0.15283093595782862
train rank: 27.808953005832215
train weight_norm: 156.35759689229994
train grad_norm: 8.68183886427835
train lr: 0.0005392173970118083
val loss: 5.579408848285675
val acc: 0.0033203125
val rank: 127.3853515625
test mean_rank: 204.986
test final_rank: 187.0
test traces_to_disclosure: nan

Epoch 82 completed.
train loss: 2.9890158336865307
train acc: 0.3234021001570211
train rank: 12.378208767945265
train weight_norm: 168.84962775951
train grad_norm: 14.24565570288098
train lr: 8.210770148509823e-05
val loss: 8.452195131778717
val acc: 0.00263671875
val rank: 127.3962890625
test mean_rank: 150.632
test final_rank: 182.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.745, ECE: 0.195
Optimal temperature: 7.625
After temperature - NLL: 5.582, ECE: 0.003
Epoch 71 completed.
train loss: 3.2357406860084583
train acc: 0.27874221904441454
train rank: 14.955687107447284
train weight_norm: 167.50663249476528
train grad_norm: 13.256470822419418
train lr: 0.00019979378004867344
val loss: 8.120018100738525
val acc: 0.00380859375
val rank: 127.98203125
test mean_rank: 155.585
test final_rank: 168.0
test traces_to_disclosure: nan

Epoch 62 completed.
train loss: 3.4628081427608812
train acc: 0.2410641683490354
train rank: 17.79948442406909
train weight_norm: 164.767153776897
train grad_norm: 13.129949462891345
train lr: 0.0003232599582516232
val loss: 5.581355035305023
val acc: 0.0056640625
val rank: 126.36357421875
test mean_rank: 52.161
test final_rank: 86.0
test traces_to_disclosure: 63.0

Epoch 52 completed.
train loss: 3.8888053239434757
train acc: 0.17755825201884254
train rank: 24.37452332884702
train weight_norm: 158.74683422241824
train grad_norm: 9.419456160803923
train lr: 0.00047643718475847286
val loss: 7.15891193151474
val acc: 0.0041015625
val rank: 127.6435546875
test mean_rank: 40.158
test final_rank: 108.0
test traces_to_disclosure: nan

Epoch 73 completed.
train loss: 3.1777083751811954
train acc: 0.2907308490354419
train rank: 14.310936799013012
train weight_norm: 167.91429674473093
train grad_norm: 13.848034388831497
train lr: 0.00017528129181558567
val loss: 8.182013952732087
val acc: 0.0029296875
val rank: 127.958203125
test mean_rank: 36.05
test final_rank: 93.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.938, ECE: 0.118
Optimal temperature: 6.426
After temperature - NLL: 5.580, ECE: 0.004
Before temperature - NLL: 7.737, ECE: 0.192
Optimal temperature: 7.645
After temperature - NLL: 5.587, ECE: 0.005
Before temperature - NLL: 6.894, ECE: 0.111
Optimal temperature: 6.500
After temperature - NLL: 5.581, ECE: 0.004
Epoch 53 completed.
train loss: 3.8441495388385265
train acc: 0.18360776973979365
train rank: 23.61605540601166
train weight_norm: 159.64886629566368
train grad_norm: 9.776289187470336
train lr: 0.0004607615277568329
val loss: 7.200500440597534
val acc: 0.0033203125
val rank: 126.7765625
test mean_rank: 153.346
test final_rank: 136.0
test traces_to_disclosure: nan

Epoch 48 completed.
train loss: 4.064585687655299
train acc: 0.15280464894571555
train rank: 27.88496102512337
train weight_norm: 156.16680153582558
train grad_norm: 8.577971038553965
train lr: 0.0005392173970118083
val loss: 5.579856288433075
val acc: 0.0037109375
val rank: 127.43369140625
test mean_rank: 183.538
test final_rank: 204.0
test traces_to_disclosure: nan

Epoch 83 completed.
train loss: 2.9753580520162672
train acc: 0.3265144823912068
train rank: 12.212716254486315
train weight_norm: 168.95282552986833
train grad_norm: 14.187840612388749
train lr: 7.369192646647374e-05
val loss: 8.468109464645385
val acc: 0.00283203125
val rank: 127.37724609375
test mean_rank: 152.351
test final_rank: 119.0
test traces_to_disclosure: nan

Epoch 62 completed.
train loss: 3.489423272747692
train acc: 0.23653929733064158
train rank: 18.15723313425303
train weight_norm: 164.57803572125025
train grad_norm: 13.118619043567845
train lr: 0.0003232599582516232
val loss: 5.588430178165436
val acc: 0.00322265625
val rank: 127.97080078125
test mean_rank: 179.648
test final_rank: 239.0
test traces_to_disclosure: nan

Epoch 53 completed.
train loss: 3.8526910808173036
train acc: 0.18260535834454913
train rank: 23.722048143786456
train weight_norm: 159.59391868934404
train grad_norm: 9.526895232421666
train lr: 0.0004607615277568329
val loss: 7.229065334796905
val acc: 0.00380859375
val rank: 128.9939453125
test mean_rank: 146.144
test final_rank: 145.0
test traces_to_disclosure: nan

Epoch 47 completed.
train loss: 4.122737156751178
train acc: 0.14513935621354868
train rank: 29.111169526693587
train weight_norm: 155.5534799955688
train grad_norm: 8.367813404966002
train lr: 0.0005548543928776817
val loss: 5.579432559013367
val acc: 0.003125
val rank: 128.2357421875
test mean_rank: 168.635
test final_rank: 206.0
test traces_to_disclosure: nan

Epoch 72 completed.
train loss: 3.2098529030785747
train acc: 0.28362284096007173
train rank: 14.636702977792732
train weight_norm: 167.74231808458038
train grad_norm: 13.216221597419985
train lr: 0.0001873832784513824
val loss: 8.153243947029114
val acc: 0.003515625
val rank: 127.91025390625
test mean_rank: 66.35
test final_rank: 99.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.794, ECE: 0.200
Optimal temperature: 7.626
After temperature - NLL: 5.584, ECE: 0.004
Before temperature - NLL: 7.003, ECE: 0.123
Optimal temperature: 6.488
After temperature - NLL: 5.582, ECE: 0.005
Epoch 63 completed.
train loss: 3.4291088622800436
train acc: 0.24626724427994617
train rank: 17.34955241980709
train weight_norm: 165.14358640209352
train grad_norm: 13.315416608371626
train lr: 0.000308656386770065
val loss: 5.583848786354065
val acc: 0.00537109375
val rank: 126.8517578125
test mean_rank: 190.923
test final_rank: 142.0
test traces_to_disclosure: nan

Epoch 53 completed.
train loss: 3.847286627719412
train acc: 0.18323975157021088
train rank: 23.63068675695379
train weight_norm: 159.3707785382315
train grad_norm: 9.503108566060082
train lr: 0.0004607615277568329
val loss: 7.209340679645538
val acc: 0.00390625
val rank: 127.49228515625
test mean_rank: 220.581
test final_rank: 238.0
test traces_to_disclosure: nan

Epoch 49 completed.
train loss: 4.0127487394402195
train acc: 0.15947629262000895
train rank: 26.726599301816957
train weight_norm: 157.12148635628697
train grad_norm: 8.863831584640275
train lr: 0.000523541698309858
val loss: 5.580359435081482
val acc: 0.00390625
val rank: 127.205859375
test mean_rank: 157.717
test final_rank: 231.0
test traces_to_disclosure: nan

Epoch 74 completed.
train loss: 3.1566792092766125
train acc: 0.2939133299685958
train rank: 14.090837399057873
train weight_norm: 168.12180801341069
train grad_norm: 13.962954329784518
train lr: 0.00016349976334100182
val loss: 8.210037279129029
val acc: 0.0046875
val rank: 127.6857421875
test mean_rank: 115.451
test final_rank: 133.0
test traces_to_disclosure: nan

Epoch 84 completed.
train loss: 2.9565403516006983
train acc: 0.32990725942126514
train rank: 12.051042367653658
train weight_norm: 169.04516641949996
train grad_norm: 14.143861460964299
train lr: 6.569686604762924e-05
val loss: 8.481090879440307
val acc: 0.00244140625
val rank: 127.476953125
test mean_rank: 108.408
test final_rank: 134.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.787, ECE: 0.197
Optimal temperature: 7.647
After temperature - NLL: 5.587, ECE: 0.005
Before temperature - NLL: 6.999, ECE: 0.122
Optimal temperature: 6.430
After temperature - NLL: 5.583, ECE: 0.004
Epoch 49 completed.
train loss: 4.0166259078286375
train acc: 0.15979348923283984
train rank: 26.8784716380664
train weight_norm: 156.9322850597603
train grad_norm: 8.762992608145025
train lr: 0.000523541698309858
val loss: 5.581570672988891
val acc: 0.00322265625
val rank: 127.4314453125
test mean_rank: 100.05
test final_rank: 125.0
test traces_to_disclosure: nan

Epoch 63 completed.
train loss: 3.459058900219595
train acc: 0.24180721455809784
train rank: 17.753736260655003
train weight_norm: 164.9617385399066
train grad_norm: 13.409923993118896
train lr: 0.000308656386770065
val loss: 5.5893649697303776
val acc: 0.003515625
val rank: 128.09921875
test mean_rank: 183.681
test final_rank: 162.0
test traces_to_disclosure: nan

Epoch 54 completed.
train loss: 3.8018269455448936
train acc: 0.1902478689995514
train rank: 22.90947278768506
train weight_norm: 160.24508613488337
train grad_norm: 9.833870920627877
train lr: 0.00044512459438997856
val loss: 7.25114506483078
val acc: 0.004296875
val rank: 126.63173828125
test mean_rank: 135.0
test final_rank: 170.0
test traces_to_disclosure: nan

Epoch 73 completed.
train loss: 3.187939049899177
train acc: 0.28730127018842533
train rank: 14.400677153432031
train weight_norm: 167.96316062394283
train grad_norm: 13.19144597296894
train lr: 0.00017528129181558567
val loss: 8.189617621898652
val acc: 0.00439453125
val rank: 128.089453125
test mean_rank: 170.017
test final_rank: 219.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.833, ECE: 0.203
Optimal temperature: 7.627
After temperature - NLL: 5.584, ECE: 0.003
Epoch 54 completed.
train loss: 3.812318474896663
train acc: 0.18918061630776134
train rank: 23.056574907469717
train weight_norm: 160.1996884974045
train grad_norm: 9.746632386204688
train lr: 0.00044512459438997856
val loss: 7.285081565380096
val acc: 0.0033203125
val rank: 129.21064453125
test mean_rank: 158.186
test final_rank: 163.0
test traces_to_disclosure: nan

Before temperature - NLL: 6.955, ECE: 0.117
Optimal temperature: 6.505
After temperature - NLL: 5.583, ECE: 0.004
Epoch 85 completed.
train loss: 2.942089796708057
train acc: 0.3337907273441005
train rank: 11.928933938986095
train weight_norm: 169.12954370204312
train grad_norm: 14.18780901231936
train lr: 5.813041038794308e-05
val loss: 8.495935606956483
val acc: 0.00185546875
val rank: 127.4076171875
test mean_rank: 44.326
test final_rank: 57.0
test traces_to_disclosure: nan

Epoch 75 completed.
train loss: 3.1302275583849943
train acc: 0.29863622981157467
train rank: 13.810249831763123
train weight_norm: 168.3168622695829
train grad_norm: 13.795655760408673
train lr: 0.00015205031997383474
val loss: 8.246240735054016
val acc: 0.00361328125
val rank: 127.9609375
test mean_rank: 149.992
test final_rank: 220.0
test traces_to_disclosure: nan

Epoch 64 completed.
train loss: 3.3946768162548944
train acc: 0.25201183266038585
train rank: 16.892992583557646
train weight_norm: 165.50312752084363
train grad_norm: 13.476776130080117
train lr: 0.0002942416483335689
val loss: 5.582901811599731
val acc: 0.00615234375
val rank: 126.2076171875
test mean_rank: 177.394
test final_rank: 129.0
test traces_to_disclosure: nan

Epoch 48 completed.
train loss: 4.0728145425444815
train acc: 0.15231220558546432
train rank: 28.04873086305518
train weight_norm: 156.36674961400837
train grad_norm: 8.613941853476065
train lr: 0.0005392173970118083
val loss: 5.581004571914673
val acc: 0.00361328125
val rank: 128.18818359375
test mean_rank: 199.335
test final_rank: 248.0
test traces_to_disclosure: nan

Epoch 54 completed.
train loss: 3.8073964394919804
train acc: 0.18851467866756394
train rank: 22.922758243607
train weight_norm: 159.962690167701
train grad_norm: 9.806555484379512
train lr: 0.00044512459438997856
val loss: 7.25671774148941
val acc: 0.0037109375
val rank: 127.40498046875
test mean_rank: 182.964
test final_rank: 166.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.071, ECE: 0.129
Optimal temperature: 6.494
After temperature - NLL: 5.585, ECE: 0.005
Epoch 50 completed.
train loss: 3.969135514178475
train acc: 0.16618999551368324
train rank: 25.87580263010318
train weight_norm: 157.8482118835541
train grad_norm: 9.151668043777299
train lr: 0.0005078427667938984
val loss: 5.582980549335479
val acc: 0.0033203125
val rank: 127.619140625
test mean_rank: 180.697
test final_rank: 192.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.828, ECE: 0.202
Optimal temperature: 7.648
After temperature - NLL: 5.588, ECE: 0.005
Epoch 74 completed.
train loss: 3.1652123135480714
train acc: 0.2905573547554957
train rank: 14.162289002916108
train weight_norm: 168.17028156881068
train grad_norm: 13.381254215298533
train lr: 0.00016349976334100182
val loss: 8.212083423137665
val acc: 0.00390625
val rank: 127.79521484375
test mean_rank: 127.081
test final_rank: 81.0
test traces_to_disclosure: nan

Epoch 64 completed.
train loss: 3.425429057304824
train acc: 0.24752551592642438
train rank: 17.322879864849707
train weight_norm: 165.32048728305622
train grad_norm: 13.240704390027002
train lr: 0.0002942416483335689
val loss: 5.589382541179657
val acc: 0.002734375
val rank: 127.8482421875
test mean_rank: 214.339
test final_rank: 237.0
test traces_to_disclosure: nan

Epoch 55 completed.
train loss: 3.7624282272154037
train acc: 0.19685291890982504
train rank: 22.26090034768955
train weight_norm: 160.81382993931012
train grad_norm: 10.242441408769599
train lr: 0.0004295418164232739
val loss: 7.296224844455719
val acc: 0.003515625
val rank: 126.8384765625
test mean_rank: 100.322
test final_rank: 38.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.057, ECE: 0.129
Optimal temperature: 6.435
After temperature - NLL: 5.583, ECE: 0.004
Epoch 86 completed.
train loss: 2.934857889909603
train acc: 0.33478087146702556
train rank: 11.848751542171376
train weight_norm: 169.20454409696325
train grad_norm: 14.277647871312169
train lr: 5.100002666564194e-05
val loss: 8.52194311618805
val acc: 0.00244140625
val rank: 127.4703125
test mean_rank: 96.283
test final_rank: 79.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.874, ECE: 0.208
Optimal temperature: 7.630
After temperature - NLL: 5.584, ECE: 0.004
Epoch 55 completed.
train loss: 3.7735070553313674
train acc: 0.1936108540825482
train rank: 22.37285147487663
train weight_norm: 160.7669132289613
train grad_norm: 9.806031434788736
train lr: 0.0004295418164232739
val loss: 7.339882743358612
val acc: 0.0033203125
val rank: 129.4541015625
test mean_rank: 160.693
test final_rank: 148.0
test traces_to_disclosure: nan

Epoch 76 completed.
train loss: 3.1118276141694223
train acc: 0.30179592866756394
train rank: 13.599419232279047
train weight_norm: 168.49803660344213
train grad_norm: 14.125176760578631
train lr: 0.00014094426093237933
val loss: 8.274335062503814
val acc: 0.002734375
val rank: 127.8658203125
test mean_rank: 136.159
test final_rank: 102.0
test traces_to_disclosure: nan

Epoch 50 completed.
train loss: 3.9717776380669862
train acc: 0.16608134253028264
train rank: 26.019657427658142
train weight_norm: 157.6456514157727
train grad_norm: 8.927966589322239
train lr: 0.0005078427667938984
val loss: 5.583703052997589
val acc: 0.00380859375
val rank: 127.71416015625
test mean_rank: 165.503
test final_rank: 103.0
test traces_to_disclosure: nan

Epoch 65 completed.
train loss: 3.3665034443661472
train acc: 0.2570431667788246
train rank: 16.556308532413638
train weight_norm: 165.84748833127045
train grad_norm: 13.506624585970876
train lr: 0.00028002996854866136
val loss: 5.5824502348899845
val acc: 0.00537109375
val rank: 126.0521484375
test mean_rank: 166.62
test final_rank: 187.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.114, ECE: 0.134
Optimal temperature: 6.500
After temperature - NLL: 5.585, ECE: 0.005
Before temperature - NLL: 7.012, ECE: 0.122
Optimal temperature: 6.511
After temperature - NLL: 5.584, ECE: 0.004
Epoch 55 completed.
train loss: 3.768294951476127
train acc: 0.19461677041274117
train rank: 22.31017447566173
train weight_norm: 160.52195465481375
train grad_norm: 9.898106139880074
train lr: 0.0004295418164232739
val loss: 7.31353667974472
val acc: 0.0037109375
val rank: 127.59990234375
test mean_rank: 43.565
test final_rank: 79.0
test traces_to_disclosure: nan

Epoch 51 completed.
train loss: 3.926874321530677
train acc: 0.17136853689995513
train rank: 25.07905731269628
train weight_norm: 158.54140532586578
train grad_norm: 9.420964318468164
train lr: 0.0004921360954139836
val loss: 5.5834709167480465
val acc: 0.00361328125
val rank: 127.28037109375
test mean_rank: 117.207
test final_rank: 64.0
test traces_to_disclosure: nan

Epoch 49 completed.
train loss: 4.0229086349661864
train acc: 0.15905219549125169
train rank: 27.000860461529832
train weight_norm: 157.14094872691578
train grad_norm: 8.786894062899858
train lr: 0.000523541698309858
val loss: 5.582019412517548
val acc: 0.00322265625
val rank: 128.290234375
test mean_rank: 173.205
test final_rank: 225.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.865, ECE: 0.205
Optimal temperature: 7.650
After temperature - NLL: 5.589, ECE: 0.005
Epoch 75 completed.
train loss: 3.139447843081858
train acc: 0.29528200706594887
train rank: 13.882167591969491
train weight_norm: 168.36514393438958
train grad_norm: 13.611603495764559
train lr: 0.00015205031997383474
val loss: 8.255446040630341
val acc: 0.00361328125
val rank: 127.95654296875
test mean_rank: 75.007
test final_rank: 143.0
test traces_to_disclosure: nan

Epoch 65 completed.
train loss: 3.3967050046009457
train acc: 0.2521800695379094
train rank: 16.92144564546882
train weight_norm: 165.66393341392515
train grad_norm: 13.509160619735106
train lr: 0.00028002996854866136
val loss: 5.590131306648255
val acc: 0.003515625
val rank: 127.95302734375
test mean_rank: 137.605
test final_rank: 179.0
test traces_to_disclosure: nan

Epoch 87 completed.
train loss: 2.9177608753117066
train acc: 0.3373587511215792
train rank: 11.686886636384028
train weight_norm: 169.26989292244815
train grad_norm: 14.03910959915763
train lr: 4.431275170859809e-05
val loss: 8.532561922073365
val acc: 0.00263671875
val rank: 127.372265625
test mean_rank: 77.039
test final_rank: 58.0
test traces_to_disclosure: nan

Epoch 77 completed.
train loss: 3.093070563525563
train acc: 0.30507654777927323
train rank: 13.38184163301929
train weight_norm: 168.667629349262
train grad_norm: 14.050447907478036
train lr: 0.00013019254655605928
val loss: 8.301236343383788
val acc: 0.00361328125
val rank: 127.8431640625
test mean_rank: 192.003
test final_rank: 223.0
test traces_to_disclosure: nan

Epoch 56 completed.
train loss: 3.724900313694416
train acc: 0.2021138262673845
train rank: 21.633713268281742
train weight_norm: 161.35318419971418
train grad_norm: 10.367074132857306
train lr: 0.0004140285721772396
val loss: 7.3437167525291445
val acc: 0.00361328125
val rank: 126.64443359375
test mean_rank: 152.655
test final_rank: 173.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.912, ECE: 0.212
Optimal temperature: 7.630
After temperature - NLL: 5.585, ECE: 0.004
Epoch 56 completed.
train loss: 3.7356292720116966
train acc: 0.1994623429789143
train rank: 21.76110188144908
train weight_norm: 161.30377460613295
train grad_norm: 10.102579418245215
train lr: 0.0004140285721772396
val loss: 7.387053108215332
val acc: 0.00419921875
val rank: 128.9896484375
test mean_rank: 213.161
test final_rank: 231.0
test traces_to_disclosure: nan

Epoch 66 completed.
train loss: 3.336272771072901
train acc: 0.2615067014356214
train rank: 16.143718105091967
train weight_norm: 166.16958173891948
train grad_norm: 13.499456402967429
train lr: 0.00026603537262749225
val loss: 5.5836612462997435
val acc: 0.00537109375
val rank: 126.1103515625
test mean_rank: 176.289
test final_rank: 101.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.113, ECE: 0.134
Optimal temperature: 6.442
After temperature - NLL: 5.585, ECE: 0.004
Epoch 51 completed.
train loss: 3.9284126094340635
train acc: 0.17161738728129206
train rank: 25.203007584679224
train weight_norm: 158.32649909228064
train grad_norm: 9.257903821926071
train lr: 0.0004921360954139836
val loss: 5.585468232631683
val acc: 0.00419921875
val rank: 127.82197265625
test mean_rank: 112.348
test final_rank: 129.0
test traces_to_disclosure: nan

Epoch 88 completed.
train loss: 2.9057555683207865
train acc: 0.34058854867653654
train rank: 11.578480750897265
train weight_norm: 169.3277614425173
train grad_norm: 14.11740284484961
train lr: 3.807518504982966e-05
val loss: 8.533888006210328
val acc: 0.002734375
val rank: 127.39384765625
test mean_rank: 35.235
test final_rank: 24.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.171, ECE: 0.140
Optimal temperature: 6.506
After temperature - NLL: 5.585, ECE: 0.005
Epoch 78 completed.
train loss: 3.071544496400199
train acc: 0.30959966633019287
train rank: 13.172327136608345
train weight_norm: 168.82443201125247
train grad_norm: 13.96530272422746
train lr: 0.000119805787488893
val loss: 8.321992111206054
val acc: 0.00361328125
val rank: 127.8875
test mean_rank: 154.313
test final_rank: 228.0
test traces_to_disclosure: nan

Epoch 76 completed.
train loss: 3.1188443560619534
train acc: 0.2996754430237775
train rank: 13.673219142552716
train weight_norm: 168.54531785067465
train grad_norm: 13.536064007438249
train lr: 0.00014094426093237933
val loss: 8.29041154384613
val acc: 0.00341796875
val rank: 127.98232421875
test mean_rank: 112.072
test final_rank: 74.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.920, ECE: 0.208
Optimal temperature: 7.650
After temperature - NLL: 5.591, ECE: 0.005
Before temperature - NLL: 7.074, ECE: 0.128
Optimal temperature: 6.512
After temperature - NLL: 5.586, ECE: 0.005
Epoch 52 completed.
train loss: 3.8793213178139196
train acc: 0.1770640561911171
train rank: 24.236840721736204
train weight_norm: 159.19445644372928
train grad_norm: 9.583161714133082
train lr: 0.00047643718475847286
val loss: 5.583869242668152
val acc: 0.00361328125
val rank: 126.9970703125
test mean_rank: 67.384
test final_rank: 86.0
test traces_to_disclosure: nan

Epoch 56 completed.
train loss: 3.729197704294649
train acc: 0.20015632009869894
train rank: 21.67232538414087
train weight_norm: 161.0496744583971
train grad_norm: 10.10593935035209
train lr: 0.0004140285721772396
val loss: 7.359755158424377
val acc: 0.00458984375
val rank: 127.1283203125
test mean_rank: 189.915
test final_rank: 125.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.957, ECE: 0.214
Optimal temperature: 7.636
After temperature - NLL: 5.586, ECE: 0.004
Epoch 66 completed.
train loss: 3.3640521285030114
train acc: 0.2580981521982952
train rank: 16.521210113840286
train weight_norm: 165.99286219204336
train grad_norm: 13.918278991076667
train lr: 0.00026603537262749225
val loss: 5.592874014377594
val acc: 0.0033203125
val rank: 128.2591796875
test mean_rank: 159.269
test final_rank: 196.0
test traces_to_disclosure: nan

Epoch 50 completed.
train loss: 3.9781544375387528
train acc: 0.16399240130103185
train rank: 26.11689659039928
train weight_norm: 157.87089712436978
train grad_norm: 9.04702607125813
train lr: 0.0005078427667938984
val loss: 5.5847220659255985
val acc: 0.00283203125
val rank: 128.26875
test mean_rank: 165.138
test final_rank: 75.0
test traces_to_disclosure: nan

Epoch 57 completed.
train loss: 3.685881329096182
train acc: 0.20889412292507847
train rank: 21.021737606550023
train weight_norm: 161.86410284743906
train grad_norm: 10.456023994597123
train lr: 0.00039860017135100997
val loss: 7.399849605560303
val acc: 0.00439453125
val rank: 126.59140625
test mean_rank: 14.851
test final_rank: 0.0
test traces_to_disclosure: 869.0

Epoch 67 completed.
train loss: 3.3110487804438513
train acc: 0.2669200734634365
train rank: 15.888082169694929
train weight_norm: 166.4780726352162
train grad_norm: 13.670660450308548
train lr: 0.0002522716715466487
val loss: 5.5854032158851625
val acc: 0.00556640625
val rank: 126.35458984375
test mean_rank: 105.652
test final_rank: 65.0
test traces_to_disclosure: nan

Epoch 57 completed.
train loss: 3.693842680264931
train acc: 0.2062794414535666
train rank: 21.097985713885148
train weight_norm: 161.81752777409392
train grad_norm: 10.21950791712898
train lr: 0.00039860017135100997
val loss: 7.4465602278709415
val acc: 0.0041015625
val rank: 129.154296875
test mean_rank: 198.444
test final_rank: 142.0
test traces_to_disclosure: nan

Epoch 89 completed.
train loss: 2.8999605557478936
train acc: 0.341168615410498
train rank: 11.517806822005383
train weight_norm: 169.3769492210735
train grad_norm: 14.062937645117039
train lr: 3.2293482414558174e-05
val loss: 8.553065061569214
val acc: 0.0025390625
val rank: 127.4431640625
test mean_rank: 132.771
test final_rank: 170.0
test traces_to_disclosure: nan

Epoch 79 completed.
train loss: 3.0484106441205157
train acc: 0.3142261804620906
train rank: 12.949248541947062
train weight_norm: 168.97162659357647
train grad_norm: 13.751871310085582
train lr: 0.00010979423420807191
val loss: 8.35108972787857
val acc: 0.00419921875
val rank: 127.8916015625
test mean_rank: 181.688
test final_rank: 108.0
test traces_to_disclosure: nan

Epoch 77 completed.
train loss: 3.1047801377795747
train acc: 0.3021534320323015
train rank: 13.48959384813818
train weight_norm: 168.7156662446868
train grad_norm: 13.479814749929469
train lr: 0.00013019254655605928
val loss: 8.315050411224366
val acc: 0.00361328125
val rank: 128.17626953125
test mean_rank: 181.207
test final_rank: 227.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.154, ECE: 0.138
Optimal temperature: 6.448
After temperature - NLL: 5.585, ECE: 0.004
Epoch 52 completed.
train loss: 3.8842702941971545
train acc: 0.17713941229250782
train rank: 24.40428723642889
train weight_norm: 158.97015567931382
train grad_norm: 9.450991954209213
train lr: 0.00047643718475847286
val loss: 5.584709012508393
val acc: 0.00439453125
val rank: 127.27998046875
test mean_rank: 59.734
test final_rank: 66.0
test traces_to_disclosure: nan

Before temperature - NLL: 8.002, ECE: 0.219
Optimal temperature: 7.639
After temperature - NLL: 5.587, ECE: 0.004
Before temperature - NLL: 7.953, ECE: 0.212
Optimal temperature: 7.651
After temperature - NLL: 5.591, ECE: 0.005
Before temperature - NLL: 7.227, ECE: 0.144
Optimal temperature: 6.512
After temperature - NLL: 5.588, ECE: 0.005
Epoch 68 completed.
train loss: 3.280300915963236
train acc: 0.27166750785105426
train rank: 15.4886685453118
train weight_norm: 166.76963254036247
train grad_norm: 13.76724396767574
train lr: 0.00023875244841738502
val loss: 5.585959041118622
val acc: 0.00595703125
val rank: 126.391796875
test mean_rank: 77.163
test final_rank: 16.0
test traces_to_disclosure: nan

Epoch 90 completed.
train loss: 2.8905194447467335
train acc: 0.3437605148048452
train rank: 11.42453875056079
train weight_norm: 169.41896949300332
train grad_norm: 14.078640569109929
train lr: 2.6973349645251412e-05
val loss: 8.549494886398316
val acc: 0.00263671875
val rank: 127.3271484375
test mean_rank: 87.45
test final_rank: 2.0
test traces_to_disclosure: nan

Epoch 57 completed.
train loss: 3.689358863342819
train acc: 0.2071188733737102
train rank: 21.080804522768055
train weight_norm: 161.55826912829758
train grad_norm: 10.281131612442158
train lr: 0.00039860017135100997
val loss: 7.424946570396424
val acc: 0.0033203125
val rank: 127.84775390625
test mean_rank: 86.557
test final_rank: 121.0
test traces_to_disclosure: nan

Epoch 67 completed.
train loss: 3.3393142281117703
train acc: 0.2619307985643786
train rank: 16.231136440107672
train weight_norm: 166.30108459918694
train grad_norm: 13.793535013335848
train lr: 0.0002522716715466487
val loss: 5.593330597877502
val acc: 0.0041015625
val rank: 128.2041015625
test mean_rank: 54.007
test final_rank: 9.0
test traces_to_disclosure: nan

Epoch 58 completed.
train loss: 3.6490114238990587
train acc: 0.21339621186630778
train rank: 20.45452872644684
train weight_norm: 162.35158892949548
train grad_norm: 10.598429924511915
train lr: 0.0003832718399135072
val loss: 7.447599375247956
val acc: 0.00419921875
val rank: 126.9998046875
test mean_rank: 118.964
test final_rank: 132.0
test traces_to_disclosure: nan

Epoch 53 completed.
train loss: 3.837441097197911
train acc: 0.1855144543517272
train rank: 23.501733190331983
train weight_norm: 159.8246718291536
train grad_norm: 9.844813333061863
train lr: 0.0004607615277568329
val loss: 5.586475110054016
val acc: 0.00341796875
val rank: 127.51220703125
test mean_rank: 230.065
test final_rank: 233.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.133, ECE: 0.134
Optimal temperature: 6.516
After temperature - NLL: 5.588, ECE: 0.004
Epoch 80 completed.
train loss: 3.034749225844926
train acc: 0.3168566341408704
train rank: 12.817494532301481
train weight_norm: 169.1074566745155
train grad_norm: 13.946075588363467
train lr: 0.00010016776690797451
val loss: 8.390447354316711
val acc: 0.0029296875
val rank: 128.1423828125
test mean_rank: 102.795
test final_rank: 99.0
test traces_to_disclosure: nan

Epoch 58 completed.
train loss: 3.658954078384235
train acc: 0.21209237606550024
train rank: 20.576570561350383
train weight_norm: 162.3103628220795
train grad_norm: 10.34359959687665
train lr: 0.0003832718399135072
val loss: 7.495096325874329
val acc: 0.00322265625
val rank: 129.4826171875
test mean_rank: 74.657
test final_rank: 54.0
test traces_to_disclosure: nan

Epoch 78 completed.
train loss: 3.0784854423630765
train acc: 0.3070691032974428
train rank: 13.225845740803052
train weight_norm: 168.8695728366505
train grad_norm: 13.482694273631823
train lr: 0.000119805787488893
val loss: 8.326829552650452
val acc: 0.00380859375
val rank: 127.9892578125
test mean_rank: 110.772
test final_rank: 133.0
test traces_to_disclosure: nan

Epoch 51 completed.
train loss: 3.9322916065539517
train acc: 0.1703976699192463
train rank: 25.24117807873486
train weight_norm: 158.56423372285568
train grad_norm: 9.296783668997664
train lr: 0.0004921360954139836
val loss: 5.5858815789222716
val acc: 0.0041015625
val rank: 128.46123046875
test mean_rank: 161.164
test final_rank: 55.0
test traces_to_disclosure: nan

Epoch 91 completed.
train loss: 2.8770423365473587
train acc: 0.34814869336025117
train rank: 11.32172148384926
train weight_norm: 169.45410679138695
train grad_norm: 13.987988070794922
train lr: 2.2120037070645153e-05
val loss: 8.565304708480834
val acc: 0.00283203125
val rank: 127.38681640625
test mean_rank: 190.457
test final_rank: 161.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.227, ECE: 0.144
Optimal temperature: 7.588
After temperature - NLL: 5.576, ECE: 0.004
Before temperature - NLL: 7.989, ECE: 0.215
Optimal temperature: 7.657
After temperature - NLL: 5.592, ECE: 0.004
Before temperature - NLL: 8.032, ECE: 0.221
Optimal temperature: 7.644
After temperature - NLL: 5.587, ECE: 0.003
Epoch 53 completed.
train loss: 3.840430202907701
train acc: 0.18403011440107672
train rank: 23.63395861372813
train weight_norm: 159.58616125824912
train grad_norm: 9.521828721351056
train lr: 0.0004607615277568329
val loss: 5.576388394832611
val acc: 0.00458984375
val rank: 127.7263671875
test mean_rank: 58.398
test final_rank: 28.0
test traces_to_disclosure: nan

Epoch 68 completed.
train loss: 3.308037930831293
train acc: 0.26703398384925975
train rank: 15.809087945827725
train weight_norm: 166.59771806062366
train grad_norm: 13.805142389513179
train lr: 0.00023875244841738502
val loss: 5.594250786304474
val acc: 0.0041015625
val rank: 128.28603515625
test mean_rank: 167.372
test final_rank: 182.0
test traces_to_disclosure: nan

Epoch 69 completed.
train loss: 3.2534966436722397
train acc: 0.277249116756393
train rank: 15.175900417788247
train weight_norm: 167.04698612246867
train grad_norm: 13.923286219101985
train lr: 0.000225491045080734
val loss: 5.586809647083283
val acc: 0.00537109375
val rank: 126.39833984375
test mean_rank: 86.599
test final_rank: 159.0
test traces_to_disclosure: nan

Epoch 81 completed.
train loss: 3.017626963585896
train acc: 0.31942750392552716
train rank: 12.631461347577389
train weight_norm: 169.22974059590928
train grad_norm: 13.887743002718446
train lr: 9.093588574960833e-05
val loss: 8.40595383644104
val acc: 0.00263671875
val rank: 127.960546875
test mean_rank: 77.556
test final_rank: 142.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.282, ECE: 0.150
Optimal temperature: 7.668
After temperature - NLL: 5.577, ECE: 0.004
Epoch 79 completed.
train loss: 3.058145671320796
train acc: 0.30968553723642894
train rank: 13.019354250785105
train weight_norm: 169.01801522711978
train grad_norm: 13.464804353638131
train lr: 0.00010979423420807191
val loss: 8.356880402565002
val acc: 0.003125
val rank: 127.93828125
test mean_rank: 35.943
test final_rank: 30.0
test traces_to_disclosure: nan

Epoch 58 completed.
train loss: 3.6550604526961314
train acc: 0.21162621971736204
train rank: 20.516029819986542
train weight_norm: 162.04512052579767
train grad_norm: 10.348337591001169
train lr: 0.0003832718399135072
val loss: 7.4542975425720215
val acc: 0.003515625
val rank: 127.433984375
test mean_rank: 217.997
test final_rank: 251.0
test traces_to_disclosure: nan

Epoch 59 completed.
train loss: 3.614323522649896
train acc: 0.21867814883355763
train rank: 19.917302812359804
train weight_norm: 162.8138218210908
train grad_norm: 10.767242889770854
train lr: 0.00036805870507724853
val loss: 7.5001326441764835
val acc: 0.00390625
val rank: 127.0892578125
test mean_rank: 34.433
test final_rank: 3.0
test traces_to_disclosure: nan

Epoch 54 completed.
train loss: 3.7955863049020677
train acc: 0.18956090174966353
train rank: 22.752670760430686
train weight_norm: 160.41126391389164
train grad_norm: 9.872697517627934
train lr: 0.00044512459438997856
val loss: 5.575533163547516
val acc: 0.003125
val rank: 127.3025390625
test mean_rank: 25.651
test final_rank: 23.0
test traces_to_disclosure: 742.0

Epoch 59 completed.
train loss: 3.622615814529871
train acc: 0.21818395300583218
train rank: 20.011324444818303
train weight_norm: 162.77303441645265
train grad_norm: 10.38507241168352
train lr: 0.00036805870507724853
val loss: 7.536426055431366
val acc: 0.003125
val rank: 129.17158203125
test mean_rank: 159.74
test final_rank: 196.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.187, ECE: 0.140
Optimal temperature: 6.523
After temperature - NLL: 5.589, ECE: 0.004
Epoch 92 completed.
train loss: 2.868813330199805
train acc: 0.34916161956034103
train rank: 11.237042255495737
train weight_norm: 169.4835627789217
train grad_norm: 14.007455448564267
train lr: 1.773833432430308e-05
val loss: 8.586703968048095
val acc: 0.00244140625
val rank: 127.49658203125
test mean_rank: 45.464
test final_rank: 68.0
test traces_to_disclosure: nan

Epoch 52 completed.
train loss: 3.8916008170809433
train acc: 0.17603360531628534
train rank: 24.472582646366085
train weight_norm: 159.2223084842749
train grad_norm: 9.491751847214989
train lr: 0.00047643718475847286
val loss: 5.586999022960663
val acc: 0.00380859375
val rank: 128.23681640625
test mean_rank: 234.988
test final_rank: 253.0
test traces_to_disclosure: nan

Before temperature - NLL: 8.031, ECE: 0.218
Optimal temperature: 7.663
After temperature - NLL: 5.592, ECE: 0.005
Epoch 69 completed.
train loss: 3.280665956628114
train acc: 0.2724368410722297
train rank: 15.511250841184388
train weight_norm: 166.8774632439933
train grad_norm: 13.942562619706528
train lr: 0.000225491045080734
val loss: 5.593798494338989
val acc: 0.00361328125
val rank: 127.821875
test mean_rank: 22.083
test final_rank: 26.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.269, ECE: 0.149
Optimal temperature: 7.589
After temperature - NLL: 5.577, ECE: 0.003
Before temperature - NLL: 8.068, ECE: 0.225
Optimal temperature: 7.650
After temperature - NLL: 5.587, ECE: 0.004
Epoch 80 completed.
train loss: 3.0455157374950628
train acc: 0.3123159909152086
train rank: 12.908027002018843
train weight_norm: 169.15238499337283
train grad_norm: 13.562280469572265
train lr: 0.00010016776690797451
val loss: 8.386738491058349
val acc: 0.00400390625
val rank: 128.10009765625
test mean_rank: 110.882
test final_rank: 138.0
test traces_to_disclosure: nan

Epoch 82 completed.
train loss: 2.9974738646644603
train acc: 0.32382093988335575
train rank: 12.445873289591747
train weight_norm: 169.34373074807675
train grad_norm: 13.889030649303981
train lr: 8.210770148509823e-05
val loss: 8.422149300575256
val acc: 0.0037109375
val rank: 127.9537109375
test mean_rank: 137.762
test final_rank: 60.0
test traces_to_disclosure: nan

Epoch 54 completed.
train loss: 3.8013215308876087
train acc: 0.18812212595334227
train rank: 22.98828125
train weight_norm: 160.22063373135882
train grad_norm: 9.751557733461057
train lr: 0.00044512459438997856
val loss: 5.57727427482605
val acc: 0.00361328125
val rank: 127.98486328125
test mean_rank: 10.412
test final_rank: 2.0
test traces_to_disclosure: 222.0

Epoch 70 completed.
train loss: 3.22674401772295
train acc: 0.2805367457379991
train rank: 14.88166638627187
train weight_norm: 167.30695932855141
train grad_norm: 13.994708699776321
train lr: 0.00021250054894072056
val loss: 5.586667871475219
val acc: 0.00400390625
val rank: 126.23173828125
test mean_rank: 38.07
test final_rank: 18.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.332, ECE: 0.154
Optimal temperature: 7.669
After temperature - NLL: 5.579, ECE: 0.004
Epoch 93 completed.
train loss: 2.865789864939283
train acc: 0.3486323743831314
train rank: 11.201810649394348
train weight_norm: 169.5064926985957
train grad_norm: 13.872756522988961
train lr: 1.3832565617826394e-05
val loss: 8.570864176750183
val acc: 0.00224609375
val rank: 127.44755859375
test mean_rank: 42.52
test final_rank: 46.0
test traces_to_disclosure: nan

Epoch 60 completed.
train loss: 3.578879281617751
train acc: 0.2253042283535218
train rank: 19.418384084791388
train weight_norm: 163.25438865188337
train grad_norm: 10.792172807303132
train lr: 0.00035297578036961284
val loss: 7.541934549808502
val acc: 0.003125
val rank: 126.887890625
test mean_rank: 169.176
test final_rank: 132.0
test traces_to_disclosure: nan

Epoch 59 completed.
train loss: 3.6203538996053415
train acc: 0.21680651357110808
train rank: 20.0150747252131
train weight_norm: 162.49591791449024
train grad_norm: 10.566356206884366
train lr: 0.00036805870507724853
val loss: 7.4975017786026
val acc: 0.00341796875
val rank: 127.406640625
test mean_rank: 92.586
test final_rank: 30.0
test traces_to_disclosure: nan

Epoch 55 completed.
train loss: 3.755923694107446
train acc: 0.19603451659937188
train rank: 22.114621887617766
train weight_norm: 161.0310022070453
train grad_norm: 10.164364571963546
train lr: 0.0004295418164232739
val loss: 5.576684165000915
val acc: 0.00341796875
val rank: 127.448828125
test mean_rank: 151.557
test final_rank: 237.0
test traces_to_disclosure: nan

Epoch 60 completed.
train loss: 3.5881159979433903
train acc: 0.22211298508299687
train rank: 19.47932263627187
train weight_norm: 163.2154914293082
train grad_norm: 10.588742100065067
train lr: 0.00035297578036961284
val loss: 7.5886023998260494
val acc: 0.00458984375
val rank: 129.40283203125
test mean_rank: 213.948
test final_rank: 219.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.237, ECE: 0.144
Optimal temperature: 7.695
After temperature - NLL: 5.578, ECE: 0.004
Before temperature - NLL: 8.059, ECE: 0.222
Optimal temperature: 7.669
After temperature - NLL: 5.592, ECE: 0.005
Epoch 83 completed.
train loss: 2.9847956573337435
train acc: 0.32616223642889186
train rank: 12.304184541834902
train weight_norm: 169.4477691298714
train grad_norm: 13.891444289253972
train lr: 7.369192646647374e-05
val loss: 8.440886664390565
val acc: 0.00341796875
val rank: 127.8802734375
test mean_rank: 159.849
test final_rank: 160.0
test traces_to_disclosure: nan

Epoch 70 completed.
train loss: 3.2555325759692595
train acc: 0.27521800695379095
train rank: 15.191358933378197
train weight_norm: 167.14354750209262
train grad_norm: 14.064237065805793
train lr: 0.00021250054894072056
val loss: 5.593636095523834
val acc: 0.0037109375
val rank: 127.7626953125
test mean_rank: 136.958
test final_rank: 239.0
test traces_to_disclosure: 60.0

Epoch 53 completed.
train loss: 3.8480600659330633
train acc: 0.1823582604306864
train rank: 23.723045297779272
train weight_norm: 159.8530028118955
train grad_norm: 9.686436858121464
train lr: 0.0004607615277568329
val loss: 5.576745140552521
val acc: 0.003515625
val rank: 128.52373046875
test mean_rank: 190.214
test final_rank: 250.0
test traces_to_disclosure: nan

Epoch 81 completed.
train loss: 3.0251243178648712
train acc: 0.3170231185509197
train rank: 12.697688845895021
train weight_norm: 169.27606646677674
train grad_norm: 13.579838498556263
train lr: 9.093588574960833e-05
val loss: 8.405624079704285
val acc: 0.003515625
val rank: 127.90595703125
test mean_rank: 115.361
test final_rank: 76.0
test traces_to_disclosure: nan

Before temperature - NLL: 8.112, ECE: 0.229
Optimal temperature: 7.653
After temperature - NLL: 5.588, ECE: 0.004
Epoch 94 completed.
train loss: 2.856013077585726
train acc: 0.35085625560789585
train rank: 11.117215539479586
train weight_norm: 169.52450086052002
train grad_norm: 14.081741031430592
train lr: 1.0406585473379184e-05
val loss: 8.581267809867859
val acc: 0.0025390625
val rank: 127.436328125
test mean_rank: 55.827
test final_rank: 59.0
test traces_to_disclosure: 37.0

Epoch 71 completed.
train loss: 3.200135298725092
train acc: 0.2856819902422611
train rank: 14.572963983288469
train weight_norm: 167.55365447755463
train grad_norm: 14.077057297827436
train lr: 0.00019979378004867344
val loss: 5.587688863277435
val acc: 0.00625
val rank: 126.24453125
test mean_rank: 191.606
test final_rank: 91.0
test traces_to_disclosure: nan

Epoch 60 completed.
train loss: 3.582983748588716
train acc: 0.22294190219829518
train rank: 19.40677924517721
train weight_norm: 162.92843168789608
train grad_norm: 10.634094611009473
train lr: 0.00035297578036961284
val loss: 7.541385245323181
val acc: 0.00400390625
val rank: 127.4494140625
test mean_rank: 216.434
test final_rank: 251.0
test traces_to_disclosure: 10.0

Before temperature - NLL: 7.317, ECE: 0.154
Optimal temperature: 7.589
After temperature - NLL: 5.578, ECE: 0.004
Epoch 61 completed.
train loss: 3.5449597196976876
train acc: 0.2304617401301032
train rank: 18.986644445379092
train weight_norm: 163.67797628233916
train grad_norm: 11.074098416239904
train lr: 0.0003380379508163031
val loss: 7.611098980903625
val acc: 0.00361328125
val rank: 126.92412109375
test mean_rank: 154.877
test final_rank: 184.0
test traces_to_disclosure: nan

Epoch 55 completed.
train loss: 3.761479533697362
train acc: 0.19568227063705695
train rank: 22.262463548676532
train weight_norm: 160.77966957990012
train grad_norm: 9.942723656404054
train lr: 0.0004295418164232739
val loss: 5.578672313690186
val acc: 0.0033203125
val rank: 127.9265625
test mean_rank: 67.511
test final_rank: 111.0
test traces_to_disclosure: nan

Epoch 61 completed.
train loss: 3.555218900036202
train acc: 0.22865494616419918
train rank: 19.019960604531178
train weight_norm: 163.6372992881321
train grad_norm: 10.825758154247616
train lr: 0.0003380379508163031
val loss: 7.641894328594208
val acc: 0.00390625
val rank: 129.54365234375
test mean_rank: 245.965
test final_rank: 250.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.376, ECE: 0.158
Optimal temperature: 7.669
After temperature - NLL: 5.579, ECE: 0.003
Epoch 84 completed.
train loss: 2.966829735048687
train acc: 0.3303068220053836
train rank: 12.154117247083892
train weight_norm: 169.53982814918947
train grad_norm: 13.98584182980587
train lr: 6.569686604762924e-05
val loss: 8.466156601905823
val acc: 0.0037109375
val rank: 127.83857421875
test mean_rank: 74.094
test final_rank: 139.0
test traces_to_disclosure: nan

Epoch 95 completed.
train loss: 2.849313145530978
train acc: 0.35312745345446384
train rank: 11.077818318192016
train weight_norm: 169.53802472395125
train grad_norm: 14.029031794070756
train lr: 7.463774919740511e-06
val loss: 8.580922985076905
val acc: 0.00263671875
val rank: 127.54111328125
test mean_rank: 103.594
test final_rank: 127.0
test traces_to_disclosure: nan

Epoch 56 completed.
train loss: 3.7180950991398234
train acc: 0.20118501850605652
train rank: 21.479124607447286
train weight_norm: 161.56358364057766
train grad_norm: 10.212771136834672
train lr: 0.0004140285721772396
val loss: 5.57712299823761
val acc: 0.0041015625
val rank: 127.33193359375
test mean_rank: 197.295
test final_rank: 246.0
test traces_to_disclosure: nan

Before temperature - NLL: 8.140, ECE: 0.231
Optimal temperature: 7.658
After temperature - NLL: 5.589, ECE: 0.004
Before temperature - NLL: 8.105, ECE: 0.225
Optimal temperature: 7.671
After temperature - NLL: 5.594, ECE: 0.005
Epoch 82 completed.
train loss: 3.0079128434167095
train acc: 0.3207874186855092
train rank: 12.507852806751908
train weight_norm: 169.38883592448778
train grad_norm: 13.475439379307243
train lr: 8.210770148509823e-05
val loss: 8.431840443611145
val acc: 0.00361328125
val rank: 127.99345703125
test mean_rank: 180.303
test final_rank: 155.0
test traces_to_disclosure: 3.0

Epoch 72 completed.
train loss: 3.180891200318471
train acc: 0.2885455220951099
train rank: 14.358416400291611
train weight_norm: 167.7863795223927
train grad_norm: 14.090109865483992
train lr: 0.0001873832784513824
val loss: 5.588318312168122
val acc: 0.00400390625
val rank: 126.23994140625
test mean_rank: 169.618
test final_rank: 219.0
test traces_to_disclosure: nan

Epoch 71 completed.
train loss: 3.2299882053205815
train acc: 0.2810659909152086
train rank: 14.935295395917453
train weight_norm: 167.39293697064858
train grad_norm: 13.92585538975578
train lr: 0.00019979378004867344
val loss: 5.596000552177429
val acc: 0.00341796875
val rank: 128.06484375
test mean_rank: 146.85
test final_rank: 185.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.299, ECE: 0.148
Optimal temperature: 7.695
After temperature - NLL: 5.581, ECE: 0.004
Epoch 54 completed.
train loss: 3.808277967319514
train acc: 0.18696549742036786
train rank: 22.957765533871687
train weight_norm: 160.4949160670654
train grad_norm: 9.928938002186616
train lr: 0.00044512459438997856
val loss: 5.579076838493347
val acc: 0.00341796875
val rank: 129.01865234375
test mean_rank: 193.272
test final_rank: 243.0
test traces_to_disclosure: nan

Epoch 61 completed.
train loss: 3.5493866864636963
train acc: 0.22881266823687751
train rank: 18.95549258355765
train weight_norm: 163.34259912480914
train grad_norm: 10.696346063063785
train lr: 0.0003380379508163031
val loss: 7.6091009974479675
val acc: 0.0029296875
val rank: 127.3955078125
test mean_rank: 119.895
test final_rank: 146.0
test traces_to_disclosure: nan

Epoch 96 completed.
train loss: 2.8516281555992116
train acc: 0.35206896310004493
train rank: 11.084470684724092
train weight_norm: 169.54730112771185
train grad_norm: 13.875462640406418
train lr: 5.007038155636968e-06
val loss: 8.578044557571411
val acc: 0.002734375
val rank: 127.348046875
test mean_rank: 73.656
test final_rank: 83.0
test traces_to_disclosure: nan

Epoch 85 completed.
train loss: 2.9539745001581124
train acc: 0.330706384589502
train rank: 12.039257023889636
train weight_norm: 169.62427250564636
train grad_norm: 13.921422558580774
train lr: 5.813041038794308e-05
val loss: 8.465429711341859
val acc: 0.00341796875
val rank: 127.86962890625
test mean_rank: 57.238
test final_rank: 50.0
test traces_to_disclosure: nan

Epoch 62 completed.
train loss: 3.5124671301963675
train acc: 0.2347412657021086
train rank: 18.476765786227006
train weight_norm: 164.07720995215945
train grad_norm: 11.128539665552085
train lr: 0.0003232599582516232
val loss: 7.633728885650635
val acc: 0.00390625
val rank: 127.0603515625
test mean_rank: 142.895
test final_rank: 181.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.366, ECE: 0.159
Optimal temperature: 7.589
After temperature - NLL: 5.579, ECE: 0.004
Epoch 83 completed.
train loss: 2.9944100110399288
train acc: 0.3226941032974428
train rank: 12.409469282750111
train weight_norm: 169.491401232533
train grad_norm: 13.598412675194322
train lr: 7.369192646647374e-05
val loss: 8.451614260673523
val acc: 0.00283203125
val rank: 128.00830078125
test mean_rank: 155.948
test final_rank: 59.0
test traces_to_disclosure: nan

Epoch 62 completed.
train loss: 3.522223742460659
train acc: 0.23384049742036786
train rank: 18.59853598867205
train weight_norm: 164.03731248438186
train grad_norm: 10.905276648868737
train lr: 0.0003232599582516232
val loss: 7.699320065975189
val acc: 0.00390625
val rank: 130.03505859375
test mean_rank: 95.615
test final_rank: 142.0
test traces_to_disclosure: nan

Before temperature - NLL: 8.145, ECE: 0.229
Optimal temperature: 7.674
After temperature - NLL: 5.595, ECE: 0.005
Before temperature - NLL: 8.171, ECE: 0.233
Optimal temperature: 7.661
After temperature - NLL: 5.589, ECE: 0.004
Epoch 56 completed.
train loss: 3.7230227802194467
train acc: 0.20136727512337374
train rank: 21.6833221175415
train weight_norm: 161.3047776710845
train grad_norm: 10.037050829990696
train lr: 0.0004140285721772396
val loss: 5.5791511058807375
val acc: 0.00361328125
val rank: 127.78876953125
test mean_rank: 40.27
test final_rank: 32.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.440, ECE: 0.164
Optimal temperature: 7.670
After temperature - NLL: 5.581, ECE: 0.004
Epoch 72 completed.
train loss: 3.2062570201596534
train acc: 0.28511944818304175
train rank: 14.636348979362944
train weight_norm: 167.6294633043499
train grad_norm: 14.365605762055969
train lr: 0.0001873832784513824
val loss: 5.596623492240906
val acc: 0.00302734375
val rank: 128.1484375
test mean_rank: 202.012
test final_rank: 191.0
test traces_to_disclosure: nan

Epoch 73 completed.
train loss: 3.1552237402221555
train acc: 0.2937959146478241
train rank: 14.073114695491252
train weight_norm: 168.00554948358365
train grad_norm: 14.117780876400717
train lr: 0.00017528129181558567
val loss: 5.588406682014465
val acc: 0.00576171875
val rank: 126.13359375
test mean_rank: 48.481
test final_rank: 81.0
test traces_to_disclosure: 2.0

Epoch 57 completed.
train loss: 3.6809729711524892
train acc: 0.20620583781965007
train rank: 20.916740270300583
train weight_norm: 162.07592535664375
train grad_norm: 10.530728010685785
train lr: 0.00039860017135100997
val loss: 5.578268229961395
val acc: 0.003125
val rank: 127.2328125
test mean_rank: 123.748
test final_rank: 109.0
test traces_to_disclosure: nan

Epoch 86 completed.
train loss: 2.9441533813887295
train acc: 0.33480891094661286
train rank: 11.937843483624942
train weight_norm: 169.69940812609315
train grad_norm: 13.870563619358558
train lr: 5.100002666564194e-05
val loss: 8.480593585968018
val acc: 0.00361328125
val rank: 127.865234375
test mean_rank: 208.642
test final_rank: 174.0
test traces_to_disclosure: nan

Epoch 97 completed.
train loss: 2.84319232931689
train acc: 0.3536654609690444
train rank: 11.021140015141318
train weight_norm: 169.55336509973384
train grad_norm: 13.879440933191814
train lr: 3.038799683649294e-06
val loss: 8.59556050300598
val acc: 0.00234375
val rank: 127.50751953125
test mean_rank: 175.087
test final_rank: 207.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.338, ECE: 0.154
Optimal temperature: 7.696
After temperature - NLL: 5.580, ECE: 0.004
Epoch 62 completed.
train loss: 3.517439008240424
train acc: 0.23284684836249436
train rank: 18.528328636720502
train weight_norm: 163.73499420698076
train grad_norm: 10.994968121702463
train lr: 0.0003232599582516232
val loss: 7.657845222949982
val acc: 0.00361328125
val rank: 127.98193359375
test mean_rank: 51.866
test final_rank: 89.0
test traces_to_disclosure: nan

Epoch 55 completed.
train loss: 3.7664737496048732
train acc: 0.1946378000224316
train rank: 22.311622013795425
train weight_norm: 161.05814845455546
train grad_norm: 9.995927876686489
train lr: 0.0004295418164232739
val loss: 5.578977584838867
val acc: 0.00361328125
val rank: 128.5611328125
test mean_rank: 112.182
test final_rank: 61.0
test traces_to_disclosure: nan

Epoch 84 completed.
train loss: 2.9763879792045294
train acc: 0.3269315696500673
train rank: 12.245641613391655
train weight_norm: 169.58356778585275
train grad_norm: 13.534598128457542
train lr: 6.569686604762924e-05
val loss: 8.466758322715759
val acc: 0.00380859375
val rank: 128.0873046875
test mean_rank: 69.318
test final_rank: 105.0
test traces_to_disclosure: nan

Before temperature - NLL: 8.172, ECE: 0.231
Optimal temperature: 7.681
After temperature - NLL: 5.595, ECE: 0.005
Epoch 63 completed.
train loss: 3.4798302698584616
train acc: 0.2405279133019291
train rank: 18.068701982391207
train weight_norm: 164.4535423287158
train grad_norm: 11.207420487705177
train lr: 0.000308656386770065
val loss: 7.669918978214264
val acc: 0.00380859375
val rank: 126.74228515625
test mean_rank: 168.364
test final_rank: 222.0
test traces_to_disclosure: nan

Epoch 63 completed.
train loss: 3.4907989887016777
train acc: 0.23847577388963662
train rank: 18.08983849259758
train weight_norm: 164.4132441001691
train grad_norm: 11.069033898912613
train lr: 0.000308656386770065
val loss: 7.7359242796897885
val acc: 0.00390625
val rank: 129.67314453125
test mean_rank: 66.301
test final_rank: 75.0
test traces_to_disclosure: nan

Epoch 73 completed.
train loss: 3.182349856737324
train acc: 0.2896951407581875
train rank: 14.403963029946164
train weight_norm: 167.8478003968523
train grad_norm: 14.228401862377885
train lr: 0.00017528129181558567
val loss: 5.597023630142212
val acc: 0.00400390625
val rank: 128.01259765625
test mean_rank: 77.641
test final_rank: 74.0
test traces_to_disclosure: nan

Before temperature - NLL: 8.214, ECE: 0.239
Optimal temperature: 7.665
After temperature - NLL: 5.590, ECE: 0.004
Before temperature - NLL: 7.416, ECE: 0.162
Optimal temperature: 7.591
After temperature - NLL: 5.580, ECE: 0.003
Epoch 98 completed.
train loss: 2.842533620498062
train acc: 0.3535936098026021
train rank: 11.011511958838044
train weight_norm: 169.55680504630914
train grad_norm: 13.960611969583137
train lr: 1.5610019175210288e-06
val loss: 8.594456839561463
val acc: 0.0025390625
val rank: 127.55849609375
test mean_rank: 136.221
test final_rank: 185.0
test traces_to_disclosure: nan

Epoch 74 completed.
train loss: 3.1312085696537433
train acc: 0.2973919779048901
train rank: 13.813994854755494
train weight_norm: 168.21119799171043
train grad_norm: 14.089111830812259
train lr: 0.00016349976334100182
val loss: 5.589279413223267
val acc: 0.00419921875
val rank: 126.23232421875
test mean_rank: 170.016
test final_rank: 94.0
test traces_to_disclosure: nan

Epoch 57 completed.
train loss: 3.687051965603116
train acc: 0.20592894795872585
train rank: 21.06328861036339
train weight_norm: 161.80253239744874
train grad_norm: 10.195817714436862
train lr: 0.00039860017135100997
val loss: 5.580109763145447
val acc: 0.0046875
val rank: 127.8818359375
test mean_rank: 225.235
test final_rank: 220.0
test traces_to_disclosure: nan

Epoch 87 completed.
train loss: 2.9277815398425466
train acc: 0.33810354979811574
train rank: 11.778521408142664
train weight_norm: 169.7647372211091
train grad_norm: 14.03253787291548
train lr: 4.431275170859809e-05
val loss: 8.501628589630126
val acc: 0.00322265625
val rank: 127.816015625
test mean_rank: 103.02
test final_rank: 94.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.480, ECE: 0.170
Optimal temperature: 7.671
After temperature - NLL: 5.581, ECE: 0.005
Epoch 58 completed.
train loss: 3.6444996369157794
train acc: 0.21352764692687307
train rank: 20.372592109690444
train weight_norm: 162.56617909423903
train grad_norm: 10.599297720886023
train lr: 0.0003832718399135072
val loss: 5.579192733764648
val acc: 0.0033203125
val rank: 127.33388671875
test mean_rank: 194.279
test final_rank: 193.0
test traces_to_disclosure: nan

Epoch 85 completed.
train loss: 2.9636426841586947
train acc: 0.33008951603858233
train rank: 12.108593399506503
train weight_norm: 169.66634469435468
train grad_norm: 13.482052924291564
train lr: 5.813041038794308e-05
val loss: 8.473536896705628
val acc: 0.00380859375
val rank: 128.00712890625
test mean_rank: 38.055
test final_rank: 47.0
test traces_to_disclosure: nan

Epoch 99 completed.
train loss: 2.840119788977211
train acc: 0.35448211081202335
train rank: 10.989900529946164
train weight_norm: 169.55838108002743
train grad_norm: 13.886337621452848
train lr: 5.751032652306508e-07
val loss: 8.59136505126953
val acc: 0.0025390625
val rank: 127.51513671875
test mean_rank: 27.866
test final_rank: 24.0
test traces_to_disclosure: 254.0

Before temperature - NLL: 8.209, ECE: 0.234
Optimal temperature: 7.687
After temperature - NLL: 5.596, ECE: 0.005
Before temperature - NLL: 7.395, ECE: 0.159
Optimal temperature: 7.696
After temperature - NLL: 5.582, ECE: 0.004
Epoch 64 completed.
train loss: 3.4505786529941482
train acc: 0.24528060509196947
train rank: 17.659982755720055
train weight_norm: 164.8142145037416
train grad_norm: 11.338774147865024
train lr: 0.0002942416483335689
val loss: 7.72429769039154
val acc: 0.00380859375
val rank: 126.9853515625
test mean_rank: 220.141
test final_rank: 216.0
test traces_to_disclosure: nan

Epoch 63 completed.
train loss: 3.4860427145361097
train acc: 0.2382462006505159
train rank: 18.091317575145805
train weight_norm: 164.10593006288013
train grad_norm: 11.082138468207877
train lr: 0.000308656386770065
val loss: 7.68968414068222
val acc: 0.00322265625
val rank: 128.03671875
test mean_rank: 62.144
test final_rank: 95.0
test traces_to_disclosure: nan

Epoch 64 completed.
train loss: 3.457042158853318
train acc: 0.24435880720053835
train rank: 17.680421783871694
train weight_norm: 164.77189305808218
train grad_norm: 11.117591402624242
train lr: 0.0002942416483335689
val loss: 7.779957389831543
val acc: 0.00439453125
val rank: 129.7306640625
test mean_rank: 50.457
test final_rank: 23.0
test traces_to_disclosure: 182.0

Before temperature - NLL: 8.241, ECE: 0.241
Optimal temperature: 7.670
After temperature - NLL: 5.590, ECE: 0.004
Epoch 74 completed.
train loss: 3.1604762549034517
train acc: 0.2932403824585016
train rank: 14.140430476110364
train weight_norm: 168.05642535979965
train grad_norm: 14.415094699801296
train lr: 0.00016349976334100182
val loss: 5.597445905208588
val acc: 0.00380859375
val rank: 128.0111328125
test mean_rank: 66.358
test final_rank: 127.0
test traces_to_disclosure: nan

Epoch 56 completed.
train loss: 3.730360384102946
train acc: 0.19904700818752802
train rank: 21.713893912628983
train weight_norm: 161.59548833355376
train grad_norm: 10.167270336889196
train lr: 0.0004140285721772396
val loss: 5.579955494403839
val acc: 0.00322265625
val rank: 128.39775390625
test mean_rank: 149.159
test final_rank: 144.0
test traces_to_disclosure: nan

Epoch 75 completed.
train loss: 3.1065580918683016
train acc: 0.30245485643786446
train rank: 13.557296924069087
train weight_norm: 168.40425151236425
train grad_norm: 14.101306381852075
train lr: 0.00015205031997383474
val loss: 5.589648973941803
val acc: 0.0056640625
val rank: 126.18828125
test mean_rank: 197.218
test final_rank: 203.0
test traces_to_disclosure: nan

Epoch 88 completed.
train loss: 2.9167769269699364
train acc: 0.33988055181695825
train rank: 11.692566383467925
train weight_norm: 169.82297310903988
train grad_norm: 13.828252532582047
train lr: 3.807518504982966e-05
val loss: 8.505194687843323
val acc: 0.0033203125
val rank: 127.769140625
test mean_rank: 176.216
test final_rank: 64.0
test traces_to_disclosure: nan

Epoch 86 completed.
train loss: 2.954097855941444
train acc: 0.330792255495738
train rank: 12.002229138627188
train weight_norm: 169.74152101316645
train grad_norm: 13.477535529627263
train lr: 5.100002666564194e-05
val loss: 8.489833092689514
val acc: 0.00361328125
val rank: 127.9623046875
test mean_rank: 107.266
test final_rank: 108.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.459, ECE: 0.168
Optimal temperature: 7.592
After temperature - NLL: 5.580, ECE: 0.004
Before temperature - NLL: 7.539, ECE: 0.173
Optimal temperature: 7.671
After temperature - NLL: 5.584, ECE: 0.004
Epoch 100 completed.
train loss: 2.8389861333418343
train acc: 0.3549535245625841
train rank: 10.967672232503364
train weight_norm: 169.5587830856928
train grad_norm: 13.879298179358061
train lr: 8.207668971898738e-08
val loss: 8.59259843826294
val acc: 0.00205078125
val rank: 127.50126953125
test mean_rank: 87.072
test final_rank: 38.0
test traces_to_disclosure: nan

Done training. Computing performance of best model.
Epoch 58 completed.
train loss: 3.6488187130174596
train acc: 0.21187857503364738
train rank: 20.488966464782415
train weight_norm: 162.28346447230464
train grad_norm: 10.397956652494685
train lr: 0.0003832718399135072
val loss: 5.580822396278381
val acc: 0.00400390625
val rank: 127.5408203125
test mean_rank: 127.838
test final_rank: 77.0
test traces_to_disclosure: nan

Epoch 59 completed.
train loss: 3.6095280955328755
train acc: 0.21818745794078062
train rank: 19.83191909208165
train weight_norm: 163.0229192847364
train grad_norm: 10.800370377782908
train lr: 0.00036805870507724853
val loss: 5.581046020984649
val acc: 0.00390625
val rank: 127.77236328125
test mean_rank: 143.763
test final_rank: 208.0
test traces_to_disclosure: nan

Before temperature - NLL: 8.273, ECE: 0.244
Optimal temperature: 7.676
After temperature - NLL: 5.591, ECE: 0.004
train loss: 5.5407237871819515
train acc: 0.0051960660610139075
train rank: 120.52949227512336
val loss: 5.546994733810425
val acc: 0.00400390625
val rank: 126.41640625
test loss: 5.5482153319336875
test acc: 0.004185981457800511
test rank: 127.793258471867
Before temperature - NLL: 8.231, ECE: 0.237
Optimal temperature: 7.694
After temperature - NLL: 5.595, ECE: 0.005
Epoch 89 completed.
train loss: 2.908707719792588
train acc: 0.34268449977568416
train rank: 11.624586417676086
train weight_norm: 169.8723958180778
train grad_norm: 13.894884177249786
train lr: 3.2293482414558174e-05
val loss: 8.525428748130798
val acc: 0.0037109375
val rank: 127.86376953125
test mean_rank: 87.24
test final_rank: 161.0
test traces_to_disclosure: nan

Epoch 65 completed.
train loss: 3.4157869273528436
train acc: 0.25037853297442797
train rank: 17.184499775684163
train weight_norm: 165.15918395022078
train grad_norm: 11.348336160851357
train lr: 0.00028002996854866136
val loss: 7.760681366920471
val acc: 0.0037109375
val rank: 127.02255859375
test mean_rank: 211.023
test final_rank: 249.0
test traces_to_disclosure: nan

Epoch 65 completed.
train loss: 3.4248760365862223
train acc: 0.2494917844324809
train rank: 17.256513921601616
train weight_norm: 165.12026335764406
train grad_norm: 11.144368199485314
train lr: 0.00028002996854866136
val loss: 7.822830390930176
val acc: 0.0041015625
val rank: 129.568359375
test mean_rank: 117.58
test final_rank: 70.0
test traces_to_disclosure: nan

Epoch 76 completed.
train loss: 3.085575911751666
train acc: 0.30551641711529837
train rank: 13.36459384813818
train weight_norm: 168.58461523885757
train grad_norm: 14.21550614496837
train lr: 0.00014094426093237933
val loss: 5.590045607089996
val acc: 0.00576171875
val rank: 126.17861328125
test mean_rank: 62.263
test final_rank: 42.0
test traces_to_disclosure: nan

Epoch 75 completed.
train loss: 3.1362073559459414
train acc: 0.29741475998205474
train rank: 13.881436813032748
train weight_norm: 168.25036432428104
train grad_norm: 14.463492854452731
train lr: 0.00015205031997383474
val loss: 5.597301328182221
val acc: 0.0037109375
val rank: 127.8306640625
test mean_rank: 73.789
test final_rank: 50.0
test traces_to_disclosure: nan

Epoch 64 completed.
train loss: 3.4513112099623133
train acc: 0.2437945126738448
train rank: 17.613859564266487
train weight_norm: 164.46133873024783
train grad_norm: 11.017148381520988
train lr: 0.0002942416483335689
val loss: 7.7459731817245485
val acc: 0.00322265625
val rank: 127.7826171875
test mean_rank: 181.177
test final_rank: 191.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.440, ECE: 0.162
Optimal temperature: 7.697
After temperature - NLL: 5.583, ECE: 0.004
Epoch 87 completed.
train loss: 2.9370324107872205
train acc: 0.334766851727232
train rank: 11.865792535890536
train weight_norm: 169.8069718454116
train grad_norm: 13.400647468126344
train lr: 4.431275170859809e-05
val loss: 8.514172887802124
val acc: 0.0037109375
val rank: 128.083984375
test mean_rank: 42.241
test final_rank: 128.0
test traces_to_disclosure: nan

Epoch 57 completed.
train loss: 3.6913026505492095
train acc: 0.20645293573351278
train rank: 21.114411591520863
train weight_norm: 162.10670398461878
train grad_norm: 10.342590129814054
train lr: 0.00039860017135100997
val loss: 5.580848443508148
val acc: 0.00400390625
val rank: 128.5734375
test mean_rank: 86.669
test final_rank: 65.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.504, ECE: 0.171
Optimal temperature: 7.593
After temperature - NLL: 5.581, ECE: 0.003
Before temperature - NLL: 7.581, ECE: 0.179
Optimal temperature: 7.671
After temperature - NLL: 5.584, ECE: 0.005
Before temperature - NLL: 8.267, ECE: 0.240
Optimal temperature: 7.700
After temperature - NLL: 5.596, ECE: 0.005
Epoch 59 completed.
train loss: 3.6122886325918326
train acc: 0.21800695379093765
train rank: 19.908522950314044
train weight_norm: 162.7343062695542
train grad_norm: 10.485024626540916
train lr: 0.00036805870507724853
val loss: 5.580949068069458
val acc: 0.00400390625
val rank: 127.5568359375
test mean_rank: 146.939
test final_rank: 166.0
test traces_to_disclosure: nan

Before temperature - NLL: 8.297, ECE: 0.245
Optimal temperature: 7.683
After temperature - NLL: 5.591, ECE: 0.004
Epoch 90 completed.
train loss: 2.897986573454188
train acc: 0.3433591997532526
train rank: 11.511436602736651
train weight_norm: 169.91451946561224
train grad_norm: 13.86807287915998
train lr: 2.6973349645251412e-05
val loss: 8.534077024459839
val acc: 0.0037109375
val rank: 127.91162109375
test mean_rank: 45.636
test final_rank: 39.0
test traces_to_disclosure: nan

Epoch 60 completed.
train loss: 3.575289166310594
train acc: 0.22291386271870794
train rank: 19.308437780394797
train weight_norm: 163.46150137709046
train grad_norm: 10.870844835125439
train lr: 0.00035297578036961284
val loss: 5.580356371402741
val acc: 0.0041015625
val rank: 127.31005859375
test mean_rank: 192.399
test final_rank: 175.0
test traces_to_disclosure: nan

Epoch 66 completed.
train loss: 3.3884291857440894
train acc: 0.2556517076043069
train rank: 16.846893926648722
train weight_norm: 165.486057134529
train grad_norm: 11.543456229647491
train lr: 0.00026603537262749225
val loss: 7.798280251026154
val acc: 0.0033203125
val rank: 126.82744140625
test mean_rank: 67.558
test final_rank: 52.0
test traces_to_disclosure: nan

Epoch 66 completed.
train loss: 3.395150128155345
train acc: 0.2533612326155226
train rank: 16.8495857166891
train weight_norm: 165.44517770226804
train grad_norm: 11.369246867970949
train lr: 0.00026603537262749225
val loss: 7.854642701148987
val acc: 0.00302734375
val rank: 129.46240234375
test mean_rank: 96.593
test final_rank: 43.0
test traces_to_disclosure: nan

Epoch 76 completed.
train loss: 3.111597163199095
train acc: 0.30224280787348584
train rank: 13.63107930966801
train weight_norm: 168.43396099938016
train grad_norm: 14.306713049310826
train lr: 0.00014094426093237933
val loss: 5.598549067974091
val acc: 0.00341796875
val rank: 127.96044921875
test mean_rank: 202.936
test final_rank: 199.0
test traces_to_disclosure: nan

Epoch 77 completed.
train loss: 3.067559430929726
train acc: 0.3093735980260206
train rank: 13.164060747532528
train weight_norm: 168.75421230135538
train grad_norm: 14.30892825096069
train lr: 0.00013019254655605928
val loss: 5.590320038795471
val acc: 0.00546875
val rank: 126.1935546875
test mean_rank: 123.677
test final_rank: 18.0
test traces_to_disclosure: nan

Epoch 88 completed.
train loss: 2.9237870762518243
train acc: 0.3375480176087932
train rank: 11.742602834791386
train weight_norm: 169.86430860053795
train grad_norm: 13.469656439573837
train lr: 3.807518504982966e-05
val loss: 8.514212584495544
val acc: 0.00380859375
val rank: 127.94462890625
test mean_rank: 96.354
test final_rank: 6.0
test traces_to_disclosure: nan

Epoch 65 completed.
train loss: 3.4203932095985876
train acc: 0.24955487326155223
train rank: 17.24684380607896
train weight_norm: 164.81237911851707
train grad_norm: 11.275049692352658
train lr: 0.00028002996854866136
val loss: 7.786039972305298
val acc: 0.00322265625
val rank: 127.81904296875
test mean_rank: 240.426
test final_rank: 245.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.484, ECE: 0.168
Optimal temperature: 7.697
After temperature - NLL: 5.582, ECE: 0.005
Epoch 58 completed.
train loss: 3.6540001208817494
train acc: 0.20998766262898158
train rank: 20.48999516318977
train weight_norm: 162.59427497858786
train grad_norm: 10.532755712867383
train lr: 0.0003832718399135072
val loss: 5.580703568458557
val acc: 0.00341796875
val rank: 128.123046875
test mean_rank: 65.205
test final_rank: 30.0
test traces_to_disclosure: nan

Before temperature - NLL: 8.292, ECE: 0.242
Optimal temperature: 7.707
After temperature - NLL: 5.596, ECE: 0.005
Epoch 67 completed.
train loss: 3.360935218241141
train acc: 0.26016781628532976
train rank: 16.536763262673848
train weight_norm: 165.79008360642638
train grad_norm: 11.646974952080244
train lr: 0.0002522716715466487
val loss: 7.839888072013855
val acc: 0.00361328125
val rank: 126.6884765625
test mean_rank: 46.747
test final_rank: 33.0
test traces_to_disclosure: nan

Epoch 91 completed.
train loss: 2.884417466167486
train acc: 0.3464207604306864
train rank: 11.37842607391207
train weight_norm: 169.9497451746045
train grad_norm: 13.71501139794975
train lr: 2.2120037070645153e-05
val loss: 8.528674125671387
val acc: 0.0033203125
val rank: 127.80634765625
test mean_rank: 100.02
test final_rank: 74.0
test traces_to_disclosure: nan

Epoch 77 completed.
train loss: 3.093616512871045
train acc: 0.3058266038582324
train rank: 13.448153249775682
train weight_norm: 168.60478378360287
train grad_norm: 14.395596384660923
train lr: 0.00013019254655605928
val loss: 5.598890650272369
val acc: 0.0037109375
val rank: 127.919140625
test mean_rank: 139.908
test final_rank: 162.0
test traces_to_disclosure: nan

Epoch 67 completed.
train loss: 3.3690834215479937
train acc: 0.25847668517272315
train rank: 16.55410743326604
train weight_norm: 165.75473289120933
train grad_norm: 11.390942412543524
train lr: 0.0002522716715466487
val loss: 7.908786022663117
val acc: 0.004296875
val rank: 129.5568359375
test mean_rank: 100.605
test final_rank: 149.0
test traces_to_disclosure: nan

Epoch 89 completed.
train loss: 2.9180016931582586
train acc: 0.338716913414087
train rank: 11.687571851166444
train weight_norm: 169.91423164699222
train grad_norm: 13.518930307366293
train lr: 3.2293482414558174e-05
val loss: 8.53214054107666
val acc: 0.00361328125
val rank: 128.051171875
test mean_rank: 136.336
test final_rank: 204.0
test traces_to_disclosure: nan

Before temperature - NLL: 8.326, ECE: 0.249
Optimal temperature: 7.689
After temperature - NLL: 5.592, ECE: 0.004
Before temperature - NLL: 7.558, ECE: 0.174
Optimal temperature: 7.594
After temperature - NLL: 5.583, ECE: 0.004
Before temperature - NLL: 7.622, ECE: 0.183
Optimal temperature: 7.671
After temperature - NLL: 5.584, ECE: 0.005
Epoch 78 completed.
train loss: 3.047501948126874
train acc: 0.31334819425751453
train rank: 12.953864541274116
train weight_norm: 168.91023413256332
train grad_norm: 14.30718740928705
train lr: 0.000119805787488893
val loss: 5.5907337188720705
val acc: 0.0052734375
val rank: 126.119921875
test mean_rank: 15.357
test final_rank: 1.0
test traces_to_disclosure: 38.0

Epoch 60 completed.
train loss: 3.5844486051741713
train acc: 0.22084945603409598
train rank: 19.502791680686407
train weight_norm: 163.16372002242073
train grad_norm: 10.663619834025013
train lr: 0.00035297578036961284
val loss: 5.583361887931824
val acc: 0.00400390625
val rank: 128.042578125
test mean_rank: 132.069
test final_rank: 169.0
test traces_to_disclosure: nan

Epoch 61 completed.
train loss: 3.5421738184958413
train acc: 0.2288319453790938
train rank: 18.842642440556304
train weight_norm: 163.87511386847422
train grad_norm: 11.058878002484509
train lr: 0.0003380379508163031
val loss: 5.580855441093445
val acc: 0.003125
val rank: 127.095703125
test mean_rank: 76.381
test final_rank: 100.0
test traces_to_disclosure: nan

Epoch 92 completed.
train loss: 2.8758230822243567
train acc: 0.3485324837371018
train rank: 11.319665839502019
train weight_norm: 169.9795230105741
train grad_norm: 13.68131779506874
train lr: 1.773833432430308e-05
val loss: 8.55347957611084
val acc: 0.0033203125
val rank: 127.8265625
test mean_rank: 86.402
test final_rank: 136.0
test traces_to_disclosure: nan

Epoch 66 completed.
train loss: 3.3904262295000325
train acc: 0.2532333024899058
train rank: 16.81964831482728
train weight_norm: 165.13887042988605
train grad_norm: 11.39136010668936
train lr: 0.00026603537262749225
val loss: 7.81607745885849
val acc: 0.002734375
val rank: 127.41748046875
test mean_rank: 40.349
test final_rank: 11.0
test traces_to_disclosure: nan

Epoch 68 completed.
train loss: 3.333645720822012
train acc: 0.2646173312023329
train rank: 16.16675604250785
train weight_norm: 166.08048298767164
train grad_norm: 11.770752901061739
train lr: 0.00023875244841738502
val loss: 7.88335599899292
val acc: 0.00322265625
val rank: 126.512890625
test mean_rank: 123.148
test final_rank: 104.0
test traces_to_disclosure: nan

Before temperature - NLL: 8.327, ECE: 0.245
Optimal temperature: 7.714
After temperature - NLL: 5.598, ECE: 0.006
Before temperature - NLL: 7.537, ECE: 0.172
Optimal temperature: 7.698
After temperature - NLL: 5.585, ECE: 0.004
Epoch 68 completed.
train loss: 3.3398594371723775
train acc: 0.26326442631224767
train rank: 16.189492555518168
train weight_norm: 166.04896578115844
train grad_norm: 11.506230203256598
train lr: 0.00023875244841738502
val loss: 7.95534895658493
val acc: 0.0033203125
val rank: 129.7513671875
test mean_rank: 150.447
test final_rank: 144.0
test traces_to_disclosure: nan

Epoch 90 completed.
train loss: 2.9100359817854007
train acc: 0.33977014636608344
train rank: 11.581270679116194
train weight_norm: 169.95603075880214
train grad_norm: 13.440625420076616
train lr: 2.6973349645251412e-05
val loss: 8.541804528236389
val acc: 0.00361328125
val rank: 128.099609375
test mean_rank: 128.018
test final_rank: 72.0
test traces_to_disclosure: 66.0

Epoch 78 completed.
train loss: 3.073510301867212
train acc: 0.3092631925751458
train rank: 13.241730105989232
train weight_norm: 168.76239115246128
train grad_norm: 14.422468315108327
train lr: 0.000119805787488893
val loss: 5.599954319000244
val acc: 0.00361328125
val rank: 128.07509765625
test mean_rank: 93.508
test final_rank: 194.0
test traces_to_disclosure: nan

Epoch 59 completed.
train loss: 3.620358982445574
train acc: 0.2166400291610588
train rank: 20.06542311574697
train weight_norm: 163.05484459523834
train grad_norm: 10.606622300558767
train lr: 0.00036805870507724853
val loss: 5.583023190498352
val acc: 0.00400390625
val rank: 128.58876953125
test mean_rank: 59.063
test final_rank: 156.0
test traces_to_disclosure: 184.0

Before temperature - NLL: 8.352, ECE: 0.250
Optimal temperature: 7.696
After temperature - NLL: 5.593, ECE: 0.005
Epoch 67 completed.
train loss: 3.365596495277949
train acc: 0.2577651833781965
train rank: 16.53114485195155
train weight_norm: 165.45138739361673
train grad_norm: 11.516555012577427
train lr: 0.0002522716715466487
val loss: 7.871968829631806
val acc: 0.0025390625
val rank: 128.1876953125
test mean_rank: 203.133
test final_rank: 225.0
test traces_to_disclosure: nan

Epoch 79 completed.
train loss: 3.029023611689962
train acc: 0.31648511103633914
train rank: 12.767256547218482
train weight_norm: 169.0546312976865
train grad_norm: 14.387765269989128
train lr: 0.00010979423420807191
val loss: 5.591560292243957
val acc: 0.00556640625
val rank: 126.24755859375
test mean_rank: 208.149
test final_rank: 168.0
test traces_to_disclosure: nan

Epoch 93 completed.
train loss: 2.8738676465215467
train acc: 0.3485447510094213
train rank: 11.299288147711978
train weight_norm: 170.0028234294856
train grad_norm: 13.88540427814116
train lr: 1.3832565617826394e-05
val loss: 8.540387725830078
val acc: 0.00341796875
val rank: 127.8470703125
test mean_rank: 18.439
test final_rank: 2.0
test traces_to_disclosure: 0.0

Before temperature - NLL: 7.602, ECE: 0.178
Optimal temperature: 7.595
After temperature - NLL: 5.584, ECE: 0.003
Before temperature - NLL: 7.673, ECE: 0.187
Optimal temperature: 7.675
After temperature - NLL: 5.586, ECE: 0.005
Epoch 61 completed.
train loss: 3.5453650364163427
train acc: 0.22816075033647376
train rank: 18.94709300695379
train weight_norm: 163.56907539411003
train grad_norm: 10.66523143462933
train lr: 0.0003380379508163031
val loss: 5.5841858863830565
val acc: 0.0052734375
val rank: 128.0923828125
test mean_rank: 228.233
test final_rank: 193.0
test traces_to_disclosure: nan

Epoch 62 completed.
train loss: 3.509727408395
train acc: 0.23498485868102287
train rank: 18.41536283086586
train weight_norm: 164.2722030078425
train grad_norm: 11.087469424677705
train lr: 0.0003232599582516232
val loss: 5.583292138576508
val acc: 0.00322265625
val rank: 127.4974609375
test mean_rank: 142.466
test final_rank: 225.0
test traces_to_disclosure: nan

Epoch 91 completed.
train loss: 2.8977380700579882
train acc: 0.3423287488784208
train rank: 11.501564953454466
train weight_norm: 169.9909464710106
train grad_norm: 13.405567812077978
train lr: 2.2120037070645153e-05
val loss: 8.541907143592834
val acc: 0.00390625
val rank: 128.0203125
test mean_rank: 139.117
test final_rank: 134.0
test traces_to_disclosure: nan

Epoch 69 completed.
train loss: 3.3056800789018017
train acc: 0.26968897207267833
train rank: 15.84079358737102
train weight_norm: 166.3535027726944
train grad_norm: 11.853123923310438
train lr: 0.000225491045080734
val loss: 7.91740871667862
val acc: 0.00390625
val rank: 126.88720703125
test mean_rank: 147.962
test final_rank: 144.0
test traces_to_disclosure: nan

Before temperature - NLL: 8.370, ECE: 0.253
Optimal temperature: 7.702
After temperature - NLL: 5.593, ECE: 0.005
Epoch 69 completed.
train loss: 3.31080732724227
train acc: 0.2687303723642889
train rank: 15.82403474091521
train weight_norm: 166.3252988988106
train grad_norm: 11.544200353252853
train lr: 0.000225491045080734
val loss: 7.986847102642059
val acc: 0.0041015625
val rank: 129.74541015625
test mean_rank: 100.573
test final_rank: 23.0
test traces_to_disclosure: nan

Before temperature - NLL: 8.352, ECE: 0.246
Optimal temperature: 7.720
After temperature - NLL: 5.598, ECE: 0.005
Epoch 80 completed.
train loss: 3.0130653862677224
train acc: 0.3200163329968596
train rank: 12.579043292956484
train weight_norm: 169.18830648559396
train grad_norm: 14.39354727770967
train lr: 0.00010016776690797451
val loss: 5.591466414928436
val acc: 0.005078125
val rank: 126.069921875
test mean_rank: 56.218
test final_rank: 39.0
test traces_to_disclosure: nan

Epoch 79 completed.
train loss: 3.0549966993755477
train acc: 0.3126524646702557
train rank: 13.046836445715568
train weight_norm: 168.90941774741677
train grad_norm: 14.61711766309195
train lr: 0.00010979423420807191
val loss: 5.5997807264328
val acc: 0.0033203125
val rank: 127.76552734375
test mean_rank: 166.705
test final_rank: 80.0
test traces_to_disclosure: nan

Epoch 94 completed.
train loss: 2.865056523083036
train acc: 0.3511997392328398
train rank: 11.2010325538358
train weight_norm: 170.02078848605083
train grad_norm: 13.757130216181919
train lr: 1.0406585473379184e-05
val loss: 8.54678475856781
val acc: 0.00341796875
val rank: 127.80634765625
test mean_rank: 131.317
test final_rank: 127.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.587, ECE: 0.176
Optimal temperature: 7.699
After temperature - NLL: 5.585, ECE: 0.004
Epoch 60 completed.
train loss: 3.5871235239714343
train acc: 0.22010115242261102
train rank: 19.545294274338268
train weight_norm: 163.49018101154843
train grad_norm: 10.828304041823833
train lr: 0.00035297578036961284
val loss: 5.583941805362701
val acc: 0.00380859375
val rank: 128.66318359375
test mean_rank: 189.833
test final_rank: 124.0
test traces_to_disclosure: nan

Epoch 68 completed.
train loss: 3.3332338410142612
train acc: 0.263593890197398
train rank: 16.093918236877524
train weight_norm: 165.7439847378039
train grad_norm: 11.527587359063538
train lr: 0.00023875244841738502
val loss: 7.898731291294098
val acc: 0.00263671875
val rank: 127.3005859375
test mean_rank: 187.049
test final_rank: 188.0
test traces_to_disclosure: nan

Epoch 92 completed.
train loss: 2.8869755293767834
train acc: 0.3446945799685957
train rank: 11.378052798340065
train weight_norm: 170.02018250815422
train grad_norm: 13.395600073412743
train lr: 1.773833432430308e-05
val loss: 8.560580062866212
val acc: 0.0037109375
val rank: 128.07314453125
test mean_rank: 34.804
test final_rank: 60.0
test traces_to_disclosure: nan

Before temperature - NLL: 8.374, ECE: 0.249
Optimal temperature: 7.727
After temperature - NLL: 5.598, ECE: 0.006
Epoch 70 completed.
train loss: 3.278500253387287
train acc: 0.274212090623598
train rank: 15.543788904777927
train weight_norm: 166.61446691005236
train grad_norm: 11.862200728755328
train lr: 0.00021250054894072056
val loss: 7.950959348678589
val acc: 0.0041015625
val rank: 126.82431640625
test mean_rank: 172.262
test final_rank: 246.0
test traces_to_disclosure: nan

Epoch 70 completed.
train loss: 3.287009831232145
train acc: 0.2726401272992373
train rank: 15.521120737999102
train weight_norm: 166.58790246479205
train grad_norm: 11.497748613655762
train lr: 0.00021250054894072056
val loss: 8.02483901977539
val acc: 0.0037109375
val rank: 129.96376953125
test mean_rank: 167.032
test final_rank: 235.0
test traces_to_disclosure: 33.0

Epoch 80 completed.
train loss: 3.038923723379985
train acc: 0.31645707155675196
train rank: 12.902287671040824
train weight_norm: 169.04315389267094
train grad_norm: 14.338988792777993
train lr: 0.00010016776690797451
val loss: 5.600414991378784
val acc: 0.0033203125
val rank: 128.01328125
test mean_rank: 199.856
test final_rank: 191.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.655, ECE: 0.184
Optimal temperature: 7.597
After temperature - NLL: 5.585, ECE: 0.004
Before temperature - NLL: 7.716, ECE: 0.190
Optimal temperature: 7.675
After temperature - NLL: 5.587, ECE: 0.005
Before temperature - NLL: 8.397, ECE: 0.255
Optimal temperature: 7.709
After temperature - NLL: 5.593, ECE: 0.005
Epoch 62 completed.
train loss: 3.513645241109712
train acc: 0.23311322341857335
train rank: 18.521020847353075
train weight_norm: 163.95978456347126
train grad_norm: 10.9852481146482
train lr: 0.0003232599582516232
val loss: 5.585432529449463
val acc: 0.004296875
val rank: 128.10712890625
test mean_rank: 84.087
test final_rank: 112.0
test traces_to_disclosure: nan

Epoch 95 completed.
train loss: 2.8587848350786746
train acc: 0.3531484830641543
train rank: 11.172386720502466
train weight_norm: 170.03412867938582
train grad_norm: 13.65297495885409
train lr: 7.463774919740511e-06
val loss: 8.543757605552674
val acc: 0.00341796875
val rank: 127.78896484375
test mean_rank: 179.895
test final_rank: 69.0
test traces_to_disclosure: nan

Epoch 63 completed.
train loss: 3.4763965699746504
train acc: 0.24003196500672946
train rank: 17.97362010711081
train weight_norm: 164.64862055628993
train grad_norm: 11.196037700948038
train lr: 0.000308656386770065
val loss: 5.584033203125
val acc: 0.00283203125
val rank: 127.51201171875
test mean_rank: 60.942
test final_rank: 12.0
test traces_to_disclosure: nan

Epoch 81 completed.
train loss: 2.991988639010074
train acc: 0.32372104923732614
train rank: 12.41560992877972
train weight_norm: 169.31078426628898
train grad_norm: 14.517466672161301
train lr: 9.093588574960833e-05
val loss: 5.591771745681763
val acc: 0.0056640625
val rank: 126.06884765625
test mean_rank: 110.874
test final_rank: 69.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.621, ECE: 0.181
Optimal temperature: 7.700
After temperature - NLL: 5.585, ECE: 0.004
Epoch 93 completed.
train loss: 2.8808021936891537
train acc: 0.3464978689995513
train rank: 11.363899871018395
train weight_norm: 170.0435064134752
train grad_norm: 13.435547479988715
train lr: 1.3832565617826394e-05
val loss: 8.552144694328309
val acc: 0.00380859375
val rank: 128.0103515625
test mean_rank: 32.069
test final_rank: 69.0
test traces_to_disclosure: nan

Before temperature - NLL: 8.399, ECE: 0.250
Optimal temperature: 7.734
After temperature - NLL: 5.599, ECE: 0.005
Epoch 61 completed.
train loss: 3.5511453363487893
train acc: 0.22760697061462543
train rank: 19.027019543517273
train weight_norm: 163.91289103529397
train grad_norm: 10.883838992234798
train lr: 0.0003380379508163031
val loss: 5.583414793014526
val acc: 0.00341796875
val rank: 128.18046875
test mean_rank: 221.324
test final_rank: 220.0
test traces_to_disclosure: nan

Epoch 71 completed.
train loss: 3.2505922532498754
train acc: 0.2778186686855092
train rank: 15.22554081146254
train weight_norm: 166.86156613525284
train grad_norm: 11.75248520435851
train lr: 0.00019979378004867344
val loss: 7.998616194725036
val acc: 0.00400390625
val rank: 127.00283203125
test mean_rank: 40.205
test final_rank: 108.0
test traces_to_disclosure: nan

Epoch 69 completed.
train loss: 3.30788536668626
train acc: 0.2682133944593988
train rank: 15.843315388066395
train weight_norm: 166.02730336848308
train grad_norm: 11.572496968315695
train lr: 0.000225491045080734
val loss: 7.952150070667267
val acc: 0.00283203125
val rank: 128.10380859375
test mean_rank: 172.691
test final_rank: 96.0
test traces_to_disclosure: nan

Epoch 71 completed.
train loss: 3.2575941326480216
train acc: 0.27850563593539707
train rank: 15.201581076155225
train weight_norm: 166.83521989549135
train grad_norm: 11.662629520015726
train lr: 0.00019979378004867344
val loss: 8.059569108486176
val acc: 0.0037109375
val rank: 129.609375
test mean_rank: 213.03
test final_rank: 237.0
test traces_to_disclosure: nan

Epoch 81 completed.
train loss: 3.0187281683027183
train acc: 0.3198270665096456
train rank: 12.695535063369222
train weight_norm: 169.16712571392625
train grad_norm: 14.486497401211926
train lr: 9.093588574960833e-05
val loss: 5.601005554199219
val acc: 0.003515625
val rank: 128.01484375
test mean_rank: 45.407
test final_rank: 48.0
test traces_to_disclosure: nan

Epoch 96 completed.
train loss: 2.8581096121632714
train acc: 0.3521600914087034
train rank: 11.147825888851505
train weight_norm: 170.0435410328371
train grad_norm: 13.614485506899861
train lr: 5.007038155636968e-06
val loss: 8.551968097686768
val acc: 0.003515625
val rank: 127.90771484375
test mean_rank: 159.2
test final_rank: 180.0
test traces_to_disclosure: nan

Before temperature - NLL: 8.420, ECE: 0.257
Optimal temperature: 7.715
After temperature - NLL: 5.594, ECE: 0.005
Epoch 94 completed.
train loss: 2.875451753790895
train acc: 0.34678352119784656
train rank: 11.281439266487213
train weight_norm: 170.06141952445844
train grad_norm: 13.387597619159635
train lr: 1.0406585473379184e-05
val loss: 8.556791067123413
val acc: 0.003515625
val rank: 127.96181640625
test mean_rank: 68.339
test final_rank: 88.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.690, ECE: 0.188
Optimal temperature: 7.597
After temperature - NLL: 5.585, ECE: 0.004
Before temperature - NLL: 7.759, ECE: 0.194
Optimal temperature: 7.679
After temperature - NLL: 5.588, ECE: 0.005
Epoch 82 completed.
train loss: 2.974254051737317
train acc: 0.3268632234185734
train rank: 12.21937563088829
train weight_norm: 169.4241003391703
train grad_norm: 14.313951694608924
train lr: 8.210770148509823e-05
val loss: 5.5920751094818115
val acc: 0.00517578125
val rank: 126.1314453125
test mean_rank: 70.363
test final_rank: 39.0
test traces_to_disclosure: nan

Epoch 63 completed.
train loss: 3.4834372082757756
train acc: 0.23830753701211305
train rank: 18.078699809331535
train weight_norm: 164.32875914315997
train grad_norm: 11.062742065289832
train lr: 0.000308656386770065
val loss: 5.585224676132202
val acc: 0.00458984375
val rank: 127.91865234375
test mean_rank: 183.689
test final_rank: 166.0
test traces_to_disclosure: nan

Epoch 64 completed.
train loss: 3.4433349818592918
train acc: 0.244940626401974
train rank: 17.49966352624495
train weight_norm: 165.0074975000783
train grad_norm: 11.24272129781462
train lr: 0.0002942416483335689
val loss: 5.584993755817413
val acc: 0.00302734375
val rank: 127.6673828125
test mean_rank: 184.34
test final_rank: 148.0
test traces_to_disclosure: nan

Epoch 72 completed.
train loss: 3.2285841284658194
train acc: 0.28255208333333337
train rank: 14.95633026301032
train weight_norm: 167.09464637403076
train grad_norm: 11.979888039916359
train lr: 0.0001873832784513824
val loss: 8.029140281677247
val acc: 0.0037109375
val rank: 126.73642578125
test mean_rank: 107.868
test final_rank: 181.0
test traces_to_disclosure: nan

Epoch 72 completed.
train loss: 3.2345022426800325
train acc: 0.2820771646478241
train rank: 14.92546405338717
train weight_norm: 167.07011108696503
train grad_norm: 11.754605208429664
train lr: 0.0001873832784513824
val loss: 8.09808040857315
val acc: 0.00361328125
val rank: 129.814453125
test mean_rank: 152.288
test final_rank: 228.0
test traces_to_disclosure: nan

Epoch 97 completed.
train loss: 2.8537330059472517
train acc: 0.35374256953790933
train rank: 11.127499018618213
train weight_norm: 170.04958810410335
train grad_norm: 13.767512533597502
train lr: 3.038799683649294e-06
val loss: 8.561429858207703
val acc: 0.00341796875
val rank: 127.784375
test mean_rank: 103.025
test final_rank: 108.0
test traces_to_disclosure: nan

Before temperature - NLL: 8.416, ECE: 0.253
Optimal temperature: 7.741
After temperature - NLL: 5.599, ECE: 0.005
Before temperature - NLL: 7.654, ECE: 0.184
Optimal temperature: 7.702
After temperature - NLL: 5.585, ECE: 0.005
Epoch 82 completed.
train loss: 3.0003872822624196
train acc: 0.32299903263795426
train rank: 12.521795437976673
train weight_norm: 169.28166415124267
train grad_norm: 14.418811561462574
train lr: 8.210770148509823e-05
val loss: 5.600816106796264
val acc: 0.0037109375
val rank: 127.93056640625
test mean_rank: 208.421
test final_rank: 195.0
test traces_to_disclosure: nan

Epoch 70 completed.
train loss: 3.2794402066021555
train acc: 0.27251394964109465
train rank: 15.481287152310454
train weight_norm: 166.29035956532493
train grad_norm: 11.690417433536439
train lr: 0.00021250054894072056
val loss: 7.973802661895752
val acc: 0.002734375
val rank: 127.75576171875
test mean_rank: 217.811
test final_rank: 255.0
test traces_to_disclosure: nan

Epoch 95 completed.
train loss: 2.8670087104530384
train acc: 0.34951036058770746
train rank: 11.223967095670703
train weight_norm: 170.07479684013177
train grad_norm: 13.353589245552559
train lr: 7.463774919740511e-06
val loss: 8.558560371398926
val acc: 0.00390625
val rank: 127.95078125
test mean_rank: 93.319
test final_rank: 81.0
test traces_to_disclosure: nan

Before temperature - NLL: 8.434, ECE: 0.258
Optimal temperature: 7.722
After temperature - NLL: 5.594, ECE: 0.005
Epoch 62 completed.
train loss: 3.5195546657207997
train acc: 0.23232110812023327
train rank: 18.567024871018393
train weight_norm: 164.3101222012499
train grad_norm: 11.024131529085162
train lr: 0.0003232599582516232
val loss: 5.5846853017807
val acc: 0.00302734375
val rank: 128.404296875
test mean_rank: 210.632
test final_rank: 249.0
test traces_to_disclosure: nan

wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:           test_final_rank ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñá‚ñÅ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÇ‚ñÉ‚ñà‚ñá‚ñÉ‚ñÜ‚ñÇ‚ñÅ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÜ‚ñÖ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñá‚ñÇ
wandb:            test_mean_rank ‚ñÇ‚ñÖ‚ñÇ‚ñÇ‚ñÜ‚ñÇ‚ñÑ‚ñá‚ñÖ‚ñà‚ñÇ‚ñÉ‚ñÜ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñÑ‚ñÜ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÖ‚ñÅ‚ñÇ‚ñÜ‚ñÉ
wandb: test_traces_to_disclosure               ‚ñÅ           ‚ñà          ‚ñÅ  
wandb:                 train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:           train_grad_norm ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                  train_lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                train_rank ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:         train_weight_norm ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                   val_acc ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:                  val_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                  val_rank ‚ñÉ‚ñÉ‚ñÅ‚ñÖ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:                best_epoch 100
wandb:             best_test_acc 0.00419
wandb:            best_test_loss 5.54822
wandb:            best_test_rank 127.79326
wandb:            best_train_acc 0.0052
wandb:      best_train_grad_norm 0.28496
wandb:           best_train_loss 5.54072
wandb:             best_train_lr 0.001
wandb:           best_train_rank 120.52949
wandb:    best_train_weight_norm 94.73212
wandb:              best_val_acc 0.004
wandb:             best_val_loss 5.54699
wandb:             best_val_rank 126.41641
wandb:                     epoch 100
wandb:           test_final_rank 38.0
wandb:            test_mean_rank 87.072
wandb: test_traces_to_disclosure nan
wandb:                 train_acc 0.35495
wandb:           train_grad_norm 13.8793
wandb:                train_loss 2.83899
wandb:                  train_lr 0.0
wandb:                train_rank 10.96767
wandb:         train_weight_norm 169.55878
wandb:                   val_acc 0.00205
wandb:                  val_loss 8.5926
wandb:                  val_rank 127.50127
wandb: 
wandb: üöÄ View run northern-sweep-9 at: https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50/runs/akbyqtal
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_112640-akbyqtal/logs
wandb: Agent Starting Run: sdcq099k with config:
wandb: 	optimizer_kwargs-lr: 0.01
wandb: 	optimizer_kwargs-weight_decay: 1e-08
wandb: 	rescale_temperature: False
wandb: 	use_sam: False
Epoch 83 completed.
train loss: 2.9598369161983196
train acc: 0.3303664058995065
train rank: 12.110612242036787
train weight_norm: 169.52695532555254
train grad_norm: 14.30030528887114
train lr: 7.369192646647374e-05
val loss: 5.592261111736297
val acc: 0.00546875
val rank: 126.14619140625
test mean_rank: 92.326
test final_rank: 120.0
test traces_to_disclosure: nan

wandb: Tracking run with wandb version 0.15.4
wandb: Run data is saved locally in /local/a/jgammell/dlsca_architecture_comparison/wandb/run-20230614_151033-sdcq099k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-13
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50
wandb: üßπ View sweep at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50/sweeps/cltqb3ug
wandb: üöÄ View run at https://wandb.ai/jgammell/convmixer_htune__ascad_variable_desync50/runs/sdcq099k
Training classifier...
ConvMixer(
  (patch_embedding): Sequential(
    (conv): Conv1d(1, 256, kernel_size=(51,), stride=(51,), padding=(28,))
  )
  (pre_mixer): Sequential(
    (act): GELU(approximate='none')
    (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mixer): Sequential(
    (layer_0): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer_1): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer_2): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer_3): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer_4): Sequential(
      (spatial_mixer): SpatialMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256)
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): ChannelMixer(
        (model): Sequential(
          (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (act): GELU(approximate='none')
          (norm): BatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (head): Sequential(
    (pool): AdaptiveAvgPool1d(output_size=1)
    (flatten): Flatten(start_dim=1, end_dim=-1)
    (dense): Linear(in_features=256, out_features=256, bias=True)
  )
)
Number of parameters: 454656
Epoch 73 completed.
train loss: 3.2038524625760227
train acc: 0.28586775179452667
train rank: 14.649361050358907
train weight_norm: 167.3111440853618
train grad_norm: 12.071132358572118
train lr: 0.00017528129181558567
val loss: 8.061041605472564
val acc: 0.00380859375
val rank: 127.17705078125
test mean_rank: 235.66
test final_rank: 228.0
test traces_to_disclosure: nan

Epoch 98 completed.
train loss: 2.8532223181641116
train acc: 0.35392307368775233
train rank: 11.116085197958725
train weight_norm: 170.05304028252942
train grad_norm: 13.614304697811061
train lr: 1.5610019175210288e-06
val loss: 8.560554051399231
val acc: 0.00341796875
val rank: 127.90751953125
test mean_rank: 144.21
test final_rank: 60.0
test traces_to_disclosure: nan

Epoch 73 completed.
train loss: 3.2088974170376763
train acc: 0.2850370822117541
train rank: 14.63416014748766
train weight_norm: 167.2890812611339
train grad_norm: 11.735079211815433
train lr: 0.00017528129181558567
val loss: 8.12892689704895
val acc: 0.00341796875
val rank: 129.77744140625
test mean_rank: 232.97
test final_rank: 246.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.736, ECE: 0.192
Optimal temperature: 7.598
After temperature - NLL: 5.586, ECE: 0.004
Before temperature - NLL: 7.802, ECE: 0.200
Optimal temperature: 7.684
After temperature - NLL: 5.588, ECE: 0.005
Before temperature - NLL: 8.431, ECE: 0.254
Optimal temperature: 9.113
After temperature - NLL: 5.584, ECE: 0.004
Before temperature - NLL: 8.462, ECE: 0.260
Optimal temperature: 7.729
After temperature - NLL: 5.595, ECE: 0.005
Epoch 65 completed.
train loss: 3.4141552769159085
train acc: 0.249130776132795
train rank: 17.122069874383133
train weight_norm: 165.35142075130082
train grad_norm: 11.39181506100957
train lr: 0.00028002996854866136
val loss: 5.584948551654816
val acc: 0.003515625
val rank: 127.41181640625
test mean_rank: 82.135
test final_rank: 66.0
test traces_to_disclosure: nan

Epoch 64 completed.
train loss: 3.451169856303794
train acc: 0.2426483989457156
train rank: 17.634582492148947
train weight_norm: 164.67872071258438
train grad_norm: 11.130662809331852
train lr: 0.0002942416483335689
val loss: 5.5867203831672665
val acc: 0.0046875
val rank: 127.9640625
test mean_rank: 46.335
test final_rank: 48.0
test traces_to_disclosure: nan

Epoch 83 completed.
train loss: 2.98624501735333
train acc: 0.32543320995962316
train rank: 12.372956622925077
train weight_norm: 169.38473914936964
train grad_norm: 14.369706916895176
train lr: 7.369192646647374e-05
val loss: 5.586143934726715
val acc: 0.00302734375
val rank: 127.95224609375
test mean_rank: 201.159
test final_rank: 231.0
test traces_to_disclosure: nan

New best model found.
Epoch 1 completed.
train loss: 5.556300394307235
train acc: 0.0038063593539703904
train rank: 127.3344514075819
train weight_norm: 106.34972470678333
train grad_norm: 0.15149253089461792
train lr: 0.009999175912513092
val loss: 5.555512690544129
val acc: 0.00341796875
val rank: 127.43779296875
test mean_rank: 193.696
test final_rank: 172.0
test traces_to_disclosure: nan

Epoch 96 completed.
train loss: 2.8685821880402185
train acc: 0.3497259140870345
train rank: 11.24827031460296
train weight_norm: 170.0841742253642
train grad_norm: 13.29035021785272
train lr: 5.007038155636968e-06
val loss: 8.559609317779541
val acc: 0.00380859375
val rank: 128.0669921875
test mean_rank: 216.3
test final_rank: 247.0
test traces_to_disclosure: nan

Epoch 84 completed.
train loss: 2.943043477442191
train acc: 0.3334665208613728
train rank: 11.944338128084345
train weight_norm: 169.61988930281322
train grad_norm: 14.411752556197921
train lr: 6.569686604762924e-05
val loss: 5.593270146846772
val acc: 0.00478515625
val rank: 126.2818359375
test mean_rank: 114.47
test final_rank: 98.0
test traces_to_disclosure: 0.0

Epoch 99 completed.
train loss: 2.8479211282280863
train acc: 0.354900950538358
train rank: 11.048490775011214
train weight_norm: 170.05461070749715
train grad_norm: 13.746049530508948
train lr: 5.751032652306508e-07
val loss: 8.553283071517944
val acc: 0.003125
val rank: 127.79189453125
test mean_rank: 38.684
test final_rank: 137.0
test traces_to_disclosure: nan

Epoch 71 completed.
train loss: 3.2545871580593677
train acc: 0.27697748429789143
train rank: 15.196973839165546
train weight_norm: 166.54209456140697
train grad_norm: 11.765089562876623
train lr: 0.00019979378004867344
val loss: 8.027880012989044
val acc: 0.00302734375
val rank: 128.0169921875
test mean_rank: 41.229
test final_rank: 25.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.716, ECE: 0.189
Optimal temperature: 7.703
After temperature - NLL: 5.588, ECE: 0.004
Epoch 63 completed.
train loss: 3.487614599564194
train acc: 0.23658135655002246
train rank: 18.103688243046207
train weight_norm: 164.68431567979692
train grad_norm: 11.184248387953618
train lr: 0.000308656386770065
val loss: 5.58619464635849
val acc: 0.00361328125
val rank: 128.4650390625
test mean_rank: 54.99
test final_rank: 23.0
test traces_to_disclosure: nan

Before temperature - NLL: 8.451, ECE: 0.255
Optimal temperature: 9.114
After temperature - NLL: 5.585, ECE: 0.004
Epoch 74 completed.
train loss: 3.1827630772083637
train acc: 0.2909253729250785
train rank: 14.435754542395694
train weight_norm: 167.51718708326288
train grad_norm: 12.126292384835782
train lr: 0.00016349976334100182
val loss: 8.079581105709076
val acc: 0.0041015625
val rank: 126.88798828125
test mean_rank: 218.85
test final_rank: 247.0
test traces_to_disclosure: nan

Epoch 84 completed.
train loss: 2.970196072217754
train acc: 0.32977582436069985
train rank: 12.230176087931806
train weight_norm: 169.5461094552488
train grad_norm: 14.356462428454783
train lr: 6.569686604762924e-05
val loss: 5.586380743980408
val acc: 0.00400390625
val rank: 127.91298828125
test mean_rank: 193.26
test final_rank: 230.0
test traces_to_disclosure: nan

Epoch 74 completed.
train loss: 3.1891973650792407
train acc: 0.28994574360699865
train rank: 14.432735040937642
train weight_norm: 167.49546173060938
train grad_norm: 11.857496431928435
train lr: 0.00016349976334100182
val loss: 8.137723004817962
val acc: 0.00341796875
val rank: 129.5744140625
test mean_rank: 97.768
test final_rank: 149.0
test traces_to_disclosure: nan

Epoch 2 completed.
train loss: 5.555511575367698
train acc: 0.003879962987886945
train rank: 127.33822622252133
train weight_norm: 113.3531678053769
train grad_norm: 0.16995807714539127
train lr: 0.009994239008855531
val loss: 5.5571061134338375
val acc: 0.00400390625
val rank: 127.7201171875
test mean_rank: 213.22
test final_rank: 170.0
test traces_to_disclosure: nan

Epoch 97 completed.
train loss: 2.863813681365022
train acc: 0.34944902422611035
train rank: 11.184236905563031
train weight_norm: 170.09014302355322
train grad_norm: 13.329018603753369
train lr: 3.038799683649294e-06
val loss: 8.57072048187256
val acc: 0.00341796875
val rank: 127.9568359375
test mean_rank: 61.411
test final_rank: 205.0
test traces_to_disclosure: 222.0

Before temperature - NLL: 8.470, ECE: 0.261
Optimal temperature: 7.735
After temperature - NLL: 5.594, ECE: 0.004
Before temperature - NLL: 7.843, ECE: 0.204
Optimal temperature: 7.685
After temperature - NLL: 5.589, ECE: 0.006
Before temperature - NLL: 7.782, ECE: 0.195
Optimal temperature: 7.599
After temperature - NLL: 5.587, ECE: 0.003
Epoch 100 completed.
train loss: 2.8489183513184417
train acc: 0.3540615186182145
train rank: 11.074812836473756
train weight_norm: 170.05501307311152
train grad_norm: 13.539941274175156
train lr: 8.207668971898738e-08
val loss: 8.554935669898986
val acc: 0.0033203125
val rank: 127.84384765625
test mean_rank: 138.659
test final_rank: 211.0
test traces_to_disclosure: nan

Done training. Computing performance of best model.
Epoch 85 completed.
train loss: 2.930285363306428
train acc: 0.3374726615074024
train rank: 11.81179901301032
train weight_norm: 169.70413682759207
train grad_norm: 14.3371943439365
train lr: 5.813041038794308e-05
val loss: 5.592733478546142
val acc: 0.00556640625
val rank: 126.13876953125
test mean_rank: 125.621
test final_rank: 217.0
test traces_to_disclosure: nan

Epoch 66 completed.
train loss: 3.3848608663232937
train acc: 0.2548175330865859
train rank: 16.773712637393448
train weight_norm: 165.6738071213563
train grad_norm: 11.5339021140984
train lr: 0.00026603537262749225
val loss: 5.585805356502533
val acc: 0.00322265625
val rank: 127.40009765625
test mean_rank: 171.7
test final_rank: 135.0
test traces_to_disclosure: nan

Epoch 65 completed.
train loss: 3.4177594143160257
train acc: 0.24964424910273664
train rank: 17.27495163189771
train weight_norm: 165.02000075953384
train grad_norm: 11.206424607645687
train lr: 0.00028002996854866136
val loss: 5.58777664899826
val acc: 0.00498046875
val rank: 127.944140625
test mean_rank: 60.234
test final_rank: 7.0
test traces_to_disclosure: nan

Epoch 72 completed.
train loss: 3.2312580749773563
train acc: 0.28099238728129206
train rank: 14.950748654104979
train weight_norm: 166.77540990757944
train grad_norm: 11.861978851535909
train lr: 0.0001873832784513824
val loss: 8.053707492351531
val acc: 0.00341796875
val rank: 128.0001953125
test mean_rank: 106.161
test final_rank: 192.0
test traces_to_disclosure: nan

Before temperature - NLL: 8.466, ECE: 0.256
Optimal temperature: 9.114
After temperature - NLL: 5.585, ECE: 0.004
Before temperature - NLL: 7.754, ECE: 0.191
Optimal temperature: 7.709
After temperature - NLL: 5.589, ECE: 0.004
New best model found.
Epoch 3 completed.
train loss: 5.555847041539517
train acc: 0.0037853297442799463
train rank: 127.2578405394796
train weight_norm: 119.44251429801238
train grad_norm: 0.1944796817178982
train lr: 0.009984373394257992
val loss: 5.555113339424134
val acc: 0.0033203125
val rank: 127.2123046875
test mean_rank: 28.8
test final_rank: 1.0
test traces_to_disclosure: 530.0

train loss: 5.540723531756394
train acc: 0.005201323463436519
train rank: 120.52956587875728
val loss: 5.546995317935943
val acc: 0.00400390625
val rank: 126.41728515625
test loss: 5.548216149020378
test acc: 0.004185981457800511
test rank: 127.79386988491048
Epoch 98 completed.
train loss: 2.8624171267287406
train acc: 0.3495892216240466
train rank: 11.166428331090176
train weight_norm: 170.09358876787888
train grad_norm: 13.36088502652138
train lr: 1.5610019175210288e-06
val loss: 8.573241567611694
val acc: 0.00341796875
val rank: 128.0658203125
test mean_rank: 161.051
test final_rank: 187.0
test traces_to_disclosure: nan

Epoch 85 completed.
train loss: 2.9585845162377544
train acc: 0.3309429676985195
train rank: 12.108199094324808
train weight_norm: 169.63012830661253
train grad_norm: 14.390509629009712
train lr: 5.813041038794308e-05
val loss: 5.586791241168976
val acc: 0.0037109375
val rank: 127.95546875
test mean_rank: 91.015
test final_rank: 93.0
test traces_to_disclosure: nan

Epoch 64 completed.
train loss: 3.4544990508745688
train acc: 0.24283941790040378
train rank: 17.69383692238672
train weight_norm: 165.04391637338662
train grad_norm: 11.248907907282087
train lr: 0.0002942416483335689
val loss: 5.586884844303131
val acc: 0.003515625
val rank: 128.519140625
test mean_rank: 83.804
test final_rank: 43.0
test traces_to_disclosure: nan

Epoch 75 completed.
train loss: 3.1563976853885367
train acc: 0.2957779553611485
train rank: 14.11706657974428
train weight_norm: 167.7103730047736
train grad_norm: 12.087274724864072
train lr: 0.00015205031997383474
val loss: 8.123559522628785
val acc: 0.00341796875
val rank: 127.19287109375
test mean_rank: 157.199
test final_rank: 214.0
test traces_to_disclosure: nan

Epoch 75 completed.
train loss: 3.1643897242051917
train acc: 0.293536549461642
train rank: 14.146518548115747
train weight_norm: 167.68639179555313
train grad_norm: 11.92501765512007
train lr: 0.00015205031997383474
val loss: 8.180001521110535
val acc: 0.00390625
val rank: 129.6173828125
test mean_rank: 95.463
test final_rank: 96.0
test traces_to_disclosure: 152.0

Before temperature - NLL: 8.487, ECE: 0.262
Optimal temperature: 7.742
After temperature - NLL: 5.594, ECE: 0.004
Epoch 4 completed.
train loss: 5.55652241687595
train acc: 0.003974596231493943
train rank: 127.23769417339615
train weight_norm: 124.99943837534025
train grad_norm: 0.2144251848078303
train lr: 0.009969588804891042
val loss: 5.558840417861939
val acc: 0.00283203125
val rank: 127.77705078125
test mean_rank: 210.514
test final_rank: 186.0
test traces_to_disclosure: nan

Epoch 73 completed.
train loss: 3.2052511106750363
train acc: 0.2859466128308658
train rank: 14.62530317687304
train weight_norm: 166.995901401045
train grad_norm: 11.828675923260848
train lr: 0.00017528129181558567
val loss: 8.081391608715057
val acc: 0.00263671875
val rank: 127.86142578125
test mean_rank: 227.703
test final_rank: 188.0
test traces_to_disclosure: nan

Epoch 86 completed.
train loss: 2.9169590027142984
train acc: 0.33890092249887843
train rank: 11.670543124719607
train weight_norm: 169.7787382001021
train grad_norm: 14.331085582896678
train lr: 5.100002666564194e-05
val loss: 5.593042957782745
val acc: 0.00517578125
val rank: 126.09169921875
test mean_rank: 149.124
test final_rank: 86.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.874, ECE: 0.207
Optimal temperature: 7.690
After temperature - NLL: 5.589, ECE: 0.005
Before temperature - NLL: 7.820, ECE: 0.199
Optimal temperature: 7.605
After temperature - NLL: 5.588, ECE: 0.003
Epoch 67 completed.
train loss: 3.3594216671477737
train acc: 0.2583382402422611
train rank: 16.432861218595786
train weight_norm: 165.98245086777524
train grad_norm: 11.603247852159196
train lr: 0.0002522716715466487
val loss: 5.585887622833252
val acc: 0.002734375
val rank: 127.1826171875
test mean_rank: 162.977
test final_rank: 103.0
test traces_to_disclosure: nan

Epoch 66 completed.
train loss: 3.387419490762867
train acc: 0.2541603577837595
train rank: 16.811488826267386
train weight_norm: 165.34492445108648
train grad_norm: 11.297065231563549
train lr: 0.00026603537262749225
val loss: 5.588431549072266
val acc: 0.005078125
val rank: 128.13505859375
test mean_rank: 177.209
test final_rank: 129.0
test traces_to_disclosure: nan

Epoch 99 completed.
train loss: 2.858026314230979
train acc: 0.3507756421040826
train rank: 11.141939350605652
train weight_norm: 170.0951484452488
train grad_norm: 13.368360005472853
train lr: 5.751032652306508e-07
val loss: 8.563743853569031
val acc: 0.00361328125
val rank: 127.98359375
test mean_rank: 61.464
test final_rank: 40.0
test traces_to_disclosure: nan

Before temperature - NLL: 8.481, ECE: 0.258
Optimal temperature: 9.114
After temperature - NLL: 5.585, ECE: 0.004
Before temperature - NLL: 8.500, ECE: 0.263
Optimal temperature: 7.749
After temperature - NLL: 5.595, ECE: 0.004
Epoch 86 completed.
train loss: 2.9472704870704045
train acc: 0.333666302153432
train rank: 11.995231536002692
train weight_norm: 169.70399684718822
train grad_norm: 14.528462561364954
train lr: 5.100002666564194e-05
val loss: 5.586793327331543
val acc: 0.00361328125
val rank: 127.91298828125
test mean_rank: 205.964
test final_rank: 239.0
test traces_to_disclosure: 18.0

Epoch 87 completed.
train loss: 2.9083406357232526
train acc: 0.34099687359802605
train rank: 11.612347184836247
train weight_norm: 169.8440105068243
train grad_norm: 14.41878511734001
train lr: 4.431275170859809e-05
val loss: 5.593243837356567
val acc: 0.00517578125
val rank: 126.140234375
test mean_rank: 186.907
test final_rank: 235.0
test traces_to_disclosure: nan

Before temperature - NLL: 7.815, ECE: 0.197
Optimal temperature: 7.710
After temperature - NLL: 5.591, ECE: 0.004
Epoch 5 completed.
train loss: 5.556900166887615
train acc: 0.003908002467474203
train rank: 127.33952655338716
train weight_norm: 131.02451574545432
train grad_norm: 0.2306036579791924
train lr: 0.009949899831359374
val loss: 5.555415523052216
val acc: 0.00380859375
val rank: 127.6578125
test mean_rank: 128.025
test final_rank: 78.0
test traces_to_disclosure: nan

Epoch 76 completed.
train loss: 3.142235618260154
train acc: 0.29848551760879316
train rank: 13.89074942519067
train weight_norm: 167.8680563973746
train grad_norm: 11.88833098059945
train lr: 0.00014094426093237933
val loss: 8.224408638477325
val acc: 0.00322265625
val rank: 129.85166015625
test mean_rank: 77.281
test final_rank: 48.0
test traces_to_disclosure: nan

Epoch 76 completed.
train loss: 3.13799447840027
train acc: 0.2991023861597129
train rank: 13.93703384365186
train weight_norm: 167.8871483264221
train grad_norm: 12.216192242764606
train lr: 0.00014094426093237933
val loss: 8.152807354927063
val acc: 0.00400390625
val rank: 126.7263671875
test mean_rank: 48.59
test final_rank: 17.0
test traces_to_disclosure: nan

Epoch 65 completed.
train loss: 3.422726249951533
train acc: 0.24810733512786004
train rank: 17.258848208277254
train weight_norm: 165.38950764094312
train grad_norm: 11.189642274653938
train lr: 0.00028002996854866136
val loss: 5.589250922203064
val acc: 0.0037109375
val rank: 128.8068359375
test mean_rank: 83.8
test final_rank: 62.0
test traces_to_disclosure: 18.0

Epoch 74 completed.
train loss: 3.183804620804408
train acc: 0.2889976587034545
train rank: 14.390817771422164
train weight_norm: 167.2029021572728
train grad_norm: 12.025923583423822
train lr: 0.00016349976334100182
val loss: 8.111618185043335
val acc: 0.0029296875
val rank: 127.86103515625
test mean_rank: 34.227
test final_rank: 26.0
test traces_to_disclosure: nan

Epoch 100 completed.
train loss: 2.858935411332594
train acc: 0.35151343091072224
train rank: 11.139200243943472
train weight_norm: 170.09555170552886
train grad_norm: 13.291777217323611
train lr: 8.207668971898738e-08
val loss: 8.567790269851685
val acc: 0.00302734375
val rank: 128.10859375
test mean_rank: 60.25
test final_rank: 43.0
test traces_to_disclosure: nan

Done training. Computing performance of best model.
Before temperature - NLL: 7.914, ECE: 0.210
Optimal temperature: 7.696
After temperature - NLL: 5.590, ECE: 0.005
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 125, in _main
    prepare(preparation_data)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 236, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 287, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 288, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/local/a/jgammell/dlsca_architecture_comparison/main.py", line 12, in <module>
    import train, train.classifier
  File "/local/a/jgammell/dlsca_architecture_comparison/train/classifier.py", line 150
    if 
       ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 125, in _main
    prepare(preparation_data)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 236, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 287, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 288, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/local/a/jgammell/dlsca_architecture_comparison/main.py", line 12, in <module>
    import train, train.classifier
  File "/local/a/jgammell/dlsca_architecture_comparison/train/classifier.py", line 150
    if 
       ^
SyntaxError: invalid syntax
Before temperature - NLL: 8.495, ECE: 0.260
Optimal temperature: 9.115
After temperature - NLL: 5.586, ECE: 0.004
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 125, in _main
    prepare(preparation_data)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 236, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 287, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 288, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/local/a/jgammell/dlsca_architecture_comparison/main.py", line 12, in <module>
    import train, train.classifier
  File "/local/a/jgammell/dlsca_architecture_comparison/train/classifier.py", line 150
    if 
       ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 125, in _main
    prepare(preparation_data)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 236, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 287, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 288, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/local/a/jgammell/dlsca_architecture_comparison/main.py", line 12, in <module>
    import train, train.classifier
  File "/local/a/jgammell/dlsca_architecture_comparison/train/classifier.py", line 150
    if 
       ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 125, in _main
    prepare(preparation_data)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 236, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 287, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 288, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/local/a/jgammell/dlsca_architecture_comparison/main.py", line 12, in <module>
    import train, train.classifier
  File "/local/a/jgammell/dlsca_architecture_comparison/train/classifier.py", line 150
    if 
       ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 125, in _main
    prepare(preparation_data)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 236, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 287, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 288, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/local/a/jgammell/dlsca_architecture_comparison/main.py", line 12, in <module>
    import train, train.classifier
  File "/local/a/jgammell/dlsca_architecture_comparison/train/classifier.py", line 150
    if 
       ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 125, in _main
    prepare(preparation_data)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 236, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 287, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 288, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/local/a/jgammell/dlsca_architecture_comparison/main.py", line 12, in <module>
    import train, train.classifier
  File "/local/a/jgammell/dlsca_architecture_comparison/train/classifier.py", line 150
    if 
       ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 125, in _main
    prepare(preparation_data)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 236, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 287, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 288, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/local/a/jgammell/dlsca_architecture_comparison/main.py", line 12, in <module>
    import train, train.classifier
  File "/local/a/jgammell/dlsca_architecture_comparison/train/classifier.py", line 150
    if 
       ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 125, in _main
    prepare(preparation_data)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 236, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 287, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 288, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/local/a/jgammell/dlsca_architecture_comparison/main.py", line 12, in <module>
    import train, train.classifier
  File "/local/a/jgammell/dlsca_architecture_comparison/train/classifier.py", line 150
    if 
       ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 125, in _main
    prepare(preparation_data)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 236, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 287, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 288, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/local/a/jgammell/dlsca_architecture_comparison/main.py", line 12, in <module>
    import train, train.classifier
  File "/local/a/jgammell/dlsca_architecture_comparison/train/classifier.py", line 150
    if 
       ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 125, in _main
    prepare(preparation_data)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 236, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/spawn.py", line 287, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 288, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/local/a/jgammell/dlsca_architecture_comparison/main.py", line 12, in <module>
    import train, train.classifier
  File "/local/a/jgammell/dlsca_architecture_comparison/train/classifier.py", line 150
    if 
       ^
SyntaxError: invalid syntax
wandb: Ctrl + C detected. Stopping sweep.
wandb: Ctrl + C detected. Stopping sweep.
wandb: Ctrl + C detected. Stopping sweep.
wandb: Waiting for W&B process to finish... (success).
wandb: Ctrl + C detected. Stopping sweep.
wandb: Ctrl + C detected. Stopping sweep.
wandb: Ctrl + C detected. Stopping sweep.
wandb: Ctrl + C detected. Stopping sweep.
wandb: Ctrl + C detected. Stopping sweep.
wandb: Ctrl + C detected. Stopping sweep.
wandb: Ctrl + C detected. Stopping sweep.
wandb: Ctrl + C detected. Stopping sweep.
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
wandb: Waiting for W&B process to finish... (success).
Traceback (most recent call last):
  File "/local/a/jgammell/dlsca_architecture_comparison/main.py", line 175, in <module>
    main()
  File "/local/a/jgammell/dlsca_architecture_comparison/main.py", line 171, in main
    htune_classifier(args.dataset, settings, seed_=args.seed, devices=devices, num_agents=args.num_wandb_agents)
  File "/local/a/jgammell/dlsca_architecture_comparison/main.py", line 96, in htune_classifier
    p.join()
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/popen_fork.py", line 43, in wait
    return self.poll(os.WNOHANG if timeout == 0.0 else 0)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/popen_fork.py", line 27, in poll
    pid, sts = os.waitpid(self.pid, flag)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/wandb/sdk/wandb_manager.py", line 185, in _teardown
    self._inform_teardown(exit_code)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/wandb/sdk/wandb_manager.py", line 228, in _inform_teardown
    svc_iface._svc_inform_teardown(exit_code)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/wandb/sdk/service/service_sock.py", line 68, in _svc_inform_teardown
    self._sock_client.send(inform_teardown=inform_teardown)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py", line 211, in send
    self.send_server_request(server_req)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py", line 155, in send_server_request
    self._send_message(msg)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py", line 152, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py", line 130, in _sendall_with_error_handle
    sent = self._sock.send(data)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Error in atexit._run_exitfuncs:
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1189, in wait
Error in atexit._run_exitfuncs:
Error in atexit._run_exitfuncs:
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/popen_fork.py", line 27, in poll
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1189, in wait
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1189, in wait
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1189, in wait
Traceback (most recent call last):
Error in atexit._run_exitfuncs:
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1189, in wait
Traceback (most recent call last):
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1189, in wait
Error in atexit._run_exitfuncs:
Error in atexit._run_exitfuncs:
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1189, in wait
    pid, sts = os.waitpid(self.pid, flag)
Error in atexit._run_exitfuncs:
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1189, in wait
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1189, in wait
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1189, in wait
    return self._wait(timeout=timeout)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1917, in _wait
    (pid, sts) = self._try_wait(0)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1875, in _try_wait
    return self._wait(timeout=timeout)
    return self._wait(timeout=timeout)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1917, in _wait
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1917, in _wait
    return self._wait(timeout=timeout)
    return self._wait(timeout=timeout)
    return self._wait(timeout=timeout)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1917, in _wait
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1917, in _wait
    return self._wait(timeout=timeout)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1917, in _wait
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1917, in _wait
    return self._wait(timeout=timeout)
    return self._wait(timeout=timeout)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1917, in _wait
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1917, in _wait
    (pid, sts) = self._try_wait(0)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1875, in _try_wait
    return self._wait(timeout=timeout)
    (pid, sts) = self._try_wait(0)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1917, in _wait
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1875, in _try_wait
    (pid, sts) = self._try_wait(0)
    (pid, sts) = os.waitpid(self.pid, wait_flags)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1875, in _try_wait
    (pid, sts) = self._try_wait(0)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1875, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
    (pid, sts) = os.waitpid(self.pid, wait_flags)
    (pid, sts) = self._try_wait(0)
KeyboardInterrupt
    (pid, sts) = self._try_wait(0)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1875, in _try_wait
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1875, in _try_wait
KeyboardInterrupt
    (pid, sts) = self._try_wait(0)
    (pid, sts) = os.waitpid(self.pid, wait_flags)

During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1875, in _try_wait
Traceback (most recent call last):
Traceback (most recent call last):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/wandb/sdk/wandb_manager.py", line 186, in _teardown
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/wandb/sdk/wandb_manager.py", line 186, in _teardown
Traceback (most recent call last):
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/wandb/sdk/wandb_manager.py", line 186, in _teardown
    (pid, sts) = self._try_wait(0)
    (pid, sts) = self._try_wait(0)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1875, in _try_wait
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1875, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
    result = self._service.join()
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/wandb/sdk/service/service.py", line 216, in join
    result = self._service.join()
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/wandb/sdk/service/service.py", line 216, in join
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/wandb/sdk/wandb_manager.py", line 186, in _teardown
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
    result = self._service.join()
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/wandb/sdk/wandb_manager.py", line 186, in _teardown
    (pid, sts) = os.waitpid(self.pid, wait_flags)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/wandb/sdk/service/service.py", line 216, in join
    result = self._service.join()
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/wandb/sdk/service/service.py", line 216, in join
KeyboardInterrupt
    ret = self._internal_proc.wait()
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1202, in wait

During handling of the above exception, another exception occurred:

    result = self._service.join()
    (pid, sts) = os.waitpid(self.pid, wait_flags)
Traceback (most recent call last):
    (pid, sts) = os.waitpid(self.pid, wait_flags)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/wandb/sdk/service/service.py", line 216, in join
    ret = self._internal_proc.wait()
    ret = self._internal_proc.wait()
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1202, in wait
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/wandb/sdk/wandb_manager.py", line 186, in _teardown
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1202, in wait
    self._wait(timeout=sigint_timeout)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1911, in _wait
    ret = self._internal_proc.wait()
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1202, in wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt
KeyboardInterrupt
    (pid, sts) = os.waitpid(self.pid, wait_flags)

During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

    self._wait(timeout=sigint_timeout)
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1911, in _wait
    result = self._service.join()
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/wandb/sdk/service/service.py", line 216, in join
    ret = self._internal_proc.wait()
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/wandb/sdk/wandb_manager.py", line 186, in _teardown
KeyboardInterrupt
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/wandb/sdk/wandb_manager.py", line 186, in _teardown
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1202, in wait
    time.sleep(delay)

During handling of the above exception, another exception occurred:

KeyboardInterrupt
KeyboardInterrupt
Traceback (most recent call last):

During handling of the above exception, another exception occurred:

    time.sleep(delay)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/wandb/sdk/wandb_manager.py", line 186, in _teardown
Traceback (most recent call last):
KeyboardInterrupt
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/wandb/sdk/wandb_manager.py", line 186, in _teardown
    self._wait(timeout=sigint_timeout)
    ret = self._internal_proc.wait()
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1911, in _wait
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1202, in wait
    result = self._service.join()
    result = self._service.join()
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/wandb/sdk/service/service.py", line 216, in join
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/wandb/sdk/service/service.py", line 216, in join
    self._wait(timeout=sigint_timeout)
    result = self._service.join()
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1911, in _wait
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/wandb/sdk/service/service.py", line 216, in join
    result = self._service.join()
    self._wait(timeout=sigint_timeout)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/wandb/sdk/service/service.py", line 216, in join
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1911, in _wait
    ret = self._internal_proc.wait()
    ret = self._internal_proc.wait()
    self._wait(timeout=sigint_timeout)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1202, in wait
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1202, in wait
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1911, in _wait
    ret = self._internal_proc.wait()
    time.sleep(delay)
    ret = self._internal_proc.wait()
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1202, in wait
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1202, in wait
    time.sleep(delay)
KeyboardInterrupt
KeyboardInterrupt
    time.sleep(delay)
    self._wait(timeout=sigint_timeout)
    self._wait(timeout=sigint_timeout)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1911, in _wait
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1911, in _wait
KeyboardInterrupt
    self._wait(timeout=sigint_timeout)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1911, in _wait
    time.sleep(delay)
    self._wait(timeout=sigint_timeout)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1911, in _wait
KeyboardInterrupt
    time.sleep(delay)
KeyboardInterrupt
    time.sleep(delay)
KeyboardInterrupt
    time.sleep(delay)
    time.sleep(delay)
KeyboardInterrupt
KeyboardInterrupt
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1189, in wait
    return self._wait(timeout=timeout)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1917, in _wait
    (pid, sts) = self._try_wait(0)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1875, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/wandb/sdk/wandb_manager.py", line 186, in _teardown
    result = self._service.join()
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/wandb/sdk/service/service.py", line 216, in join
    ret = self._internal_proc.wait()
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1202, in wait
    self._wait(timeout=sigint_timeout)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/subprocess.py", line 1911, in _wait
    time.sleep(delay)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Error in atexit._run_exitfuncs:
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/sentry_sdk/worker.py", line 95, in flush
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/sentry_sdk/worker.py", line 95, in flush
Error in atexit._run_exitfuncs:
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/sentry_sdk/worker.py", line 95, in flush
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/weakref.py", line 667, in _exitfunc
Traceback (most recent call last):
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/weakref.py", line 667, in _exitfunc
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/weakref.py", line 667, in _exitfunc
    self._wait_flush(timeout, callback)
    self._wait_flush(timeout, callback)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/sentry_sdk/worker.py", line 107, in _wait_flush
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/sentry_sdk/worker.py", line 107, in _wait_flush
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/sentry_sdk/worker.py", line 95, in flush
    self._wait_flush(timeout, callback)
Error in atexit._run_exitfuncs:
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/sentry_sdk/worker.py", line 107, in _wait_flush
Traceback (most recent call last):
    if not self._timed_queue_join(timeout - initial_timeout):
    if not self._timed_queue_join(timeout - initial_timeout):
    f()
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/sentry_sdk/worker.py", line 95, in flush
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/sentry_sdk/worker.py", line 56, in _timed_queue_join
    f()
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/sentry_sdk/worker.py", line 56, in _timed_queue_join
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/weakref.py", line 591, in __call__
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/weakref.py", line 586, in __call__
Error in atexit._run_exitfuncs:
    f()
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/weakref.py", line 591, in __call__
    self._wait_flush(timeout, callback)
Error in atexit._run_exitfuncs:
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/sentry_sdk/worker.py", line 107, in _wait_flush
    if not self._timed_queue_join(timeout - initial_timeout):
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/sentry_sdk/worker.py", line 56, in _timed_queue_join
Traceback (most recent call last):
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/sentry_sdk/worker.py", line 95, in flush
    queue.all_tasks_done.wait(timeout=delay)
    if not self._timed_queue_join(timeout - initial_timeout):
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/threading.py", line 316, in wait
    self._wait_flush(timeout, callback)
    def __call__(self, _=None):
    return info.func(*info.args, **(info.kwargs or {}))
    queue.all_tasks_done.wait(timeout=delay)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/sentry_sdk/worker.py", line 56, in _timed_queue_join
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/urllib3/connectionpool.py", line 1129, in _close_pool_connections
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/sentry_sdk/worker.py", line 107, in _wait_flush
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/threading.py", line 316, in wait
    return info.func(*info.args, **(info.kwargs or {}))
KeyboardInterrupt
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/urllib3/connectionpool.py", line 1129, in _close_pool_connections
    self._wait_flush(timeout, callback)
    queue.all_tasks_done.wait(timeout=delay)
    if not self._timed_queue_join(timeout - initial_timeout):
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/sentry_sdk/worker.py", line 107, in _wait_flush
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/threading.py", line 316, in wait
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/sentry_sdk/worker.py", line 56, in _timed_queue_join
    queue.all_tasks_done.wait(timeout=delay)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/threading.py", line 316, in wait
Traceback (most recent call last):
    if not self._timed_queue_join(timeout - initial_timeout):
    queue.all_tasks_done.wait(timeout=delay)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/sentry_sdk/worker.py", line 56, in _timed_queue_join
    gotit = waiter.acquire(True, timeout)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/sentry_sdk/worker.py", line 95, in flush
    gotit = waiter.acquire(True, timeout)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/threading.py", line 316, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt
KeyboardInterrupt
KeyboardInterrupt
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt
    queue.all_tasks_done.wait(timeout=delay)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/threading.py", line 316, in wait
    gotit = waiter.acquire(True, timeout)
    self._wait_flush(timeout, callback)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/sentry_sdk/worker.py", line 107, in _wait_flush
KeyboardInterrupt
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt
    if not self._timed_queue_join(timeout - initial_timeout):
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/sentry_sdk/worker.py", line 56, in _timed_queue_join
    if conn:
    if conn:
KeyboardInterrupt
KeyboardInterrupt
    queue.all_tasks_done.wait(timeout=delay)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/threading.py", line 316, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt
wandb: - 0.006 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: \ 0.006 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: \ 0.006 MB of 0.059 MB uploaded (0.000 MB deduped)wandb: \ 0.006 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: \ 0.006 MB of 0.055 MB uploaded (0.000 MB deduped)wandb: | 0.012 MB of 0.059 MB uploaded (0.000 MB deduped)/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 11 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
